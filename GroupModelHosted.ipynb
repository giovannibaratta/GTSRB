{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GroupModelHosted.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giovannibaratta/GTSRB/blob/master/GroupModelHosted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Emgme5Yh5gG_",
        "colab": {}
      },
      "source": [
        "#@title Import e definizioni (Versione 5) { vertical-output: true, display-mode: \"form\" }\n",
        "#@markdown Selezionare se si vuole caricare una versione specifica di tensorflow\n",
        "forceVersion = False #@param {type:\"boolean\"} \n",
        "tfVersion = \"1.13.1\" #@param [\"1.12.2\", \"1.13.1\", \"1.14.0rc1\", \"1.14.0\", \"2.0.0b1\", \"PRINT_AV_VERSION\"] {allow-input: true}\n",
        "#@markdown Selezionare se si è collegati ad un runtime locale (non quello di colab)\n",
        "localRuntime = False #@param{type:\"boolean\"}\n",
        "#@markdown Selezionare se si intende utilizzare le TPU come acceleratore (solo se il runtime è quello di colab)\n",
        "useTPU = False #@param {type:\"boolean\"}\n",
        "\n",
        "useTPU = False if localRuntime else useTPU\n",
        "\n",
        "if forceVersion == True:\n",
        "  if useTPU == True:\n",
        "    !pip install -q tensorflow=={tfVersion}\n",
        "  else:\n",
        "    !pip install -q tensorflow-gpu=={tfVersion}\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import pprint\n",
        "import math\n",
        "import random as rn\n",
        "#data aug\n",
        "from tensorflow import keras \n",
        "# gestione directory\n",
        "import shutil\n",
        "import sys\n",
        "# colorare output\n",
        "!pip install -q colorama\n",
        "from colorama import Style as ColoramaStyle\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "currentPath = !pwd\n",
        "#@markdown Path da utilizzare nel caso di runtime remoto\n",
        "colabPath = '/gdrive/My Drive/DatasetSegnaliStradali/GTSRB/' #@param{type:'string'} \n",
        "#@markdown Path da utilizzare nel caso di runtime locale\n",
        "localPath =  \"/Desktop/DL/\" #@param{type:'string'} \n",
        "completeLocalPath = currentPath[0] + localPath\n",
        "#@markdown Cartella da utilizzare all'interno del path per l'output dei risultati (la cartella deve essere già presente)\n",
        "phase = \"trainingPhaseGroupModel\" #@param [\"trainingPhase1\", \"trainingPhaseCNN\", \"trainingPhaseResNet\", \"trainingPhaseInception\", \"trainingPhaseGroupModel\"] {allow-input: true}\n",
        "rootPath = completeLocalPath if localRuntime else colabPath\n",
        "\n",
        "#@markdown Dimensioni delle immagini di training, validation e test\n",
        "width = 48#@param{type:'integer'}\n",
        "height = 48#@param{type:'integer'}\n",
        "tmpPath = rootPath + 'tmp/'\n",
        "testDir = rootPath + 'data/test' + str(width) + 'x' + str(height) + '/'\n",
        "\n",
        "print('Versione TF : ', ColoramaStyle.BRIGHT, tf.__version__, ColoramaStyle.RESET_ALL,sep=\"\")\n",
        "\n",
        "if useTPU == False:\n",
        "  if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    raise RuntimeError(\"Hai selezionato il runtime TPU. Cambia l'impostazioni del notebook\")\n",
        "  print(\"Acceleratore : GPU\")\n",
        "  print(\"Verifica device :\",tf.test.gpu_device_name())\n",
        "  tpu_address = ''\n",
        "else:\n",
        "  if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "    print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "  else:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    print(\"Acceleratore : TPU\")\n",
        "    print ('Verifica device : ', tpu_address)\n",
        "\n",
        "if not localRuntime:\n",
        "  from google.colab import drive\n",
        "  from google.colab import files\n",
        "  drive.mount('/gdrive')\n",
        "    \n",
        "#import script da gdrive\n",
        "scriptPath = rootPath + \"scripts/colab/\"\n",
        "sys.path.append(scriptPath)\n",
        "\n",
        "from CommonUtils import *\n",
        "from ModelBuilderUtils import *\n",
        "from TrainingUtils import *\n",
        "from TestUtils import *\n",
        "\n",
        "if tfVersion()['MAJOR'] < 2:\n",
        "  tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "resetSeed()\n",
        "\n",
        "groupInfo = {\n",
        "    0 : 'prohibitory',\n",
        "    1 : 'danger',\n",
        "    2 : 'mandatory',\n",
        "    3 : 'others',\n",
        "    4 : 'limitsEnd'\n",
        "}\n",
        "\n",
        "labelsInfo = {\n",
        "    # labelNumber : (group,labelInsideGroup, description)\n",
        "    0 : (0,0, '20 km/h'),\n",
        "    1 : (0,1, '30 km/h'),\n",
        "    2 : (0,2, '50 km/h'),\n",
        "    3 : (0,3, '60 km/h'),\n",
        "    4 : (0,4, '70 km/h'),\n",
        "    5 : (0,5, '80 km/h'),\n",
        "    6 : (4,0, '80 km/h end'),\n",
        "    7 : (0,6, '100 km/h'),\n",
        "    8 : (0,7, '120 km/h'),\n",
        "    9 : (0,8, 'No overtaking'),\n",
        "    10 : (0,9, 'No overtaking for tracks'),\n",
        "    11 : (1,0, 'Crossroad with secondary way'),\n",
        "    12 : (3,0, 'Main road'),\n",
        "    13 : (3,1,  'Give way'),\n",
        "    14 : (3,2, 'Stop'),\n",
        "    15 : (0,10,  'Road up'),\n",
        "    16 : (0,11, 'Road up for track'),\n",
        "    17 : (3,3,  'Brock'),\n",
        "    18 : (1,1, 'Other dangerous'),\n",
        "    19 : (1,2, 'Turn left'),\n",
        "    20 : (1,3, 'Turn right'),\n",
        "    21 : (1,4, 'Winding road'),\n",
        "    22 : (1,5, 'Hollow road'),\n",
        "    23 : (1,6, 'Slippery road'),\n",
        "    24 : (1,7, 'Narrowing road'),\n",
        "    25 : (1,8, 'Roadwork'),\n",
        "    26 : (1,9, 'Traffic light'),\n",
        "    27 : (1,10, 'Pedestrian'),\n",
        "    28 : (1,11, 'Children'),\n",
        "    29 : (1,12, 'Bike'),\n",
        "    30 : (1,13, 'Snow'),\n",
        "    31 : (1,14, 'Deer'),\n",
        "    32 : (4,1, 'End of the limits'),\n",
        "    33 : (2,0, 'Only right'),\n",
        "    34 : (2,1, 'Only left'),\n",
        "    35 : (2,2, 'Only straight'),\n",
        "    36 : (2,3, 'Only straight and right'),\n",
        "    37 : (2,4, 'Only straight and left'),\n",
        "    38 : (2,5, 'Take right'),\n",
        "    39 : (2,6, 'Take left'),\n",
        "    40 : (2,7, 'Circle crossroad'),\n",
        "    41 : (4,2, 'End of overtaking limit'),\n",
        "    42 : (4,3, 'End of overtaking limit for track')\n",
        "}\n",
        "\n",
        "lookUpTable=[\n",
        "    # gruppo 0\n",
        "    {\n",
        "        0:0,\n",
        "        1:1,\n",
        "        2:2,\n",
        "        3:3,\n",
        "        4:4,\n",
        "        5:5,\n",
        "        6:7,\n",
        "        7:8,\n",
        "        8:9,\n",
        "        9:10,\n",
        "        10:15,\n",
        "        11:16\n",
        "    },\n",
        "    # gruppo 1\n",
        "    {\n",
        "        0:11,\n",
        "        1:18,\n",
        "        2:19,\n",
        "        3:20,\n",
        "        4:21,\n",
        "        5:22,\n",
        "        6:23,\n",
        "        7:24,\n",
        "        8:25,\n",
        "        9:26,\n",
        "        10:27,\n",
        "        11:28,\n",
        "        12:29,\n",
        "        13:30,\n",
        "        14:31\n",
        "    },\n",
        "    # gruppo 2\n",
        "    {\n",
        "        0:33,\n",
        "        1:34,\n",
        "        2:35,\n",
        "        3:36,\n",
        "        4:37,\n",
        "        5:38,\n",
        "        6:39,\n",
        "        7:40\n",
        "    },\n",
        "    # gruppo 3\n",
        "    {\n",
        "        0:12,\n",
        "        1:13,\n",
        "        2:14,\n",
        "        3:17\n",
        "    },\n",
        "    #gruppo 4\n",
        "    {\n",
        "        0:6,\n",
        "        1:32,\n",
        "        2:41,\n",
        "        3:42  \n",
        "    }\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg7Zj2axTkiQ",
        "colab_type": "text"
      },
      "source": [
        "### Caricamento dati, definizione modello e training per riconoscere il gruppo delle immagini (prohibitory,danger,mandatory,others,limits end)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1CDs1W0GIft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Caricamento dei dati (versione 5) { vertical-output: true, display-mode: \"form\" }\n",
        "if 'trainingData' in locals():\n",
        "  del trainingData\n",
        "if 'trainingLabels' in locals():\n",
        "  del trainingLabels\n",
        "if 'validationData' in locals():  \n",
        "  del validationData\n",
        "if 'validationLabels' in locals():\n",
        "  del validationLabels\n",
        "\n",
        "trainingDir = rootPath + 'data/training/'\n",
        "validationDir = rootPath + 'data/validation/'\n",
        "\n",
        "#@markdown Deselezionare nel caso si sti allenando il modello a due step, in quel caso le label non sono le originale ma sono il gruppo della classe\n",
        "loadTrueLabels = True #@param{type:'boolean'}\n",
        "\n",
        "samplingToLoad = 1#@param{type:'integer'}\n",
        "#@markdown Seed per la genezione di nuove immagini\n",
        "randomSeed = 62806#@param{type:'integer'}\n",
        "#@markdown Sperimentale, non usare\n",
        "use16Bit = False#@param{type:'boolean'}\n",
        "#@markdown Sperimentale, non usare\n",
        "convertToTesnor = False#@param{type:'boolean'}\n",
        "trainingDir = rootPath + 'data/sampling' + str(samplingToLoad) + '_' + str(width) + 'x' + str(height) + '/training/'\n",
        "validationDir = rootPath + 'data/sampling' + str(samplingToLoad) + '_' + str(width) + 'x' + str(height) + '/validation/'\n",
        "\n",
        "#riproducibilità dei training\n",
        "resetSeed(15 + randomSeed)\n",
        "\n",
        "#@markdown Selezionare se si vogliono generare delle immagini aggiuntive\n",
        "useDataAugmentation = True #@param {type:\"boolean\"}\n",
        "#@markdown Se selezionato il valore degli slider vengono aggiunti ai valori presenti nel codice\n",
        "usePerLabelDataAug = True #@param {type:\"boolean\"}\n",
        "#@markdown Se selezionato non genera immagini aggiuntive per il validation set\n",
        "onlyTrainingAug = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Numero di immagini da generare per ogni immagine originale\n",
        "NUMBER_OF_TRAINING_AUG_GLOBAL = 1 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "NUMBER_OF_VALIDATION_AUG_GLOBAL = 1 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "\n",
        "# da modificare se si vuole alterare la distribuzione delle classi\n",
        "NUMBER_AUG_BY_LABEL = { \n",
        "                0 : ( 4 , 2 ), # group 0  label inside group 0\n",
        "                1 : ( 1 , 1 ), # group 0  label inside group 1\n",
        "                2 : ( 1 , 1 ), # group 0  label inside group 2\n",
        "                3 : ( 1 , 1 ), # group 0  label inside group 3\n",
        "                4 : ( 1 , 1 ), # group 0  label inside group 4\n",
        "                5 : ( 1 , 1 ), # group 0  label inside group 5\n",
        "                6 : ( 3 , 2 ), # group 4  label inside group 0\n",
        "                7 : ( 1 , 1 ), # group 0  label inside group 6\n",
        "                8 : ( 1 , 1 ), # group 0  label inside group 7\n",
        "                9 : ( 1 , 1 ), # group 0  label inside group 8\n",
        "                10 : ( 1 , 1 ), # group 0  label inside group 9\n",
        "                11 : ( 1 , 1 ), # group 1  label inside group 0\n",
        "                12 : ( 1 , 1 ), # group 3  label inside group 0\n",
        "                13 : ( 1 , 1 ), # group 3  label inside group 1\n",
        "                14 : ( 2 , 1 ), # group 3  label inside group 2\n",
        "                15 : ( 2 , 1 ), # group 0  label inside group 10\n",
        "                16 : ( 3 , 2 ), # group 0  label inside group 11\n",
        "                17 : ( 1 , 1 ), # group 3  label inside group 3\n",
        "                18 : ( 1 , 1 ), # group 1  label inside group 1\n",
        "                19 : ( 4 , 2 ), # group 1  label inside group 2\n",
        "                20 : ( 3 , 2 ), # group 1  label inside group 3\n",
        "                21 : ( 3 , 2 ), # group 1  label inside group 4\n",
        "                22 : ( 3 , 2 ), # group 1  label inside group 5\n",
        "                23 : ( 3 , 2 ), # group 1  label inside group 6\n",
        "                24 : ( 3 , 2 ), # group 1  label inside group 7\n",
        "                25 : ( 1 , 1 ), # group 1  label inside group 8\n",
        "                26 : ( 3 , 2 ), # group 1  label inside group 9\n",
        "                27 : ( 3 , 2 ), # group 1  label inside group 10\n",
        "                28 : ( 3 , 2 ), # group 1  label inside group 11\n",
        "                29 : ( 3 , 2 ), # group 1  label inside group 12\n",
        "                30 : ( 4 , 2 ), # group 1  label inside group 13\n",
        "                31 : ( 2 , 2 ), # group 1  label inside group 14\n",
        "                32 : ( 3 , 2 ), # group 4  label inside group 1\n",
        "                33 : ( 3 , 2 ), # group 2  label inside group 0\n",
        "                34 : ( 5 , 2 ), # group 2  label inside group 1\n",
        "                35 : ( 1 , 2 ), # group 2  label inside group 2\n",
        "                36 : ( 2 , 2 ), # group 2  label inside group 3\n",
        "                37 : ( 2 , 2 ), # group 2  label inside group 4\n",
        "                38 : ( 1 , 1 ), # group 2  label inside group 5\n",
        "                39 : ( 3 , 2 ), # group 2  label inside group 6\n",
        "                40 : ( 3, 2 ), # group 2  label inside group 7\n",
        "                41 : ( 3 , 2 ), # group 4  label inside group 2\n",
        "                42 : ( 3 , 2 ), # group 4  label inside group 3\n",
        "              }\n",
        "\n",
        "NUMBER_OF_TRAINING_AUG = [0 for i in range(43)]\n",
        "NUMBER_OF_VALIDATION_AUG = [0 for i in range(43)]\n",
        "\n",
        "if useDataAugmentation == True:\n",
        "  for key in labelsInfo.keys():\n",
        "    NUMBER_OF_TRAINING_AUG[key] = NUMBER_AUG_BY_LABEL[key][0] if usePerLabelDataAug else NUMBER_OF_TRAINING_AUG_GLOBAL\n",
        "    NUMBER_OF_VALIDATION_AUG[key] = NUMBER_AUG_BY_LABEL[key][1] if usePerLabelDataAug else NUMBER_OF_VALIDATION_AUG_GLOBAL\n",
        "    if usePerLabelDataAug and onlyTrainingAug:\n",
        "        NUMBER_OF_VALIDATION_AUG[key] = 0\n",
        "\n",
        "\n",
        "brightness_range_training = (0.25,0.6)\n",
        "rotation_range_training = 25\n",
        "width_shift_range_training = 8\n",
        "height_shift_range_training = 8\n",
        "shear_range_training = 15\n",
        "zoom_range_training =(0.4,1.15)\n",
        "channel_shift_range_training = 0.13\n",
        "\n",
        "brightness_range_validation =(0.25,0.7)\n",
        "rotation_range_validation = 25\n",
        "width_shift_range_validation = 8 \n",
        "height_shift_range_validation = 8\n",
        "shear_range_validation = 0.4\n",
        "zoom_range_validation = (0.4,1.15)\n",
        "channel_shift_range_validation = 0.12\n",
        "\n",
        "#generatore utilizzato per le immagni di training\n",
        "generatorTraining = keras.preprocessing.image.ImageDataGenerator(\n",
        "    brightness_range = brightness_range_training,\n",
        "    rotation_range= rotation_range_training,\n",
        "    width_shift_range= width_shift_range_training,\n",
        "    height_shift_range= height_shift_range_training,\n",
        "    shear_range=shear_range_training,\n",
        "    zoom_range= zoom_range_training,\n",
        "    channel_shift_range=channel_shift_range_training)\n",
        "\n",
        "#generatore utilizzato per le immagini di validation\n",
        "generatorValidation = keras.preprocessing.image.ImageDataGenerator(\n",
        "    brightness_range = brightness_range_validation,\n",
        "    rotation_range=rotation_range_validation,\n",
        "    width_shift_range=width_shift_range_validation,\n",
        "    height_shift_range=height_shift_range_validation,\n",
        "    shear_range=shear_range_validation,\n",
        "    zoom_range=zoom_range_validation,\n",
        "    channel_shift_range=channel_shift_range_validation)\n",
        "\n",
        "# numero di immagini originali disponibili per ogni classe\n",
        "trainingClassCount = {}\n",
        "# numero di immagini di training totali\n",
        "totalTrainingCount = 0\n",
        "\n",
        "files = list(filter(lambda fn : fn.startswith('resized'), os.listdir(trainingDir)))\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  numFilePath = trainingDir + 'num' + str(classLabel)\n",
        "  with open(numFilePath, 'r') as file:\n",
        "    originalNum = int(file.readline())\n",
        "    trainingClassCount[classLabel] = originalNum \n",
        "    totalTrainingCount += originalNum * (NUMBER_OF_TRAINING_AUG[classLabel] + 1)\n",
        "\n",
        "print(\"Training images (no pad):\", totalTrainingCount)\n",
        "\n",
        "# se uso le TPU in tf 1.13 il numero di immagini deve essere divisibile per 8\n",
        "trainingPadEnd = False\n",
        "\n",
        "if useTPU == True and tfVersion()['MAJOR'] == 1 and tfVersion()['MAJOR'] <= 13:\n",
        "  if totalTrainingCount % 8 != 0:\n",
        "    trainingToPad = 8 - (totalTrainingCount % 8)\n",
        "    totalTrainingCount = totalTrainingCount + (8 - (totalTrainingCount % 8))\n",
        "    trainingPadEnd = True\n",
        "  \n",
        "#preparo gli array che contengono le img di training\n",
        "trainingData = np.empty((totalTrainingCount, width, height, 3), dtype='float32')\n",
        "trainingLabels = np.empty((totalTrainingCount), dtype='int32')\n",
        "trueTrainingLabels = np.empty((totalTrainingCount), dtype='int32')\n",
        "\n",
        "# numero di immagini originali disponibili per ogni classe\n",
        "validationClassCount = {}\n",
        "# numero di immagini di validation totali\n",
        "totalValidationCount = 0\n",
        "\n",
        "# recupero il numero di immagini di validation disponibili per ogni classe\n",
        "files = list(filter(lambda fn : fn.startswith('resized'), os.listdir(trainingDir)))\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  numFilePath = validationDir + 'num' + str(classLabel)\n",
        "  with open(numFilePath, 'r') as file:\n",
        "    originalNum = int(file.readline())\n",
        "    validationClassCount[classLabel] = originalNum\n",
        "    totalValidationCount += originalNum * (NUMBER_OF_VALIDATION_AUG[classLabel] + 1)\n",
        "\n",
        "print(\"Validation images (no pad):\", totalValidationCount)\n",
        "\n",
        "# se uso le TPU in tf 1.13 il numero di immagini deve essere divisibile per 8\n",
        "validationPadEnd = False \n",
        "\n",
        "if useTPU == True and tfVersion()['MAJOR'] == 1 and tfVersion()['MAJOR'] <= 13:\n",
        "    if totalValidationCount % 8 != 0:\n",
        "      # se uso le TPU la lunghezza dei dati deve essere divisibile per 8\n",
        "      validationToPad = 8 - (totalValidationCount % 8)\n",
        "      totalValidationCount = totalValidationCount + (8 - (totalValidationCount % 8))\n",
        "      validationPadEnd = True\n",
        "  \n",
        "#preparo gli array che contengono le img di validation\n",
        "validationData = np.empty((totalValidationCount, width, height, 3), dtype='float32')\n",
        "# contengono il gruppo da 0 a 4\n",
        "validationLabels = np.empty((totalValidationCount), dtype='int32')\n",
        "#contengono la label vera da 0 a 42\n",
        "trueValidationLabels = np.empty((totalValidationCount), dtype='int32')\n",
        "\n",
        "print('Total', totalValidationCount + totalTrainingCount)\n",
        "if useDataAugmentation == True:\n",
        "  print(\"Data augmentation training\", NUMBER_OF_TRAINING_AUG, \"\\nvalidation\", NUMBER_OF_VALIDATION_AUG)\n",
        "else:\n",
        "  print(\"Data augmentation : OFF\")\n",
        "\n",
        "#numero di immagini elaborate  \n",
        "validationCount = 0\n",
        "trainingCount = 0\n",
        "loadedClass = 0\n",
        "\n",
        "#caricamento dati\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  #carico le img di training originali\n",
        "  trainingImages = np.memmap(trainingDir + fileName, dtype=np.uint8,\n",
        "              mode='r', shape=(trainingClassCount[classLabel],width,height,3))\n",
        "\n",
        "  for img in trainingImages:\n",
        "    trainingData[trainingCount]  = img/255.0\n",
        "    trainingLabels[trainingCount] = labelsInfo[classLabel][0] if not loadTrueLabels else classLabel\n",
        "    trueTrainingLabels[trainingCount] = classLabel\n",
        "    trainingCount += 1\n",
        "\n",
        "  #carico le immagini di validation\n",
        "  validationImages = np.memmap(validationDir + fileName, dtype=np.uint8,\n",
        "              mode='r', shape=(validationClassCount[classLabel],width,height,3))\n",
        "\n",
        "  for img in validationImages:\n",
        "    validationData[validationCount] = img/255.0\n",
        "    validationLabels[validationCount] = labelsInfo[classLabel][0] if not loadTrueLabels else classLabel\n",
        "    trueValidationLabels[validationCount] = classLabel\n",
        "    validationCount += 1\n",
        "  \n",
        "# per ogni immagine genero delle nuove immagini con trasformazioni casuali\n",
        "if useDataAugmentation == True:\n",
        "  print(\"Genero le immagini aggiuntive\")\n",
        "  resetSeed(48560  + randomSeed)\n",
        "  for imageIndex in range(0, trainingCount):\n",
        "    for augIndex in range(0, NUMBER_OF_TRAINING_AUG[trueTrainingLabels[imageIndex]]):\n",
        "      trainingData[trainingCount] = generateRandomImage(generatorTraining, trainingData[imageIndex])/255.0\n",
        "      trainingLabels[trainingCount] = trainingLabels[imageIndex]\n",
        "      trueTrainingLabels[trainingCount] = trueTrainingLabels[imageIndex]\n",
        "      trainingCount += 1\n",
        "\n",
        "  resetSeed(-420360  + randomSeed)\n",
        "  for imageIndex in range(0, validationCount):\n",
        "    for augIndex in range(0, NUMBER_OF_VALIDATION_AUG[trueValidationLabels[imageIndex]]):\n",
        "      validationData[validationCount] = generateRandomImage(generatorValidation, validationData[imageIndex])/255.0\n",
        "      validationLabels[validationCount] = validationLabels[imageIndex]\n",
        "      trueValidationLabels[validationCount] = trueValidationLabels[imageIndex]\n",
        "      validationCount += 1\n",
        "\n",
        "# Se necessario copio l'ultima immagine per rendere la lunghezza divisibile per 8\n",
        "if trainingPadEnd == True:\n",
        "  for index in range(1, trainingToPad + 1):\n",
        "    trainingData[-index] = trainingData[len(trainingData) - (trainingToPad + 1)]\n",
        "    trainingLabels[-index] = trainingLabels[len(trainingLabels) - (trainingToPad + 1)]\n",
        "if validationPadEnd == True:\n",
        "  for index in range(1, validationToPad + 1):\n",
        "    validationData[-index] = validationData[len(validationData) - (validationToPad + 1)]\n",
        "    validationLabels[-index] = validationLabels[len(validationLabels) - (validationToPad + 1)]\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "if use16Bit:\n",
        "    trainingData = tf.convert_to_tensor(trainingData, dtype=tf.bfloat16)\n",
        "    validationData = tf.convert_to_tensor(validationData, dtype=tf.bfloat16)\n",
        "else:\n",
        "    if convertToTesnor:\n",
        "        tempTrainingData = tf.convert_to_tensor(trainingData[:1000], dtype=tf.float32)\n",
        "        tempValidationData = tf.convert_to_tensor(validationData[:1000], dtype=tf.float32)\n",
        "\n",
        "        for index in range((len(trainingData)//1000)-1):\n",
        "            tempTrainingData = tf.concat([tempTrainingData, tf.convert_to_tensor(trainingData[1000+1000*index:1000+1000*(index+1)], dtype=tf.float32)],0)\n",
        "        for index in range((len(validationData)//1000)-1):\n",
        "            tempValidationData = tf.concat([tempValidationData, tf.convert_to_tensor(validationData[1000+1000*index:1000+1000*(index+1)], dtype=tf.float32)],0)\n",
        "        trainingData = tf.concat([tempTrainingData, tf.convert_to_tensor(trainingData[1000*(len(trainingData)//1000):len(trainingData)], dtype=tf.float32)],0)\n",
        "        validationData = tf.concat([tempValidationData, tf.convert_to_tensor(validationData[1000*(len(validationData)//1000):len(validationData)], dtype=tf.float32)],0)\n",
        "print('Training', trainingData.shape) \n",
        "print('Validation', validationData.shape)\n",
        "\n",
        "# statistiche sulla distribuzione delle labels\n",
        "plt.figure(figsize=(20,5))\n",
        "maxLabel = max(trainingLabels)+1\n",
        "print(maxLabel)\n",
        "if maxLabel > 43:\n",
        "  raise RuntimeError(\"C'è un errore grave nel codice, ricontrolla.\")\n",
        "plt.hist(trainingLabels, alpha = 0.5, bins=maxLabel, label = \"training\")\n",
        "plt.hist(validationLabels, alpha = 0.5, bins=maxLabel, label = \"validation\")\n",
        "plt.xticks(np.arange(0, maxLabel, 1))\n",
        "plt.xlim(left=0, right=maxLabel)\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yJzWb-Gp6sdY",
        "colab": {}
      },
      "source": [
        "#@title Esempio immagini { vertical-output: true, display-mode: \"form\" }\n",
        "numImages = 10 #@param {type:\"integer\"}\n",
        "offsetTraining = 5000 #@param {type:\"integer\"}\n",
        "offsetValidation = 50 #@param {type:\"integer\"}\n",
        "\n",
        "if offsetTraining < 0:\n",
        "  offsetTraining = np.random.randint(low = 0, high = len(trainingData) - numImages)\n",
        "if offsetValidation < 0:\n",
        "  offsetValidation = np.random.randint(low = 0, high = len(validationData) - numImages)\n",
        "\n",
        "print(\"Offset training : \", offsetTraining)\n",
        "print(\"Offset validation : \", offsetValidation)\n",
        "\n",
        "figure = plt.figure(figsize = (30,30),constrained_layout=False)\n",
        "gs = figure.add_gridspec(nrows=2, ncols=numImages, right = 0.4, left = 0.1,top = 0.2, bottom = 0.1)\n",
        "count = 0\n",
        "for i in range(numImages):\n",
        "  ax = figure.add_subplot(gs[0,i])\n",
        "  ax.imshow(trainingData[offsetTraining + count])\n",
        "  ax.axis('off')\n",
        "  ax.grid(False)\n",
        "  count += 1\n",
        "  \n",
        "\n",
        "\n",
        "figure = plt.figure(figsize = (30,30),constrained_layout=False)\n",
        "gs = figure.add_gridspec(nrows=2, ncols=numImages, right = 0.4, left = 0.1,top = 0.2, bottom = 0.1)\n",
        "count = 0\n",
        "for i in range(numImages):\n",
        "  ax = figure.add_subplot(gs[0,i])\n",
        "  ax.imshow(validationData[offsetValidation + count])\n",
        "  ax.axis('off')\n",
        "  ax.grid(False)\n",
        "  count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECNsZzsqq2Dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BigResNet():\n",
        "  def closure():\n",
        "    inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "    layer = buildConvBlock(inputs, layers = 3, size = 64, kernelSize = 3, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "    layer = buildResNetBlock(layer, 128, 128, 512)\n",
        "    layer = buildResNetBlock(layer, 128, 128, 512)\n",
        "    layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "    layer = buildResNetBlock(layer, 256, 256, 1024)\n",
        "    layer = buildResNetBlock(layer, 256, 256, 1024)\n",
        "    layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "    layer = buildResNetBlock(layer, 512, 512, 2048)\n",
        "    outputs = buildGlobalSoftmax(layer, numberOfLabels = 5, kernelSize=3, denseDepth = 2, denseSize=128, dropout = 0.35)\n",
        "    return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return (closure,\"BigResNetGroupDetection\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urCz6X5MGZ7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = Models()\n",
        "\n",
        "trInfo = TrainingInfo.getDefaultTPU(\n",
        "    trainingData,\n",
        "    trainingLabels,\n",
        "    validationData,\n",
        "    validationLabels\n",
        ")\n",
        "\n",
        "trInfo.setParameters(\n",
        "    learningRateList = [0.001],\n",
        "    fineTuningIterations = 4,\n",
        "    mainEpochs = 200,\n",
        "    fineTuningEpochs = 50,\n",
        "    batchSize = 128,\n",
        "    validationFrequency = 10,\n",
        "    validationFrequencyFT = 5,\n",
        "    metrics = ['sparse_categorical_accuracy'],\n",
        "    classWeights = None\n",
        ")\n",
        "\n",
        "generatedModel = BigResNet()\n",
        "models.addModel(generatedModel[1], generatedModel[0], trInfo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y_-ugGJM7U0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Training ( versione 4) { vertical-output: true, display-mode: \"form\" }\n",
        "cleanLastSession = False #@param {type:\"boolean\"}\n",
        "if 'lastSession' in locals():\n",
        "  if cleanLastSession == True:\n",
        "    for trainedModel in lastSession:\n",
        "      print(\"Rimuovo il training del modello\", trainedModel)\n",
        "      shutil.rmtree(trainedModel)\n",
        "    lastSession = []\n",
        "else:\n",
        "  lastSession = []\n",
        "#@markdown ---\n",
        "verboseTraining = 0 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "mainTrainingEarlyStoppingDelta = 0.01 #@param {type:\"number\"}\n",
        "mainTrainingEarlyStoppinPatience = 15 #@param {type:\"integer\"}\n",
        "fineTuningEarlyStoppingDelta = 0.003 #@param {type:\"number\"}\n",
        "fineTuningEarlyStoppinPatience = 10 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "trainingPath = rootPath + phase + \"/\"\n",
        "\n",
        "dataToLog  = [\"AUG : \"+ str(useDataAugmentation)+\"\\n\",\n",
        "                    \"TR_AUG : \" + str(NUMBER_OF_TRAINING_AUG)+\"\\n\",\n",
        "                    \"VAL_AUG : \" + str(NUMBER_OF_VALIDATION_AUG)+\"\\n\",\n",
        "                    \"brightness_range_training : \" + str(brightness_range_training) + \"\\n\",\n",
        "                    \"rotation_range_training : \" + str(rotation_range_training) + \"\\n\",\n",
        "                    \"width_shift_range_training : \" + str(width_shift_range_training) + \"\\n\",\n",
        "                    \"height_shift_range_training : \" + str(height_shift_range_training) + \"\\n\",\n",
        "                    \"shear_range_training : \" + str(shear_range_training) + \"\\n\",     \n",
        "                    \"zoom_range_training : \" + str(zoom_range_training) + \"\\n\",\n",
        "                    \"channel_shift_range_training : \" + str(channel_shift_range_training) + \"\\n\",\n",
        "                    \"brightness_range_validation : \" + str(brightness_range_validation) + \"\\n\",\n",
        "                    \"rotation_range_validation : \" + str(rotation_range_validation) + \"\\n\",\n",
        "                    \"width_shift_range_validation : \" + str(width_shift_range_validation) + \"\\n\",\n",
        "                    \"height_shift_range_validation : \" + str(height_shift_range_validation) + \"\\n\",\n",
        "                    \"shear_range_validation : \" + str(shear_range_validation) + \"\\n\",     \n",
        "                    \"zoom_range_validation : \" + str(zoom_range_validation) + \"\\n\",\n",
        "                    \"channel_shift_range_validation : \" + str(channel_shift_range_validation) + \"\\n\",\n",
        "                    \"sampling : \" + str(samplingToLoad) + \"\\n\",\n",
        "                    \"randomSeed : \" + str(randomSeed)+\"\\n\"]\n",
        "\n",
        "if \"useCustomLoad\" in locals() and useCustomLoad == True:\n",
        "  dataToLog.append(\"Custom_load : \" + str(useCustomLoad)+\"\\n\")\n",
        "  dataToLog.append(\"Custom_ratio : \" + str(customRatio) + \"\\n\")  \n",
        "        \n",
        "train(tpu_address,\n",
        "  trainingPath,\n",
        "  models, \n",
        "  verboseTraining = 1,\n",
        "  mainTrainingEarlyStoppingDelta = mainTrainingEarlyStoppingDelta,\n",
        "  mainTrainingEarlyStoppinPatience = mainTrainingEarlyStoppinPatience,\n",
        "  fineTuningEarlyStoppingDelta = fineTuningEarlyStoppingDelta,\n",
        "  fineTuningEarlyStoppinPatience = fineTuningEarlyStoppinPatience,\n",
        "  stringToLog = ''.join(dataToLog),\n",
        "  lastSession = lastSession)\n",
        "  \n",
        "    \n",
        "print(\"Fine training\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgZyEOY902qN",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Group test\n",
        "\n",
        "testData, padding = loadTestData(testDir, width, height)\n",
        "labels = np.load(testDir + \"labels.npy\")\n",
        "groupLabels = np.zeros((len(labels)), dtype=\"int32\")\n",
        "print(\"Test data ( padding\", padding,\") :\", len(testData))\n",
        "\n",
        "bigResNetMdodel = BigResNet()[0]\n",
        "\n",
        "predictions = testModels([\n",
        "                           (\n",
        "                              bigResNetMdodel,\n",
        "                              [\n",
        "                               rootPath + 'trainingPhaseGroupModel/BigResNetGroupDetection_2019_8_16_14_38_11/0.001/FineTuning/6.25e-05/weights/epoch_45_valLoss_0.0181.hdf5'\n",
        "                              ]\n",
        "                           )\n",
        "                         ],\n",
        "                         testData,\n",
        "                         useTPU,\n",
        "                         tpu_address\n",
        "                       )  \n",
        "\n",
        "savePredictions(predictions, tmpPath + \"step1Predictions.npy\")\n",
        "\n",
        "for i in range(len(labels)):\n",
        "  groupLabels[i] = labelsInfo[labels[i]][0]\n",
        "\n",
        "confusionMatrix = predictionEvaluation(predictions, groupLabels, [0], topN = 5)\n",
        "confusionMatrixStat(confusionMatrix[0], printStat = True)\n",
        "plotConfusionMatrix(confusionMatrix[0], \"TOP 1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfFyOP13hnBs",
        "colab_type": "text"
      },
      "source": [
        "# ***Segue l'allenamento dei singoli modelli***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1DCvK-Ehp5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Caricamento dei dati { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "if 'trainingData' in locals():\n",
        "  del trainingData\n",
        "if 'trainingLabels' in locals():\n",
        "  del trainingLabels\n",
        "if 'validationData' in locals():  \n",
        "  del validationData\n",
        "if 'validationLabels' in locals():\n",
        "  del validationLabels\n",
        "\n",
        "#@markdown Seed per la genezione di nuove immagini e la scelta casuale per custom\n",
        "#@markdown load\n",
        "samplingToLoad = 1#@param{type:'integer'}\n",
        "randomSeed = 41117#@param{type:'integer'}\n",
        "\n",
        "trainingDir = rootPath + 'data/sampling' + str(samplingToLoad) + '_' + str(width) + 'x' + str(height) + '/training/'\n",
        "validationDir = rootPath + 'data/sampling' + str(samplingToLoad) + '_' + str(width) + 'x' + str(height) + '/validation/'\n",
        "\n",
        "#riproducibilità dei training\n",
        "resetSeed(15 + randomSeed)\n",
        "\n",
        "#@markdown ---\n",
        "# Load selettivo dei singoli gruppi\n",
        "loadG0 = False #@param {type:\"boolean\"}\n",
        "loadG1 = True #@param {type:\"boolean\"}\n",
        "loadG2 = False #@param {type:\"boolean\"}\n",
        "loadG3 = False #@param {type:\"boolean\"}\n",
        "loadG4 = False #@param {type:\"boolean\"}\n",
        "\n",
        "loadGroup = [loadG0, loadG1, loadG2, loadG3, loadG4]\n",
        "\n",
        "#@markdown ---\n",
        "useDataAugmentation = True #@param {type:\"boolean\"}\n",
        "#@markdown Se selezionato ignora i valori assegnati ai gruppi sottostanti e usa \n",
        "#@markdown un valore perogni label invece che ogni gruppo. Sono definiti nel codice\n",
        "usePerLabelDataAug = False #@param {type:\"boolean\"}\n",
        "#Numero di immagini da generare per ogni immagine originale\n",
        "NUMBER_OF_TRAINING_AUG_G0 = 7 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "NUMBER_OF_VALIDATION_AUG_G0 = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "NUMBER_OF_TRAINING_AUG_G1 = 9 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "NUMBER_OF_VALIDATION_AUG_G1 = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "NUMBER_OF_TRAINING_AUG_G2 = 7 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "NUMBER_OF_VALIDATION_AUG_G2 = 4 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "NUMBER_OF_TRAINING_AUG_G3 = 12 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "NUMBER_OF_VALIDATION_AUG_G3 = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "NUMBER_OF_TRAINING_AUG_G4 = 27 #@param {type:\"slider\", min:0, max:30, step:1}\n",
        "NUMBER_OF_VALIDATION_AUG_G4 = 5 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "# da modificare se si vuole alterare la distribuzione delle classi\n",
        "NUMBER_AUG_BY_LABEL = { \n",
        "                0 : ( 20 , 2 ), # group 0  label inside group 0\n",
        "                1 : ( 1 , 2 ), # group 0  label inside group 1\n",
        "                2 : ( 1 , 2 ), # group 0  label inside group 2\n",
        "                3 : ( 2 , 2 ), # group 0  label inside group 3\n",
        "                4 : ( 1 , 2 ), # group 0  label inside group 4\n",
        "                5 : ( 1 , 2 ), # group 0  label inside group 5\n",
        "                6 : ( 8 , 4 ), # group 4  label inside group 0\n",
        "                7 : ( 2 , 2 ), # group 0  label inside group 6\n",
        "                8 : ( 2 , 2 ), # group 0  label inside group 7\n",
        "                9 : ( 2 , 2 ), # group 0  label inside group 8\n",
        "                10 : ( 1 , 2 ), # group 0  label inside group 9\n",
        "                11 : ( 2 , 2 ), # group 1  label inside group 0\n",
        "                12 : ( 2 , 2 ), # group 3  label inside group 0\n",
        "                13 : ( 2 , 2 ), # group 3  label inside group 1\n",
        "                14 : ( 8 , 2 ), # group 3  label inside group 2\n",
        "                15 : ( 6 , 2 ), # group 0  label inside group 10\n",
        "                16 : ( 8 , 2 ), # group 0  label inside group 11\n",
        "                17 : ( 5 , 2 ), # group 3  label inside group 3\n",
        "                18 : ( 2 , 2 ), # group 1  label inside group 1\n",
        "                19 : ( 13 , 2 ), # group 1  label inside group 2\n",
        "                20 : ( 9 , 2 ), # group 1  label inside group 3\n",
        "                21 : ( 10 , 2 ), # group 1  label inside group 4\n",
        "                22 : ( 8 , 2 ), # group 1  label inside group 5\n",
        "                23 : ( 6 , 2 ), # group 1  label inside group 6\n",
        "                24 : ( 9 , 2 ), # group 1  label inside group 7\n",
        "                25 : ( 1 , 2 ), # group 1  label inside group 8\n",
        "                26 : ( 5 , 2 ), # group 1  label inside group 9\n",
        "                27 : ( 15 , 5 ), # group 1  label inside group 10\n",
        "                28 : ( 6 , 2 ), # group 1  label inside group 11\n",
        "                29 : ( 10 , 2 ), # group 1  label inside group 12\n",
        "                30 : ( 7 , 2 ), # group 1  label inside group 13\n",
        "                31 : ( 3 , 2 ), # group 1  label inside group 14\n",
        "                32 : ( 9 , 6 ), # group 4  label inside group 1\n",
        "                33 : ( 4 , 2 ), # group 2  label inside group 0\n",
        "                34 : ( 6 , 2 ), # group 2  label inside group 1\n",
        "                35 : ( 3 , 2 ), # group 2  label inside group 2\n",
        "                36 : ( 7 , 3 ), # group 2  label inside group 3\n",
        "                37 : (11 , 5 ), # group 2  label inside group 4\n",
        "                38 : ( 2 , 1 ), # group 2  label inside group 5\n",
        "                39 : ( 7 , 4 ), # group 2  label inside group 6\n",
        "                40 : ( 7, 4 ), # group 2  label inside group 7\n",
        "                41 : ( 9 , 6 ), # group 4  label inside group 2\n",
        "                42 : ( 9 , 6 ), # group 4  label inside group 3\n",
        "              }\n",
        "\n",
        "NUMBER_AUG_BY_GROUP = [\n",
        "        (NUMBER_OF_TRAINING_AUG_G0, NUMBER_OF_VALIDATION_AUG_G0),\n",
        "        (NUMBER_OF_TRAINING_AUG_G1, NUMBER_OF_VALIDATION_AUG_G1),\n",
        "        (NUMBER_OF_TRAINING_AUG_G2, NUMBER_OF_VALIDATION_AUG_G2),\n",
        "        (NUMBER_OF_TRAINING_AUG_G3, NUMBER_OF_VALIDATION_AUG_G3),\n",
        "        (NUMBER_OF_TRAINING_AUG_G4, NUMBER_OF_VALIDATION_AUG_G4)\n",
        "        ]\n",
        "                  \n",
        "NUMBER_OF_TRAINING_AUG = [0 for i in range(43)]\n",
        "NUMBER_OF_VALIDATION_AUG = [0 for i in range(43)]\n",
        "\n",
        "if useDataAugmentation == True:\n",
        "  for key in labelsInfo.keys():\n",
        "    NUMBER_OF_TRAINING_AUG[key] = NUMBER_AUG_BY_LABEL[key][0] if usePerLabelDataAug else NUMBER_AUG_BY_GROUP[labelsInfo[key][0]][0]\n",
        "    NUMBER_OF_VALIDATION_AUG[key] = NUMBER_AUG_BY_LABEL[key][1] if usePerLabelDataAug else NUMBER_AUG_BY_GROUP[labelsInfo[key][0]][1]\n",
        "\n",
        "print(\"Tr AUG : \", NUMBER_OF_TRAINING_AUG)\n",
        "print(\"Val AUG : \", NUMBER_OF_VALIDATION_AUG)\n",
        "\n",
        "# parametri generatore training per gruppo\n",
        "brightness_range_training = [\n",
        "    (0.25,0.6), (0.28,0.57), (0.2,0.7), (0.25,0.6), (0.7,1.0)\n",
        "]\n",
        "rotation_range_training = [25, 20, 10, 25,20]\n",
        "width_shift_range_training=[8,7,10,8,10]\n",
        "height_shift_range_training=[8,7,10,8,10]\n",
        "shear_range_training=[15,12,10,15,12]\n",
        "zoom_range_training=[(0.4,1.15),(0.45,1.15),(0.3,1.25),(0.4,1.15),(0.45,1.15)]\n",
        "channel_shift_range_training=[0.13,0.10,0.15,0.13,0.15]\n",
        "\n",
        "# parametri generatore validation per gruppo\n",
        "brightness_range_validation = [\n",
        "    (0.25,0.6), (0.28,0.57), (0.2,0.7), (0.25,0.6), (0.35,0.6)\n",
        "]\n",
        "rotation_range_validation = [25, 22, 15, 25, 30]\n",
        "width_shift_range_validation=[8,8,9,8,9]\n",
        "height_shift_range_validation=[8,8,9,8,9]\n",
        "shear_range_validation=[15,12,12,15,15]\n",
        "zoom_range_validation=[(0.4,1.15),(0.45,1.15),(0.25,1.3),(0.4,1.15),(0.35,1.15)]\n",
        "channel_shift_range_validation=[0.13,0.115,0.16,0.13,0.15]\n",
        "\n",
        "generatorTraining = []\n",
        "generatorValidation= []\n",
        "\n",
        "for group in range(len(groupInfo.keys())):\n",
        "  #generatore utilizzato per le immagni di training\n",
        "  generatorTraining.append(keras.preprocessing.image.ImageDataGenerator(\n",
        "      brightness_range = brightness_range_training[group],\n",
        "      rotation_range=rotation_range_training[group],\n",
        "      width_shift_range=width_shift_range_training[group],\n",
        "      height_shift_range=height_shift_range_training[group],\n",
        "      shear_range=shear_range_training[group],\n",
        "      zoom_range=zoom_range_training[group],\n",
        "      channel_shift_range=channel_shift_range_training[group]))\n",
        "\n",
        "  #generatore utilizzato per le immagini di validation\n",
        "  generatorValidation.append(keras.preprocessing.image.ImageDataGenerator(\n",
        "      brightness_range = brightness_range_validation[group],\n",
        "      rotation_range=rotation_range_validation[group],\n",
        "      width_shift_range=width_shift_range_validation[group],\n",
        "      height_shift_range=height_shift_range_validation[group],\n",
        "      shear_range=shear_range_validation[group],\n",
        "      zoom_range=zoom_range_validation[group],\n",
        "      channel_shift_range=channel_shift_range_validation[group]))\n",
        "\n",
        "# numero di immagini originali disponibili per ogni classe\n",
        "trainingClassCount = {}\n",
        "#numero di immagini di training totali suddivide per gruppo\n",
        "totalTrainingCount = [0 for group in groupInfo.keys()]\n",
        "loadLabel = [False for i in range(43)]\n",
        "# recupero il numero di immagini di training disponibili per ogni classe\n",
        "files = list(filter(lambda fn : fn.startswith('resized'), os.listdir(trainingDir)))\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  numFilePath = trainingDir + 'num' + str(classLabel)\n",
        "  with open(numFilePath, 'r') as file:\n",
        "    originalNum = int(file.readline())\n",
        "    trainingClassCount[classLabel] = originalNum\n",
        "    groupIndex = labelsInfo[classLabel][0]\n",
        "    if loadGroup[groupIndex] == True:\n",
        "      loadLabel[classLabel] = True\n",
        "      totalTrainingCount[groupIndex] += originalNum * (NUMBER_OF_TRAINING_AUG[classLabel] + 1)\n",
        "\n",
        "# se uso le TPU in tf 1.13 il numero di immagini deve essere divisibile per 8\n",
        "trainingPadEnd = [False for group in groupInfo.keys()]\n",
        "trainingToPad = [0 for group in groupInfo.keys()]\n",
        "if useTPU == True and tfVersion()['MAJOR'] == 1 and tfVersion()['MAJOR'] <= 13:\n",
        "  for groupIndex in range(len(groupInfo.keys())):\n",
        "    if loadGroup[groupIndex] and totalTrainingCount[groupIndex] % 8 != 0:\n",
        "      # se uso le TPU la lunghezza dei dati deve essere divisibile per 8\n",
        "      trainingToPad[groupIndex] = 8 - (totalTrainingCount[groupIndex]  % 8)\n",
        "      totalTrainingCount[groupIndex] = totalTrainingCount[groupIndex]  + (trainingToPad[groupIndex])\n",
        "      trainingPadEnd[groupIndex] = True\n",
        "  \n",
        "#preparo gli array che contengono le img di training\n",
        "trainingData = []\n",
        "trainingLabels = []\n",
        "originalTrainingLabels = []\n",
        "\n",
        "for groupIndex in range(len(groupInfo.keys())):\n",
        "  trainingData.append(np.empty((totalTrainingCount[groupIndex], width, height, 3), dtype=\"float32\"))\n",
        "  trainingLabels.append( np.empty((totalTrainingCount[groupIndex]), dtype='int32'))\n",
        "  originalTrainingLabels.append( np.empty((totalTrainingCount[groupIndex]), dtype='int32'))\n",
        "\n",
        "# numero di immagini originali disponibili per ogni classe\n",
        "validationClassCount = {}\n",
        "#leggo quante img ci sono per ogni class di validation\n",
        "totalValidationCount = [0 for group in groupInfo.keys()]\n",
        "\n",
        "\n",
        "# recupero il numero di immagini di validation disponibili per ogni classe\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  numFilePath = validationDir + 'num' + str(classLabel)\n",
        "  with open(numFilePath, 'r') as file:\n",
        "    numFile = int(file.readline())\n",
        "    validationClassCount[classLabel] = numFile\n",
        "    groupIndex = labelsInfo[classLabel][0]\n",
        "    if loadGroup[groupIndex] == True:\n",
        "      totalValidationCount[groupIndex] += numFile * (NUMBER_OF_VALIDATION_AUG[classLabel]+ 1)\n",
        "\n",
        "# se uso le TPU in tf 1.13 il numero di immagini deve essere divisibile per 8\n",
        "validationPadEnd = [False for group in groupInfo.keys()]\n",
        "validationToPad = [0 for group in groupInfo.keys()]\n",
        "if tfVersion()['MAJOR'] == 1 and tfVersion()['MAJOR'] <= 13:\n",
        "  for groupIndex in range(len(groupInfo.keys())):\n",
        "    if totalValidationCount[groupIndex] % 8 != 0:\n",
        "      validationToPad[groupIndex] = 8 - (totalValidationCount[groupIndex]  % 8)\n",
        "      totalValidationCount[groupIndex] = totalValidationCount[groupIndex]  + (validationToPad[groupIndex])\n",
        "      validationPadEnd[groupIndex] = True\n",
        "  \n",
        "#preparo gli array che contengono le img di validation\n",
        "validationData = []\n",
        "validationLabels = []\n",
        "originalValidationLabels = []\n",
        "for groupIndex in range(len(groupInfo.keys())):\n",
        "  validationData.append(np.empty((totalValidationCount[groupIndex], width, height, 3), dtype=\"float32\"))\n",
        "  validationLabels.append( np.empty((totalValidationCount[groupIndex]), dtype='int32'))\n",
        "  originalValidationLabels.append( np.empty((totalValidationCount[groupIndex]), dtype='int32'))\n",
        "\n",
        "#numero di immagini elaborate per gruppo\n",
        "validationCount = [0 for group in groupInfo.keys()]\n",
        "trainingCount = [0 for group in groupInfo.keys()]\n",
        "loadedClass = 0\n",
        "\n",
        "#caricamento dati\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  if loadLabel[classLabel] == True:\n",
        "    #carico le img di training originali\n",
        "    trainingImages = np.memmap(trainingDir + fileName, dtype=np.uint8,\n",
        "                mode='r', shape=(trainingClassCount[classLabel],width,height,3))\n",
        "\n",
        "    group = labelsInfo[classLabel][0]\n",
        "\n",
        "    for img in trainingImages:\n",
        "      trainingData[group][trainingCount[group]]  = img/255.0\n",
        "      trainingLabels[group][trainingCount[group]] = labelsInfo[classLabel][1]\n",
        "      originalTrainingLabels[group][trainingCount[group]] = classLabel\n",
        "      trainingCount[group] += 1\n",
        "\n",
        "    #carico le immagini di validation\n",
        "    validationImages = np.memmap(validationDir + fileName, dtype=np.uint8,\n",
        "                mode='r', shape=(validationClassCount[classLabel],width,height,3))\n",
        "\n",
        "    for img in validationImages:\n",
        "      validationData[group][validationCount[group]] = img/255.0\n",
        "      validationLabels[group][validationCount[group]] = labelsInfo[classLabel][1]\n",
        "      originalValidationLabels[group][validationCount[group]] = classLabel\n",
        "      validationCount[group] += 1\n",
        "\n",
        "  loadedClass += 1\n",
        "  if (loadedClass) % 5 == 0 or loadedClass == len(files):\n",
        "    print('Caricamento file ', loadedClass, 'su', len(files))\n",
        "\n",
        "# fine for caricamento classi\n",
        "\n",
        "# per ogni immagine genero delle nuove immagini con trasformazioni casuali\n",
        "print(\"\\nGenero le immagini aggiuntive necessarie:\\n\")\n",
        "resetSeed(48560  + randomSeed)\n",
        "for group in range(len(groupInfo.keys())):\n",
        "  for imageIndex in range(0, trainingCount[group]):\n",
        "    #print(group, imageIndex, originalTrainingLabels[group][imageIndex], NUMBER_OF_TRAINING_AUG[originalTrainingLabels[group][imageIndex]])    \n",
        "    for augIndex in range(0, NUMBER_OF_TRAINING_AUG[originalTrainingLabels[group][imageIndex]]):\n",
        "      trainingData[group][trainingCount[group]] = generateRandomImage(generatorTraining[group], trainingData[group][imageIndex])/255.0\n",
        "      trainingLabels[group][trainingCount[group]] = trainingLabels[group][imageIndex]\n",
        "      trainingCount[group] += 1\n",
        "  print(\"Gruppo\", group, \"training terminato\")\n",
        "\n",
        "resetSeed(-420360  + randomSeed)\n",
        "for group in range(len(groupInfo.keys())):\n",
        "  for imageIndex in range(0, validationCount[group]):\n",
        "    for augIndex in range(0, NUMBER_OF_VALIDATION_AUG[originalValidationLabels[group][imageIndex]]):\n",
        "      validationData[group][validationCount[group]] = generateRandomImage(generatorValidation[group], validationData[group][imageIndex])/255.0\n",
        "      validationLabels[group][validationCount[group]] = validationLabels[group][imageIndex]\n",
        "      validationCount[group] += 1\n",
        "  print(\"Gruppo\", group, \"validation terminato\")\n",
        "\n",
        "# Se necessario copio l'ultima immagine per rendere la lunghezza divisibile per 8\n",
        "for group in range(len(groupInfo.keys())):       \n",
        "  if trainingPadEnd[group] == True:\n",
        "    for index in range(1, trainingToPad[group] + 1):\n",
        "      trainingData[group][-index] = trainingData[group][len(trainingData[group]) - (trainingToPad[group] + 1)]\n",
        "      trainingLabels[group][-index] = trainingLabels[group][len(trainingLabels[group]) - (trainingToPad[group] + 1)]\n",
        "    \n",
        "  if validationPadEnd[group] == True:\n",
        "    for index in range(1, validationToPad[group] + 1):\n",
        "      validationData[group][-index] = validationData[group][len(validationData[group]) - (validationToPad[group] + 1)]\n",
        "      validationLabels[group][-index] = validationLabels[group][len(validationLabels[group]) - (validationToPad[group] + 1)]\n",
        "    \n",
        "print(\"Fine padding\")      \n",
        "\n",
        "# statistiche sulla distribuzione delle labels      \n",
        "\n",
        "for index in range(5):\n",
        "  if loadGroup[index] == True:\n",
        "    plt.figure(figsize=(10,5))\n",
        "    maxLabel = max(trainingLabels[index])+1\n",
        "    if maxLabel > 43:\n",
        "      raise RuntimeError(\"C'è un errore grave nel codice, ricontrolla.\")\n",
        "    plt.hist(trainingLabels[index], alpha = 0.5, bins=maxLabel, label = \"training\")\n",
        "    plt.hist(validationLabels[index], alpha = 0.5, bins=maxLabel, label = \"validation\")\n",
        "    plt.xticks(np.arange(0, maxLabel, 1))\n",
        "    plt.xlim(left=0, right=maxLabel)\n",
        "    plt.title('Group' + str(index))\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fii6NWrR446X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Esempio immagini { vertical-output: true, display-mode: \"form\" }\n",
        "group = 4 #@param {type:\"integer\"}\n",
        "numImages = 10 #@param {type:\"integer\"}\n",
        "offsetTraining = 5000 #@param {type:\"integer\"}\n",
        "offsetValidation = 2000 #@param {type:\"integer\"}\n",
        "\n",
        "if offsetTraining < 0:\n",
        "  offsetTraining = np.random.randint(low = 0, high = len(trainingData[group]) - numImages)\n",
        "if offsetValidation < 0:\n",
        "  offsetValidation = np.random.randint(low = 0, high = len(validationData[group]) - numImages)\n",
        "\n",
        "print(\"Offset training : \", offsetTraining)\n",
        "print(\"Offset validation : \", offsetValidation)\n",
        "\n",
        "figure = plt.figure(figsize = (30,30),constrained_layout=False)\n",
        "gs = figure.add_gridspec(nrows=2, ncols=numImages, right = 0.4, left = 0.1,top = 0.2, bottom = 0.1)\n",
        "count = 0\n",
        "for i in range(numImages):\n",
        "  ax = figure.add_subplot(gs[0,i])\n",
        "  ax.imshow(trainingData[group][offsetTraining + count])\n",
        "  ax.axis('off')\n",
        "  ax.grid(False)\n",
        "  count += 1\n",
        "  \n",
        "\n",
        "\n",
        "figure = plt.figure(figsize = (30,30),constrained_layout=False)\n",
        "gs = figure.add_gridspec(nrows=2, ncols=numImages, right = 0.4, left = 0.1,top = 0.2, bottom = 0.1)\n",
        "count = 0\n",
        "for i in range(numImages):\n",
        "  ax = figure.add_subplot(gs[0,i])\n",
        "  ax.imshow(validationData[group][offsetValidation + count])\n",
        "  ax.axis('off')\n",
        "  ax.grid(False)\n",
        "  count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmzn1-GBY09f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model0_0(numberOfLabels):\n",
        "  \n",
        "  f1_1x1 = 32\n",
        "  f1_3x3 = 128\n",
        "  f1_5x5 = 64\n",
        "  f1_maxPool = 32\n",
        "\n",
        "  f2_1x1 = 64\n",
        "  f2_3x3 = 256\n",
        "  f2_5x5 = 128\n",
        "  f2_maxPool = 64\n",
        "\n",
        "  f3_1x1 = 128\n",
        "  f3_3x3 = 512\n",
        "  f3_5x5 = 192\n",
        "  f3_maxPool = 128\n",
        "\n",
        "  def closure():\n",
        "      inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "      layer = buildConvBlock(inputs, layers = 3, size = 64, kernelSize = 5, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "      layer = buildResidualInceptionBlockV4(layer, layer, f1_1x1, f1_3x3, f1_5x5, f1_maxPool)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResidualInceptionBlockV4(layer, layer, f2_1x1, f2_3x3, f2_5x5, f2_maxPool, 384, False)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResidualInceptionBlockV4(layer, layer, f3_1x1, f1_3x3, f3_5x5, f3_maxPool)\n",
        "      layer = buildDenseLayer(layer, 2,64,0.0015,True,True,True,0.3)\n",
        "      outputs = buildDenseSoftmax(layer, numberOfLabels=numberOfLabels, flattenInput=False)\n",
        "      return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return (closure, \"MODEL0_0_INC\")\n",
        "\n",
        "def model1_3(numberOfLabels):\n",
        "  \n",
        "  f1_1x1 = 32\n",
        "  f1_3x3 = 128\n",
        "  f1_5x5 = 64\n",
        "  f1_maxPool = 32\n",
        "\n",
        "  f2_1x1 = 64\n",
        "  f2_3x3 = 256\n",
        "  f2_5x5 = 128\n",
        "  f2_maxPool = 64\n",
        "\n",
        "  f3_1x1 = 128\n",
        "  f3_3x3 = 512\n",
        "  f3_5x5 = 192\n",
        "  f3_maxPool = 128\n",
        "\n",
        "  def closure():\n",
        "      inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "      layer = buildConvBlock(inputs, layers = 3, size = 64, kernelSize = 5, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "      layer = buildResidualInceptionBlockV4(layer, layer, f1_1x1, f1_3x3, f1_5x5, f1_maxPool)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResidualInceptionBlockV4(layer, layer, f2_1x1, f2_3x3, f2_5x5, f2_maxPool, 384, False)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResidualInceptionBlockV4(layer, layer, f3_1x1, f1_3x3, f3_5x5, f3_maxPool)\n",
        "      layer = buildDenseLayer(layer, 2,64,0.0015,True,True,True,0.3)\n",
        "      outputs = buildDenseSoftmax(layer, numberOfLabels=numberOfLabels, flattenInput=False)\n",
        "      return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return (closure, \"MODEL1_3_INC\")\n",
        "\n",
        "\n",
        "def model2_1(numberOfLabels):\n",
        "  \n",
        "  f1_1x1 = 32\n",
        "  f1_3x3 = 128\n",
        "  f1_5x5 = 64\n",
        "  f1_maxPool = 32\n",
        "\n",
        "  f2_1x1 = 64\n",
        "  f2_3x3 = 256\n",
        "  f2_5x5 = 128\n",
        "  f2_maxPool = 64\n",
        "\n",
        "  f3_1x1 = 128\n",
        "  f3_3x3 = 512\n",
        "  f3_5x5 = 192\n",
        "  f3_maxPool = 128\n",
        "\n",
        "  def closure():\n",
        "      inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "      layer = buildConvBlock(inputs, layers = 3, size = 64, kernelSize = 5, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "      layer = buildResidualInceptionBlockV4(layer, layer, f1_1x1, f1_3x3, f1_5x5, f1_maxPool)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResidualInceptionBlockV4(layer, layer, f2_1x1, f2_3x3, f2_5x5, f2_maxPool, 384, False)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResidualInceptionBlockV4(layer, layer, f3_1x1, f1_3x3, f3_5x5, f3_maxPool)\n",
        "      layer = buildDenseLayer(layer, 2,64,0.0015,True,True,True,0.3)\n",
        "      outputs = buildDenseSoftmax(layer, numberOfLabels=numberOfLabels, flattenInput=False)\n",
        "      return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return (closure, \"INC_MODEL2_1\")\n",
        "\n",
        "\n",
        "def model3_0(numberOfLabels):\n",
        "  MULT = 2\n",
        "  L1_B = 128\n",
        "  L1_A = L1_B * MULT\n",
        "  L2_B = 192\n",
        "  L2_A = L1_B * MULT\n",
        "  L3_B = 256\n",
        "  L3_A = L1_B * MULT\n",
        "  \n",
        "  def closure():\n",
        "      inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "      layer = buildConvBlock(inputs, layers = 2, size = 64, kernelSize = 3, poolSize = 3, poolStrides = 2, flatten = False)\n",
        "      layer = buildResNetBlock(layer, L1_B, L1_B, L1_A)\n",
        "      layer = buildResNetBlock(layer, L1_B, L1_B, L1_A)\n",
        "      layer = buildResNetBlock(layer, L1_B, L1_B, L1_A)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResNetBlock(layer, L2_B, L2_B, L2_A)\n",
        "      layer = buildResNetBlock(layer, L2_B, L2_B, L2_A)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResNetBlock(layer, L3_B, L3_B, L3_A)\n",
        "      layer = buildResNetBlock(layer, L3_B, L3_B, L3_A)\n",
        "      layer = buildDenseLayer(layer, 2, 64, regularizers = 0.005, useBatch = True, flattenInput = True, leaky = True, dropout = 0.2)\n",
        "      outputs = buildDenseSoftmax(layer, numberOfLabels = numberOfLabels, flattenInput = False)\n",
        "      return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return (closure, \"MODEL3_0_LEAKY\")\n",
        "\n",
        "\n",
        "def model4_6(numberOfLabels):\n",
        "  \n",
        "  f1_1x1 = 32\n",
        "  f1_3x3 = 128\n",
        "  f1_5x5 = 64\n",
        "  f1_maxPool = 32\n",
        "\n",
        "  def closure():\n",
        "      inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "      layer = buildConvBlock(inputs, layers = 3, size = 64, kernelSize = 5, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "      layer = buildResidualInceptionBlockV4(layer, layer, f1_1x1, f1_3x3, f1_5x5, f1_maxPool)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResidualInceptionBlockV4(layer, layer, f1_1x1, f1_3x3, f1_5x5, f1_maxPool, 384, False)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResidualInceptionBlockV4(layer, layer, f1_1x1, f1_3x3, f1_5x5, f1_maxPool)# 392, False)\n",
        "      layer = buildDenseLayer(layer, 2,64,0.0015,True,True,True,0.3)\n",
        "      outputs = buildDenseSoftmax(layer, numberOfLabels=numberOfLabels, flattenInput=False)\n",
        "      #outputs = buildGlobalSoftmax(layer, numberOfLabels = numberOfLabels, denseSize = 64, denseDepth = 2, kernelSize = 3)\n",
        "      return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return (closure, \"INC_MODEL4_6\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6HM-f0IZKnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subGroupModels = Models()\n",
        "\n",
        "for group in [1]:#range(len(groupInfo.keys())):\n",
        "  if loadGroup[group] == False:\n",
        "    raise RuntimeError(\"Non hai caricato i dati per il gruppo\", group)\n",
        "  trInfo = TrainingInfo.getDefaultTPU(\n",
        "      trainingData[group],\n",
        "      trainingLabels[group],\n",
        "      validationData[group],\n",
        "      validationLabels[group]\n",
        "  )\n",
        "  \n",
        "  uniqueLables, counts = np.unique(trainingLabels[group], return_counts=True)\n",
        "  classWeights = dict(zip(uniqueLables, [math.sqrt(math.sqrt(e)) for e in max(counts) / counts]))\n",
        "  print(classWeights)\n",
        "  \n",
        "  trInfo.setParameters(\n",
        "      learningRateList = [0.0005],\n",
        "      fineTuningIterations = 3,\n",
        "      mainEpochs = 150,\n",
        "      fineTuningEpochs = 60,\n",
        "      batchSize = 128,\n",
        "      validationFrequency = 1,\n",
        "      validationFrequencyFT = 1,\n",
        "      metrics = ['sparse_categorical_accuracy'],\n",
        "      classWeights = classWeights#None # Non supportato dalle TPU nella versione 1.14, utilizzare None\n",
        "  )\n",
        "  generatedModel = model1_3(max(trainingLabels[group]) + 1)\n",
        "  subGroupModels.addModel(generatedModel[1] + '_group' + str(group), generatedModel[0], trInfo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20KS91pVrjiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Training sub-group (versione 2) { vertical-output: true, display-mode: \"form\" }\n",
        "cleanLastSession = False #@param {type:\"boolean\"}\n",
        "if 'lastSession' in locals():\n",
        "  if cleanLastSession == True:\n",
        "    for trainedModel in lastSession:\n",
        "      print(\"Rimuovo il training del modello\", trainedModel)\n",
        "      shutil.rmtree(trainedModel)\n",
        "    lastSession = []\n",
        "else:\n",
        "  lastSession = []\n",
        "#@markdown ---\n",
        "verboseTraining = 0 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "mainTrainingEarlyStoppingDelta = 0.01 #@param {type:\"number\"}\n",
        "mainTrainingEarlyStoppinPatience = 15 #@param {type:\"integer\"}\n",
        "fineTuningEarlyStoppingDelta = 0.003 #@param {type:\"number\"}\n",
        "fineTuningEarlyStoppinPatience = 10 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "trainingPath = rootPath + trainingOutputDir + \"/\"\n",
        "\n",
        "dataToLog  = [\"AUG : \"+ str(useDataAugmentation)+\"\\n\",\n",
        "                    \"TR_AUG : \" + str(NUMBER_OF_TRAINING_AUG)+\"\\n\",\n",
        "                    \"VAL_AUG : \" + str(NUMBER_OF_VALIDATION_AUG)+\"\\n\",\n",
        "                    \"brightness_range_training : \" + str(brightness_range_training) + \"\\n\",\n",
        "                    \"rotation_range_training : \" + str(rotation_range_training) + \"\\n\",\n",
        "                    \"width_shift_range_training : \" + str(width_shift_range_training) + \"\\n\",\n",
        "                    \"height_shift_range_training : \" + str(height_shift_range_training) + \"\\n\",\n",
        "                    \"shear_range_training : \" + str(shear_range_training) + \"\\n\",     \n",
        "                    \"zoom_range_training : \" + str(zoom_range_training) + \"\\n\",\n",
        "                    \"channel_shift_range_training : \" + str(channel_shift_range_training) + \"\\n\",\n",
        "                    \"brightness_range_validation : \" + str(brightness_range_validation) + \"\\n\",\n",
        "                    \"rotation_range_validation : \" + str(rotation_range_validation) + \"\\n\",\n",
        "                    \"width_shift_range_validation : \" + str(width_shift_range_validation) + \"\\n\",\n",
        "                    \"height_shift_range_validation : \" + str(height_shift_range_validation) + \"\\n\",\n",
        "                    \"shear_range_validation : \" + str(shear_range_validation) + \"\\n\",     \n",
        "                    \"zoom_range_validation : \" + str(zoom_range_validation) + \"\\n\",\n",
        "                    \"channel_shift_range_validation : \" + str(channel_shift_range_validation) + \"\\n\",\n",
        "                    \"sampling : \" + str(samplingToLoad) + \"\\n\",\n",
        "                    \"randomSeed : \" + str(randomSeed)+\"\\n\"]\n",
        "\n",
        "if \"useCustomLoad\" in locals() and useCustomLoad == True:\n",
        "  dataToLog.append(\"Custom_load : \" + str(useCustomLoad)+\"\\n\")\n",
        "  dataToLog.append(\"Custom_ratio : \" + str(customRatio) + \"\\n\")  \n",
        "        \n",
        "history = train(tpu_address,\n",
        "  trainingPath,\n",
        "  subGroupModels, \n",
        "  verboseTraining = 1,\n",
        "  mainTrainingEarlyStoppingDelta = mainTrainingEarlyStoppingDelta,\n",
        "  mainTrainingEarlyStoppinPatience = mainTrainingEarlyStoppinPatience,\n",
        "  fineTuningEarlyStoppingDelta = fineTuningEarlyStoppingDelta,\n",
        "  fineTuningEarlyStoppinPatience = fineTuningEarlyStoppinPatience,\n",
        "  stringToLog = ''.join(dataToLog),\n",
        "  lastSession = lastSession)\n",
        "  \n",
        "    \n",
        "print(\"Fine training\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doyoDzepG_wV",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "plotCM = False #@param {type:\"boolean\"}\n",
        "loadG0 = True #@param {type:\"boolean\"}\n",
        "loadG1 = True #@param {type:\"boolean\"}\n",
        "loadG2 = True #@param {type:\"boolean\"}\n",
        "loadG3 = True #@param {type:\"boolean\"}\n",
        "loadG4 = True #@param {type:\"boolean\"}\n",
        "\n",
        "loadGroup = [loadG0, loadG1, loadG2, loadG3, loadG4]\n",
        "\n",
        "if 'testData' not in locals():\n",
        "  testData, padding = loadTestData(testDir, width, height, padding = False)\n",
        "if 'predictions' not in locals():\n",
        "  predictions = loadPredictions(tmpPath + \"step1Predictions.npy\")\n",
        "if 'trueLabels' not in locals():\n",
        "  trueLabels = np.load(testDir + \"labels.npy\")\n",
        "\n",
        "# Tutte le inferenze del primo blocco vengono suddivise per gruppo per poi\n",
        "# essere passate al classificatore specifico, le inferenze dovute al padding\n",
        "# vengono ignorate\n",
        "predictedGroupLabels = np.zeros((len(trueLabels)),dtype=\"int32\")\n",
        "\n",
        "for predictionIndex in range(len(trueLabels)):\n",
        "  # sommo il contributo di tutti i modelli che hanno generato un'inferenze\n",
        "  prediction = np.zeros((5), dtype=\"float\")\n",
        "  for modelIndex in range(len(predictions)):\n",
        "    for weightsIndex in range(len(predictions[0])):\n",
        "      prediction = np.add(prediction, predictions[modelIndex][weightsIndex][predictionIndex])\n",
        "  predictedGroupLabels[predictionIndex] = np.argmax(prediction)\n",
        "\n",
        "# Divido le label originali (con valore da 0 a 42) per gruppo, utilizzando il gruppo \n",
        "# (eventualmente sbagliato) derivante dall'inferenza dello step 1 e non il gruppo reale (corretto)\n",
        "# calcolato sulla label originale\n",
        "trueLabelsByPredictedGroup = [[],[],[],[],[]]\n",
        "trueLabelsByRealGroup = [[],[],[],[],[]]\n",
        "testDataGroup = [[],[],[],[],[]]\n",
        "for index in range(len(predictedGroupLabels)):\n",
        "  testDataGroup[predictedGroupLabels[index]].append(testData[index])\n",
        "  trueLabelsByPredictedGroup[predictedGroupLabels[index]].append(trueLabels[index]) \n",
        "  trueLabelsByRealGroup[labelsInfo[trueLabels[index]][0]].append(trueLabels[index])\n",
        "\n",
        "# Contiene degli array con le inferenze per ogni gruppo\n",
        "result = []  \n",
        "# Numero di label uniche per ogni gruppo\n",
        "maxLabels = [12,15,8,4,4]\n",
        "\n",
        "count = 0\n",
        "\n",
        "## \n",
        "# IMPOSTARE QUI I PESI DA UTILIZZARE PER I 5 MODELLI\n",
        "##\n",
        "weights = [\n",
        "  # grouppo 0\n",
        "    [\n",
        "     #5656\n",
        "     rootPath + 'trainingPhaseGroupModel/MODEL0_0_INC_group0_2019_8_23_14_57_16/0.0005/Main/weights/epoch_31_valLoss_0.0504.hdf5',\n",
        "    ],\n",
        "    \n",
        "  # grouppo 1\n",
        "    [\n",
        "     # gruppo 2764\n",
        "     #2743\n",
        "     rootPath+'trainingPhaseGroupModel/MODEL1_3_INC_group1_2019_8_24_19_15_53/0.0005/FineTuning/0.000125/weights/epoch_15_valLoss_0.0142.hdf5',\n",
        "     #2756\n",
        "     rootPath + 'trainingPhaseGroupModel/MODEL1_3_INC_group1_2019_8_24_14_48_42/0.0005/FineTuning/6.25e-05/weights/epoch_14_valLoss_0.0188.hdf5'\n",
        "    ],\n",
        "  # gruppo 2\n",
        "    [\n",
        "      #1757 e 1756 fanno 1762\n",
        "      #1757         \n",
        "      rootPath + 'trainingPhaseGroupModel/INC_MODEL2_1_group2_2019_8_23_6_29_18/0.0005/FineTuning/0.000125/weights/epoch_05_valLoss_0.0416.hdf5',\n",
        "      #1756         \n",
        "      rootPath  + 'trainingPhaseGroupModel/INC_MODEL2_1_group2_2019_8_22_15_29_53/0.0005/Main/weights/epoch_39_valLoss_0.0662.hdf5'\n",
        "    ],\n",
        "    \n",
        "  # grouppo 3\n",
        "    [\n",
        "      #2024\n",
        "      rootPath + 'trainingPhaseGroupModel/MODEL3_0_LEAKY_group3_2019_8_15_20_49_33/0.0005/FineTuning/6.25e-05/weights/epoch_12_valLoss_0.0110.hdf5'\n",
        "    ],\n",
        "    \n",
        "  # grouppo 4\n",
        "    [\n",
        "     #358\n",
        "     rootPath + 'trainingPhaseGroupModel/INC_MODEL4_6_group4_2019_8_22_6_26_47/0.0005/FineTuning/0.000125/weights/epoch_03_valLoss_0.0537.hdf5'\n",
        "    ]\n",
        "]\n",
        "\n",
        "for tdGroup in testDataGroup:\n",
        "  if loadGroup[count]:\n",
        "    print(\"Gruppo\", count, \"caricato.\")\n",
        "    result.append(loadPredictions(tmpPath + \"step2PredictionsG\" + str(count) + \".npy\"))\n",
        "    count += 1\n",
        "    continue\n",
        "\n",
        "  if len(tdGroup) % 8 != 0:\n",
        "    for index in range(len(tdGroup),len(tdGroup) + (8-len(tdGroup) % 8)):\n",
        "      tdGroup.append(tdGroup[-1])\n",
        "\n",
        "  data = np.asarray(tdGroup, dtype=np.float32)\n",
        "\n",
        "  ##\n",
        "  # IMPOSTARE QUI I MODELLI DA UTILIZZARE\n",
        "  ##\n",
        "  modelList = [ \n",
        "               model0_0(maxLabels[count])[0],\n",
        "               model1_3(maxLabels[count])[0],\n",
        "               model2_1(maxLabels[count])[0],\n",
        "               model3_0(maxLabels[count])[0],\n",
        "               model4_6(maxLabels[count])[0]\n",
        "  ]\n",
        "    \n",
        "  result.append(testModels(\n",
        "                    [\n",
        "                      (modelList[count], weights[count])\n",
        "                    ],\n",
        "                   data,\n",
        "                   useTPU,\n",
        "                   tpu_address\n",
        "                   )\n",
        "      )\n",
        "  savePredictions(result[-1], tmpPath + \"step2PredictionsG\" + str(count) + \".npy\")\n",
        "  count += 1\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "globalConfusionMatrix = [[0 for i in range(43)] for i in range(43)]\n",
        "groupConfusionMatrix = []\n",
        "\n",
        "for index in range(len(result)):\n",
        "  cm = predictionEvaluation(result[index], trueLabelsByPredictedGroup[index], [0], topN = 1, lookUpTable=lookUpTable[index])\n",
        "  groupConfusionMatrix.append(cm[0])\n",
        "  correct, total = confusionMatrixStat(cm[0], printStat = False)\n",
        "  print(\"Corrette\", correct, \"        su\", total, \"{0:.3f}\".format((float(correct)/total * 100)), \"% (predicted)\", \"    su : \" , len(trueLabelsByRealGroup[index]), \":\",    \"{0:.3f}\".format((float(correct)/len(trueLabelsByRealGroup[index]) * 100)), \"% (reali)\")\n",
        "  for r in range(len(cm[0])):\n",
        "    for c in range(len(cm[0])):\n",
        "      globalConfusionMatrix[r][c] += cm[0][r][c]\n",
        "  if plotCM:\n",
        "    plotConfusionMatrix(cm[0], title = \"group\" + str(index))\n",
        "print(\"\")\n",
        "print(\"Globale\")\n",
        "correct, total = confusionMatrixStat(globalConfusionMatrix, printStat = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCRm82v1oJY8",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "Corrette 5656         su 5672 99.718 % (predicted)     su :  5670 : 99.753 % (reali)\n",
        "Corrette 2764         su 2790 99.068 % (predicted)     su :  2790 : 99.068 % (reali)\n",
        "Corrette 1762         su 1771 99.492 % (predicted)     su :  1770 : 99.548 % (reali)\n",
        "Corrette 2024         su 2038 99.313 % (predicted)     su :  2040 : 99.216 % (reali)\n",
        "Corrette 358         su 359 99.721 % (predicted)     su :  360 : 99.444 % (reali)\n",
        "\n",
        "Globale\n",
        "Corrette 12564 su 12630 : 99.477 %\n",
        "```"
      ]
    }
  ]
}
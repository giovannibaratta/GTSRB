{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GroupModelTPU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giovannibaratta/GTSRB/blob/master/GroupModelTPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfHIvRgmF2bK",
        "colab_type": "code",
        "outputId": "51dbee44-f653-4206-ca6e-697ee8b51a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "#@title Import e definizioni { vertical-output: true, display-mode: \"form\" }\n",
        "forceVersion = False #@param {type:\"boolean\"}\n",
        "tfVersion = \"PRINT_AV_VERSION\" #@param [\"1.12.2\", \"1.13.1\", \"1.14.0rc1\", \"1.14.0\", \"2.0.0b1\", \"PRINT_AV_VERSION\"] {allow-input: true}\n",
        "if forceVersion == True:\n",
        "  !pip install -q tensorflow=={tfVersion}\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import os\n",
        "import time\n",
        "import pprint\n",
        "import math\n",
        "import random as rn\n",
        "#data aug\n",
        "from tensorflow import keras \n",
        "# gestione directory directory\n",
        "import shutil\n",
        "import sys\n",
        "# colorare output\n",
        "!pip install -q colorama\n",
        "from colorama import Fore, Style\n",
        "\n",
        "rootPath = '/gdrive/My Drive/DatasetSegnaliStradali/GTSRB/' #@param{type:'string'}\n",
        "width = 48#@param{type:'integer'}\n",
        "height = 48#@param{type:'integer'}\n",
        "\n",
        "useTPU = True\n",
        "\n",
        "print(Style.BRIGHT, tf.__version__, Style.RESET_ALL,sep=\"\")\n",
        "\n",
        "if useTPU == False:\n",
        "  print(tf.test.gpu_device_name())\n",
        "else:\n",
        "  if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "    print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "  else:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    print ('TPU address is', tpu_address)\n",
        "\n",
        "    #with tf.Session(tpu_address) as session:\n",
        "    #  devices = session.list_devices()\n",
        "\n",
        "    #print('TPU devices:')\n",
        "    #pprint.pprint(devices)\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "#import script da gdrive\n",
        "scriptPath = rootPath + \"scripts/colab/\"\n",
        "sys.path.append(scriptPath)\n",
        "\n",
        "from CommonUtils import *\n",
        "from ModelBuilderUtils import *\n",
        "from TrainingUtils import *\n",
        "from TestUtils import *\n",
        "\n",
        "if tfVersion()['MAJOR'] < 2:\n",
        "  tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "resetSeed()\n",
        "\n",
        "groupInfo = {\n",
        "    0 : 'prohibitory',\n",
        "    1 : 'danger',\n",
        "    2 : 'mandatory',\n",
        "    3 : 'others',\n",
        "    4 : 'limitsEnd'\n",
        "}\n",
        "\n",
        "labelsInfo = {\n",
        "    # labelNumber : (group,labelInsideGroup, description)\n",
        "    0 : (0,0, '20 km/h'),\n",
        "    1 : (0,1, '30 km/h'),\n",
        "    2 : (0,2, '50 km/h'),\n",
        "    3 : (0,3, '60 km/h'),\n",
        "    4 : (0,4, '70 km/h'),\n",
        "    5 : (0,5, '80 km/h'),\n",
        "    6 : (4,0, '80 km/h end'),\n",
        "    7 : (0,6, '100 km/h'),\n",
        "    8 : (0,7, '120 km/h'),\n",
        "    9 : (0,8, 'No overtaking'),\n",
        "    10 : (0,9, 'No overtaking for tracks'),\n",
        "    11 : (1,0, 'Crossroad with secondary way'),\n",
        "    12 : (3,0, 'Main road'),\n",
        "    13 : (3,1,  'Give way'),\n",
        "    14 : (3,2, 'Stop'),\n",
        "    15 : (0,10,  'Road up'),\n",
        "    16 : (0,11, 'Road up for track'),\n",
        "    17 : (3,3,  'Brock'),\n",
        "    18 : (1,1, 'Other dangerous'),\n",
        "    19 : (1,2, 'Turn left'),\n",
        "    20 : (1,3, 'Turn right'),\n",
        "    21 : (1,4, 'Winding road'),\n",
        "    22 : (1,5, 'Hollow road'),\n",
        "    23 : (1,6, 'Slippery road'),\n",
        "    24 : (1,7, 'Narrowing road'),\n",
        "    25 : (1,8, 'Roadwork'),\n",
        "    26 : (1,9, 'Traffic light'),\n",
        "    27 : (1,10, 'Pedestrian'),\n",
        "    28 : (1,11, 'Children'),\n",
        "    29 : (1,12, 'Bike'),\n",
        "    30 : (1,13, 'Snow'),\n",
        "    31 : (1,14, 'Deer'),\n",
        "    32 : (4,1, 'End of the limits'),\n",
        "    33 : (2,0, 'Only right'),\n",
        "    34 : (2,1, 'Only left'),\n",
        "    35 : (2,2, 'Only straight'),\n",
        "    36 : (2,3, 'Only straight and right'),\n",
        "    37 : (2,4, 'Only straight and left'),\n",
        "    38 : (2,5, 'Take right'),\n",
        "    39 : (2,6, 'Take left'),\n",
        "    40 : (2,7, 'Circle crossroad'),\n",
        "    41 : (4,2, 'End of overtaking limit'),\n",
        "    42 : (4,3, 'End of overtaking limit for track')\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m1.14.0\u001b[0m\n",
            "TPU address is grpc://10.23.91.202:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg7Zj2axTkiQ",
        "colab_type": "text"
      },
      "source": [
        "### Caricamento dati, definizione modello e training per riconoscere il gruppo delle immagini (prohibitory,danger,mandatory,others,limits end)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1CDs1W0GIft",
        "colab_type": "code",
        "outputId": "3b7143a1-6b23-43f5-b52e-7c91f8d53f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "#@title Caricamento dei dati { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "if 'trainingData' in locals():\n",
        "  del trainingData\n",
        "  del validationData\n",
        "  del validationLabels\n",
        "  del trainingLabels\n",
        "\n",
        "trainingDir = rootPath + 'data/training/'\n",
        "validationDir = rootPath + 'data/validation/'\n",
        "\n",
        "width = 48#@param{type:'integer'}\n",
        "height = 48#@param{type:'integer'}\n",
        "#@markdown Seed per la genezione di nuove immagini e la scelta casuale per custom\n",
        "#@markdown load\n",
        "randomSeed = -3850#@param{type:'integer'}\n",
        "\n",
        "#riproducibilità dei training\n",
        "resetSeed(15 + randomSeed)\n",
        "\n",
        "#@markdown Aggiunge o rimuove delle immagini dalla caassi per cercare di bilanciarle\n",
        "useCustomLoad = False #@param {type:\"boolean\"}\n",
        "#@markdown Bilancia le classi senza utilizzare i paremtri custom nel codice (richiede useCustomLoad = True)\n",
        "balanceClass = False #@param {type:\"boolean\"}\n",
        "customRatio = { \n",
        "                  0 : 1.3,\n",
        "                  1 : 0.5,\n",
        "                  2 : 0.5,\n",
        "                  3 : 0.7,\n",
        "                  4 : 0.5,\n",
        "                  5 : 0.5,\n",
        "                  6 : 1,\n",
        "                  7 : 0.7,\n",
        "                  8 : 0.7,\n",
        "                  9 : 0.7,\n",
        "                  10 : 0.5,\n",
        "                  11 : 0.7,\n",
        "                  12 : 0.5,\n",
        "                  13 : 0.5,\n",
        "                  14 : 1,\n",
        "                  15 : 1,\n",
        "                  16 : 1,\n",
        "                  17 : 1,\n",
        "                  18 : 0.7,\n",
        "                  19 : 1.3,\n",
        "                  20 : 1,\n",
        "                  21 : 1,\n",
        "                  22 : 1,\n",
        "                  23 : 1,\n",
        "                  24 : 1.2,\n",
        "                  25 : 0.5,\n",
        "                  26 : 0.7,\n",
        "                  27 : 1.2,\n",
        "                  28 : 1,\n",
        "                  29 : 1,\n",
        "                  30 : 1,\n",
        "                  31 : 1,\n",
        "                  32 : 1.2,\n",
        "                  33 : 1,\n",
        "                  34 : 1,\n",
        "                  35 : 0.7,\n",
        "                  36 : 1,\n",
        "                  37 : 1.2,\n",
        "                  38 : 0.5,\n",
        "                  39 : 1,\n",
        "                  40 : 1,\n",
        "                  41 : 1,\n",
        "                  42 : 1\n",
        "              }\n",
        "\n",
        "useDataAugmentation = True #@param {type:\"boolean\"}\n",
        "#Numero di immagini da generare per ogni immagine originale\n",
        "NUMBER_OF_TRAINING_AUG = 1 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "NUMBER_OF_VALIDATION_AUG = 1 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "\n",
        "#generatore utilizzato se customLoad > 1\n",
        "generatorCustomLoad = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=5,\n",
        "    width_shift_range=3,\n",
        "    height_shift_range=3,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=(0.95,1.05),\n",
        "    channel_shift_range=0.01)\n",
        "\n",
        "#generatore utilizzato per le immagni di training\n",
        "generatorTraining = keras.preprocessing.image.ImageDataGenerator(\n",
        "    brightness_range = (0.25,0.6),\n",
        "    rotation_range=25,\n",
        "    width_shift_range=8,\n",
        "    height_shift_range=8,\n",
        "    shear_range=15,\n",
        "    zoom_range=(0.4,1.15),\n",
        "    channel_shift_range=0.13)\n",
        "\n",
        "#generatore utilizzato per le immagini di validation\n",
        "generatorValidation = keras.preprocessing.image.ImageDataGenerator(\n",
        "    brightness_range = (0.25,0.7),\n",
        "    rotation_range=25,\n",
        "    width_shift_range=8,\n",
        "    height_shift_range=8,\n",
        "    shear_range=0.4,\n",
        "    zoom_range=(0.4,1.15),\n",
        "    channel_shift_range=0.12)\n",
        "\n",
        "# se non utilizzo dei ratio personalizzati li setto tutti a 1\n",
        "if useCustomLoad == False:\n",
        "  for key in customRatio.keys():\n",
        "    customRatio[key] = 1.0\n",
        "\n",
        "# ratio calcolati in modo automatico per bilanciare le classi (bisogna settare i flag)\n",
        "if useCustomLoad == True and balanceClass == True:\n",
        "  trClassCount = {}\n",
        "  files = list(filter(lambda fn : fn.startswith('resized'), os.listdir(trainingDir)))\n",
        "  for fileName in files:\n",
        "    classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "    numFilePath = trainingDir + 'num' + str(classLabel)\n",
        "    with open(numFilePath, 'r') as file:\n",
        "      originalNum = int(file.readline())\n",
        "      trClassCount[classLabel] = originalNum\n",
        "\n",
        "  newMin = min(trClassCount.values()) * 1.3\n",
        "  for key in trClassCount.keys():\n",
        "    val =  trClassCount[key]\n",
        "    if val < newMin:\n",
        "      customRatio[key] = max(newMin/val, 1.3)\n",
        "    elif val == newMin:\n",
        "      customRatio[key] = 1.0\n",
        "    elif val > newMin:\n",
        "      if val > newMin/2:\n",
        "        customRatio[key] = max(newMin/val, 0.4)\n",
        "      else:\n",
        "        customRatio[key] = max(newMin/val, 0.5)\n",
        "\n",
        "# numero di immagini originali disponibili per ogni classe\n",
        "trainingClassCount = {}\n",
        "# numero di immagini di training totali\n",
        "totalTrainingCount = 0\n",
        "\n",
        "# recupero il numero di immagini di training disponibili per ogni classe\n",
        "files = list(filter(lambda fn : fn.startswith('resized'), os.listdir(trainingDir)))\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  numFilePath = trainingDir + 'num' + str(classLabel)\n",
        "  with open(numFilePath, 'r') as file:\n",
        "    originalNum = int(file.readline())\n",
        "    trainingClassCount[classLabel] = originalNum\n",
        "    # il numero totale tiene conto del custom ratio\n",
        "    totalTrainingCount += round(originalNum * customRatio[classLabel])\n",
        "\n",
        "if useDataAugmentation == True:\n",
        "  totalTrainingCount = totalTrainingCount * (NUMBER_OF_TRAINING_AUG + 1)\n",
        "\n",
        "print(\"Training images (no pad):\", totalTrainingCount)\n",
        "\n",
        "# se uso le TPU in tf 1.13 il numero di immagini deve essere divisibile per 8\n",
        "trainingPadEnd = False\n",
        "\n",
        "if useTPU == True and tfVersion()['MAJOR'] == 1 and tfVersion()['MAJOR'] <= 13:\n",
        "  if totalTrainingCount % 8 != 0:\n",
        "    trainingToPad = 8 - (totalTrainingCount % 8)\n",
        "    totalTrainingCount = totalTrainingCount + (8 - (totalTrainingCount % 8))\n",
        "    trainingPadEnd = True\n",
        "  \n",
        "#preparo gli array che contengono le img di training\n",
        "trainingData = np.empty((totalTrainingCount, width, height, 3), dtype='float32')\n",
        "trainingLabels = np.empty((totalTrainingCount), dtype='int32')\n",
        "\n",
        "# numero di immagini originali disponibili per ogni classe\n",
        "validationClassCount = {}\n",
        "# numero di immagini di validation totali\n",
        "totalValidationCount = 0\n",
        "\n",
        "# recupero il numero di immagini di training disponibili per ogni classe\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  numFilePath = validationDir + 'num' + str(classLabel)\n",
        "  with open(numFilePath, 'r') as file:\n",
        "    numFile = int(file.readline())\n",
        "    validationClassCount[classLabel] = numFile\n",
        "    totalValidationCount += numFile\n",
        "\n",
        "if useDataAugmentation == True:\n",
        "  totalValidationCount = totalValidationCount * (NUMBER_OF_VALIDATION_AUG + 1)\n",
        "\n",
        "print(\"Validation images (no pad):\", totalValidationCount)\n",
        "\n",
        "# se uso le TPU in tf 1.13 il numero di immagini deve essere divisibile per 8\n",
        "validationPadEnd = False \n",
        "\n",
        "if useTPU == True and tfVersion()['MAJOR'] == 1 and tfVersion()['MAJOR'] <= 13:\n",
        "    if totalValidationCount % 8 != 0:\n",
        "      # se uso le TPU la lunghezza dei dati deve essere divisibile per 8\n",
        "      validationToPad = 8 - (totalValidationCount % 8)\n",
        "      totalValidationCount = totalValidationCount + (8 - (totalValidationCount % 8))\n",
        "      validationPadEnd = True\n",
        "  \n",
        "#preparo gli array che contengono le img di validation\n",
        "validationData = np.empty((totalValidationCount, width, height, 3), dtype='float32')\n",
        "validationLabels = np.empty((totalValidationCount), dtype='int32')\n",
        "\n",
        "print('Total', totalValidationCount + totalTrainingCount)\n",
        "if useDataAugmentation == True:\n",
        "  print(\"Data augmentation training\", NUMBER_OF_TRAINING_AUG, \"validation\", NUMBER_OF_VALIDATION_AUG)\n",
        "else:\n",
        "  print(\"Data augmentation : OFF\")\n",
        "\n",
        "#numero di immagini elaborate  \n",
        "validationCount = 0\n",
        "trainingCount = 0\n",
        "loadedClass = 0\n",
        "\n",
        "#caricamento dati\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  #carico le img di training originali\n",
        "  trainingImages = np.memmap(trainingDir + fileName, dtype=np.uint8,\n",
        "              mode='r', shape=(trainingClassCount[classLabel],width,height,3))\n",
        "\n",
        "  imagesToLoad = round(trainingClassCount[classLabel] * customRatio[classLabel])\n",
        "  #genero delle immagini aggiuntive se custom load è > 1.0\n",
        "  imageToGenerate = max(0, imagesToLoad - trainingClassCount[classLabel])\n",
        "  # scelgo casualmente le immagini da utilizzare per generarne di nuove\n",
        "  indices = generateIndices(imageToGenerate, trainingClassCount[classLabel])\n",
        "  # genero le immagini per ribilanciare le classi\n",
        "  for index in indices:\n",
        "    trainingData[trainingCount] = generateRandomImage(generatorCustomLoad, trainingImages[index])/255.0\n",
        "    trainingLabels[trainingCount] = labelsInfo[classLabel][0]\n",
        "    trainingCount += 1\n",
        "  imagesToLoad = imagesToLoad - imageToGenerate\n",
        "  # carico il resto delle immagini, potrei non doverle caricare tutte\n",
        "  indices = generateIndices(imagesToLoad, trainingClassCount[classLabel])\n",
        "  for index in indices:\n",
        "    trainingData[trainingCount] = trainingImages[index]/255.0\n",
        "    trainingLabels[trainingCount] = labelsInfo[classLabel][0]\n",
        "    trainingCount += 1\n",
        "  #carico le immagini di validation\n",
        "  validationImages = np.memmap(validationDir + fileName, dtype=np.uint8,\n",
        "              mode='r', shape=(validationClassCount[classLabel],width,height,3))\n",
        "\n",
        "  for img in validationImages:\n",
        "    validationData[validationCount] = img/255.0\n",
        "    validationLabels[validationCount] = labelsInfo[classLabel][0]\n",
        "    validationCount += 1\n",
        "\n",
        "  loadedClass += 1\n",
        "  if (loadedClass) % 5 == 0 or loadedClass == len(files):\n",
        "    print('Caricamento file ', loadedClass, 'su', len(files))\n",
        "# fine for caricamento classi\n",
        "\n",
        "# per ogni immagine genero delle nuove immagini con trasformazioni casuali\n",
        "if useDataAugmentation == True:\n",
        "  print(\"Genero le immagini aggiuntive\")\n",
        "  resetSeed(48560  + randomSeed)\n",
        "  for imageIndex in range(0, trainingCount):\n",
        "    for augIndex in range(0, NUMBER_OF_TRAINING_AUG):\n",
        "      trainingData[trainingCount] = generateRandomImage(generatorTraining, trainingData[imageIndex])/255.0\n",
        "      trainingLabels[trainingCount] = trainingLabels[imageIndex]\n",
        "      trainingCount += 1\n",
        "\n",
        "  resetSeed(-420360  + randomSeed)\n",
        "  for imageIndex in range(0, validationCount):\n",
        "    for augIndex in range(0, NUMBER_OF_VALIDATION_AUG):\n",
        "      validationData[validationCount] = generateRandomImage(generatorValidation, validationData[imageIndex])/255.0\n",
        "      validationLabels[validationCount] = validationLabels[imageIndex]\n",
        "      validationCount += 1\n",
        "\n",
        "# Se necessario copio l'ultima immagine per rendere la lunghezza divisibile per 8\n",
        "if trainingPadEnd == True:\n",
        "  for index in range(1, trainingToPad + 1):\n",
        "    trainingData[-index] = trainingData[len(trainingData) - (trainingToPad + 1)]\n",
        "    trainingLabels[-index] = trainingLabels[len(trainingLabels) - (trainingToPad + 1)]\n",
        "if validationPadEnd == True:\n",
        "  for index in range(1, validationToPad + 1):\n",
        "    validationData[-index] = validationData[len(validationData) - (validationToPad + 1)]\n",
        "    validationLabels[-index] = validationLabels[len(validationLabels) - (validationToPad + 1)]\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "print('Training', trainingData.shape) \n",
        "print('Validation', validationData.shape)\n",
        "\n",
        "# statistiche sulla distribuzione delle labels\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.hist(trainingLabels, bins=max(trainingLabels))\n",
        "plt.xticks(np.arange(0, max(trainingLabels), 1))\n",
        "plt.xlim(left=0, right=max(trainingLabels))\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.hist(validationLabels, bins=max(validationLabels))\n",
        "plt.xticks(np.arange(0, max(validationLabels), 1))\n",
        "plt.xlim(left=0, right=max(validationLabels))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training images (no pad): 62736\n",
            "Validation images (no pad): 15684\n",
            "Total 78424\n",
            "Data augmentation training 1 validation 1\n",
            "Caricamento file  5 su 43\n",
            "Caricamento file  10 su 43\n",
            "Caricamento file  15 su 43\n",
            "Caricamento file  20 su 43\n",
            "Caricamento file  25 su 43\n",
            "Caricamento file  30 su 43\n",
            "Caricamento file  35 su 43\n",
            "Caricamento file  40 su 43\n",
            "Caricamento file  43 su 43\n",
            "Genero le immagini aggiuntive\n",
            "\n",
            "Training (62736, 48, 48, 3)\n",
            "Validation (15688, 48, 48, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJQAAAEyCAYAAACs14oRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndw71hQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABI4AAAEyCAYAAACcW5swAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECNsZzsqq2Dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BigResNet():\n",
        "  inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "  layer = buildConvBlock(inputs, layers = 3, size = 64, kernelSize = 3, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "  layer = buildResNetBlock(layer, 128, 128, 512)\n",
        "  layer = buildResNetBlock(layer, 128, 128, 512)\n",
        "  layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "  layer = buildResNetBlock(layer, 256, 256, 1024)\n",
        "  layer = buildResNetBlock(layer, 256, 256, 1024)\n",
        "  layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "  layer = buildResNetBlock(layer, 512, 512, 2048)\n",
        "  outputs = buildGlobalSoftmax(layer, numberOfLabels = 5, kernelSize=3, denseDepth = 2, denseSize=128, dropout = 0.35)\n",
        "  return tf.keras.Model(inputs = inputs, outputs = outputs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urCz6X5MGZ7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = Models()\n",
        "\n",
        "trInfo = TrainingInfo.getDefaultTPU(\n",
        "    trainingData,\n",
        "    trainingLabels,\n",
        "    validationData,\n",
        "    validationLabels\n",
        ")\n",
        "\n",
        "trInfo.setParameters(\n",
        "    learningRateList = [0.001],\n",
        "    fineTuningIterations = 4,\n",
        "    mainEpochs = 300,\n",
        "    fineTuningEpochs = 75,\n",
        "    batchSize = 512,\n",
        "    validationFrequency = 5,\n",
        "    metrics = ['sparse_categorical_accuracy']\n",
        ")\n",
        "\n",
        "models.addModel('BigResNetGroupDetection', BigResNet, trInfo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y_-ugGJM7U0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Training group { vertical-output: true, display-mode: \"form\" }\n",
        "cleanLastSession = False #@param {type:\"boolean\"}\n",
        "if 'lastSession' in locals():\n",
        "  if cleanLastSession == True:\n",
        "    for trainedModel in lastSession:\n",
        "      print(\"Rimuovo il training del modello\", trainedModel)\n",
        "      shutil.rmtree(trainedModel)\n",
        "    lastSession = []\n",
        "else:\n",
        "  lastSession = []\n",
        "#@markdown ---\n",
        "verboseTraining = 1 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "mainTrainingEarlyStoppingDelta = 0.005 #@param {type:\"number\"}\n",
        "mainTrainingEarlyStoppinPatience = 15 #@param {type:\"integer\"}\n",
        "fineTuningEarlyStoppingDelta = 0.001 #@param {type:\"number\"}\n",
        "fineTuningEarlyStoppinPatience = 15 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "trainingPath = rootPath + 'trainingPhaseGroupModel/'\n",
        "\n",
        "\n",
        "dataToLog  = [\"AUG : \"+ str(useDataAugmentation)+\"\\n\",\n",
        "                     \"TR_AUG : \" + str(NUMBER_OF_TRAINING_AUG)+\"\\n\",\n",
        "                     \"VAL_AUG : \" + str(NUMBER_OF_VALIDATION_AUG)+\"\\n\",\n",
        "                     \"randomSeed : \" + str(randomSeed)]\n",
        "if \"useCustomLoad\" in locals() and useCustomLoad == True:\n",
        "  dataToLog.append(\"Custom_load : \" + str(useCustomLoad)+\"\\n\")\n",
        "  dataToLog.append(\"Custom_ratio : \" + str(customRatio) + \"\\n\")  \n",
        "        \n",
        "train(tpu_address,\n",
        "  trainingPath,\n",
        "  models, \n",
        "  verboseTraining = 1,\n",
        "  mainTrainingEarlyStoppingDelta = mainTrainingEarlyStoppingDelta,\n",
        "  mainTrainingEarlyStoppinPatience = mainTrainingEarlyStoppinPatience,\n",
        "  fineTuningEarlyStoppingDelta = fineTuningEarlyStoppingDelta,\n",
        "  fineTuningEarlyStoppinPatience = fineTuningEarlyStoppinPatience,\n",
        "  stringToLog = ''.join(dataToLog),\n",
        "  lastSession = lastSession)\n",
        "  \n",
        "    \n",
        "print(\"Fine training\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgZyEOY902qN",
        "colab_type": "code",
        "outputId": "dc0656f1-cd50-4108-dbf1-cd26e366cc69",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "#@title group test\n",
        "testDir = rootPath + 'data/test/'\n",
        "numFilePath = testDir + 'numTestData'\n",
        "\n",
        "with open(numFilePath, 'r') as file:\n",
        "  numberOfTestImages = int(file.readline())\n",
        "  \n",
        "width = 48\n",
        "height = 48\n",
        "  \n",
        "testImages = np.memmap(testDir + \"testData\", dtype=np.uint8,\n",
        "                mode='r', shape=(numberOfTestImages,width,height,3))\n",
        "\n",
        "if tfVersion()['MAJOR'] == 1 and tfVersion()['MINOR'] <= 13:\n",
        "  if len(testImages) % 8 != 0:\n",
        "    testData = np.empty((len(testImages) + (8-len(testImages) % 8), width, height, 3), dtype=np.float32)\n",
        "  else:\n",
        "    testData = np.empty((len(testImages), width, height, 3), dtype=np.float32)\n",
        "else:\n",
        "  testData = np.empty((len(testImages), width, height, 3), dtype=np.float32)\n",
        "\n",
        "count = 0\n",
        "for image in testImages:\n",
        "  testData[count] = image / 255.0\n",
        "  count += 1\n",
        "\n",
        "if tfVersion()['MAJOR'] == 1 and tfVersion()['MINOR'] <= 13:\n",
        "  if len(testImages) % 8 != 0:\n",
        "    for index in range(len(testData),len(testImages) + (8-len(testImages) % 8)):\n",
        "      testData[index] = testData[-1]\n",
        "  \n",
        "print(len(testData))\n",
        "\n",
        "predictions = testModel(tpu_address,\n",
        "                         [BigResNet],\n",
        "                         [\n",
        "                          ['/gdrive/My Drive/DatasetSegnaliStradali/GTSRB/trainingPhaseGroupModel/BigResNetGroupDetection_2019_6_22_15_51_28/0.006/FineTuning/0.00075/weights/epoch_15_valLoss_0.0379.hdf5',\n",
        "                           '/gdrive/My Drive/DatasetSegnaliStradali/GTSRB/trainingPhaseGroupModel/BigResNetGroupDetection_2019_6_22_22_7_56/0.001/FineTuning/0.0005/weights/epoch_75_valLoss_0.0387.hdf5',\n",
        "                           '/gdrive/My Drive/DatasetSegnaliStradali/GTSRB/trainingPhaseGroupModel/BigResNetGroupDetection_2019_6_23_11_56_34/0.001/FineTuning/6.25e-05/weights/epoch_05_valLoss_0.0201.hdf5']\n",
        "                         ],\n",
        "                         testData\n",
        "                       )  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12630\n",
            "Test model 0 weights 0\n",
            "25/25 [==============================] - 57s 2s/step\n",
            "25/25 [==============================] - 57s 2s/step\n",
            "Test model 0 weights 1\n",
            "25/25 [==============================] - 57s 2s/step\n",
            "25/25 [==============================] - 57s 2s/step\n",
            "Test model 0 weights 2\n",
            "25/25 [==============================] - 74s 3s/step\n",
            "25/25 [==============================] - 74s 3s/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EaMv254NxQm",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "83be6902-33b4-484e-d5c2-b5a1507c2550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "#@title group evaluation\n",
        "\n",
        "labels = np.load(testDir + \"labels.npy\")\n",
        "groupLabels = np.zeros((len(labels)), dtype=\"int32\")\n",
        "\n",
        "for i in range(len(labels)):\n",
        "  groupLabels[i] = labelsInfo[labels[i]][0]\n",
        "\n",
        "predictionEvaluation(predictions, groupLabels[:numberOfTestImages], [0,1,2], topN = 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOP 1 corrette 12619 su 12630 ( 11 ) 99.91290577988914 %\n",
            "TOP 2 corrette 12629 su 12630 ( 1 ) 99.9920823436263 %\n",
            "TOP 3 corrette 12630 su 12630 ( 0 ) 100.0 %\n",
            "TOP 4 corrette 12630 su 12630 ( 0 ) 100.0 %\n",
            "TOP 5 corrette 12630 su 12630 ( 0 ) 100.0 %\n",
            "\n",
            "TOP1 distribuzione:\n",
            "{0: 5669, 1: 2790, 2: 1765, 3: 2035, 4: 360}\n",
            "0 5669 1\n",
            "\u001b[0m\u001b[32mClasse \u001b[1m0\u001b[0m\u001b[32m] corrette 5669 su 5670 (1) \u001b[1m99.98236331569666\u001b[0m\u001b[32m%\n",
            "1 2790 0\n",
            "\u001b[0m\u001b[32mClasse \u001b[1m1\u001b[0m\u001b[32m] corrette 2790 su 2790 (0) \u001b[1m100.0\u001b[0m\u001b[32m%\n",
            "2 1765 5\n",
            "\u001b[0m\u001b[32mClasse \u001b[1m2\u001b[0m\u001b[32m] corrette 1765 su 1770 (5) \u001b[1m99.71751412429379\u001b[0m\u001b[32m%\n",
            "3 2035 5\n",
            "\u001b[0m\u001b[32mClasse \u001b[1m3\u001b[0m\u001b[32m] corrette 2035 su 2040 (5) \u001b[1m99.75490196078431\u001b[0m\u001b[32m%\n",
            "4 360 0\n",
            "\u001b[0m\u001b[32mClasse \u001b[1m4\u001b[0m\u001b[32m] corrette 360 su 360 (0) \u001b[1m100.0\u001b[0m\u001b[32m%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Emn2Pc0G5G",
        "colab_type": "text"
      },
      "source": [
        "MODELLO 0 E 2\n",
        "\n",
        "TOP 1 corrette 12622 su 12630 ( 8 ) 99.93665874901029 %\n",
        "TOP 2 corrette 12627 su 12630 ( 3 ) 99.97624703087887 %\n",
        "TOP 3 corrette 12630 su 12630 ( 0 ) 100.0 %\n",
        "TOP 4 corrette 12630 su 12630 ( 0 ) 100.0 %\n",
        "TOP 5 corrette 12630 su 12630 ( 0 ) 100.0 %\n",
        "\n",
        "TOP1 distribuzione:\n",
        "{0: 5669, 1: 2790, 2: 1764, 3: 2040, 4: 359}\n",
        "0 5669 1\n",
        "Classe 0] corrette 5669 su 5670 (1) 99.98236331569666%\n",
        "1 2790 0\n",
        "Classe 1] corrette 2790 su 2790 (0) 100.0%\n",
        "2 1764 6\n",
        "Classe 2] corrette 1764 su 1770 (6) 99.66101694915255%\n",
        "3 2040 0\n",
        "Classe 3] corrette 2040 su 2040 (0) 100.0%\n",
        "4 359 1\n",
        "Classe 4] corrette 359 su 360 (1) 99.72222222222223%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfFyOP13hnBs",
        "colab_type": "text"
      },
      "source": [
        "# ***Segue l'allenamento dei singoli modelli***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1DCvK-Ehp5E",
        "colab_type": "code",
        "outputId": "6a849969-513d-49d5-8375-3ef0f447b0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        }
      },
      "source": [
        "#@title Caricamento dei dati { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "if 'trainingData' in locals():\n",
        "  del trainingData\n",
        "  del trainingLabels\n",
        "if 'validationData' in locals():  \n",
        "  del validationData\n",
        "  del validationLabels\n",
        "\n",
        "trainingDir = rootPath + 'data/training/'\n",
        "validationDir = rootPath + 'data/validation/'\n",
        "\n",
        "groupInfo = {\n",
        "    0 : 'prohibitory',\n",
        "    1 : 'danger',\n",
        "    2 : 'mandatory',\n",
        "    3 : 'others',\n",
        "    4 : 'limitsEnd'\n",
        "}\n",
        "\n",
        "labelsInfo = {\n",
        "    # labelNumber : (group,labelInsideGroup, description)\n",
        "    0 : (0,0, '20 km/h'),\n",
        "    1 : (0,1, '30 km/h'),\n",
        "    2 : (0,2, '50 km/h'),\n",
        "    3 : (0,3, '60 km/h'),\n",
        "    4 : (0,4, '70 km/h'),\n",
        "    5 : (0,5, '80 km/h'),\n",
        "    6 : (4,0, '80 km/h end'),\n",
        "    7 : (0,6, '100 km/h'),\n",
        "    8 : (0,7, '120 km/h'),\n",
        "    9 : (0,8, 'No overtaking'),\n",
        "    10 : (0,9, 'No overtaking for tracks'),\n",
        "    11 : (1,0, 'Crossroad with secondary way'),\n",
        "    12 : (3,0, 'Main road'),\n",
        "    13 : (3,1,  'Give way'),\n",
        "    14 : (3,2, 'Stop'),\n",
        "    15 : (0,10,  'Road up'),\n",
        "    16 : (0,11, 'Road up for track'),\n",
        "    17 : (3,3,  'Brock'),\n",
        "    18 : (1,1, 'Other dangerous'),\n",
        "    19 : (1,2, 'Turn left'),\n",
        "    20 : (1,3, 'Turn right'),\n",
        "    21 : (1,4, 'Winding road'),\n",
        "    22 : (1,5, 'Hollow road'),\n",
        "    23 : (1,6, 'Slippery road'),\n",
        "    24 : (1,7, 'Narrowing road'),\n",
        "    25 : (1,8, 'Roadwork'),\n",
        "    26 : (1,9, 'Traffic light'),\n",
        "    27 : (1,10, 'Pedestrian'),\n",
        "    28 : (1,11, 'Children'),\n",
        "    29 : (1,12, 'Bike'),\n",
        "    30 : (1,13, 'Snow'),\n",
        "    31 : (1,14, 'Deer'),\n",
        "    32 : (4,1, 'End of the limits'),\n",
        "    33 : (2,0, 'Only right'),\n",
        "    34 : (2,1, 'Only left'),\n",
        "    35 : (2,2, 'Only straight'),\n",
        "    36 : (2,3, 'Only straight and right'),\n",
        "    37 : (2,4, 'Only straight and left'),\n",
        "    38 : (2,5, 'Take right'),\n",
        "    39 : (2,6, 'Take left'),\n",
        "    40 : (2,7, 'Circle crossroad'),\n",
        "    41 : (4,2, 'End of overtaking limit'),\n",
        "    42 : (4,3, 'End of overtaking limit for track')\n",
        "}\n",
        "\n",
        "#@markdown Seed per la genezione di nuove immagini e la scelta casuale per custom\n",
        "#@markdown load\n",
        "randomSeed = 4502032#@param{type:'integer'}\n",
        "\n",
        "#riproducibilità dei training\n",
        "resetSeed(15 + randomSeed)\n",
        "\n",
        "#@markdown ---\n",
        "loadG0 = False #@param {type:\"boolean\"}\n",
        "loadG1 = False #@param {type:\"boolean\"}\n",
        "loadG2 = False #@param {type:\"boolean\"}\n",
        "loadG3 = False #@param {type:\"boolean\"}\n",
        "loadG4 = True #@param {type:\"boolean\"}\n",
        "\n",
        "loadGroup = [loadG0, loadG1, loadG2, loadG3, loadG4]\n",
        "#@markdown ---\n",
        "useDataAugmentation = True #@param {type:\"boolean\"}\n",
        "#@markdown Se selezionato ignora i valori assegnati ai gruppi sottostanti e usa \n",
        "#@markdown un valore perogni label invece che ogni gruppo. Sono definiti nel codice\n",
        "usePerLabelDataAug = True #@param {type:\"boolean\"}\n",
        "#Numero di immagini da generare per ogni immagine originale\n",
        "NUMBER_OF_TRAINING_AUG_G0 = 6 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "NUMBER_OF_VALIDATION_AUG_G0 = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "NUMBER_OF_TRAINING_AUG_G1 = 8 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "NUMBER_OF_VALIDATION_AUG_G1 = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "NUMBER_OF_TRAINING_AUG_G2 = 12 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "NUMBER_OF_VALIDATION_AUG_G2 = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "NUMBER_OF_TRAINING_AUG_G3 = 12 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "NUMBER_OF_VALIDATION_AUG_G3 = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "NUMBER_OF_TRAINING_AUG_G4 = 16 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "NUMBER_OF_VALIDATION_AUG_G4 = 2 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "\n",
        "# da modificare se si vuole alterare la distribuzione delle classi\n",
        "NUMBER_AUG_BY_LABEL = { \n",
        "                0 : ( 20 , 2 ), # group 0  label inside group 0\n",
        "                1 : ( 1 , 2 ), # group 0  label inside group 1\n",
        "                2 : ( 1 , 2 ), # group 0  label inside group 2\n",
        "                3 : ( 2 , 2 ), # group 0  label inside group 3\n",
        "                4 : ( 1 , 2 ), # group 0  label inside group 4\n",
        "                5 : ( 1 , 2 ), # group 0  label inside group 5\n",
        "                6 : ( 8 , 4 ), # group 4  label inside group 0\n",
        "                7 : ( 2 , 2 ), # group 0  label inside group 6\n",
        "                8 : ( 2 , 2 ), # group 0  label inside group 7\n",
        "                9 : ( 2 , 2 ), # group 0  label inside group 8\n",
        "                10 : ( 1 , 2 ), # group 0  label inside group 9\n",
        "                11 : ( 2 , 2 ), # group 1  label inside group 0\n",
        "                12 : ( 2 , 2 ), # group 3  label inside group 0\n",
        "                13 : ( 2 , 2 ), # group 3  label inside group 1\n",
        "                14 : ( 8 , 2 ), # group 3  label inside group 2\n",
        "                15 : ( 6 , 2 ), # group 0  label inside group 10\n",
        "                16 : ( 8 , 2 ), # group 0  label inside group 11\n",
        "                17 : ( 5 , 2 ), # group 3  label inside group 3\n",
        "                18 : ( 2 , 2 ), # group 1  label inside group 1\n",
        "                19 : ( 13 , 2 ), # group 1  label inside group 2\n",
        "                20 : ( 9 , 2 ), # group 1  label inside group 3\n",
        "                21 : ( 10 , 2 ), # group 1  label inside group 4\n",
        "                22 : ( 8 , 2 ), # group 1  label inside group 5\n",
        "                23 : ( 6 , 2 ), # group 1  label inside group 6\n",
        "                24 : ( 9 , 2 ), # group 1  label inside group 7\n",
        "                25 : ( 1 , 2 ), # group 1  label inside group 8\n",
        "                26 : ( 5 , 2 ), # group 1  label inside group 9\n",
        "                27 : ( 10 , 2 ), # group 1  label inside group 10\n",
        "                28 : ( 6 , 2 ), # group 1  label inside group 11\n",
        "                29 : ( 10 , 2 ), # group 1  label inside group 12\n",
        "                30 : ( 7 , 2 ), # group 1  label inside group 13\n",
        "                31 : ( 3 , 2 ), # group 1  label inside group 14\n",
        "                32 : ( 8 , 4 ), # group 4  label inside group 1\n",
        "                33 : ( 7 , 3 ), # group 2  label inside group 0\n",
        "                34 : ( 12 , 4 ), # group 2  label inside group 1\n",
        "                35 : ( 4 , 3 ), # group 2  label inside group 2\n",
        "                36 : ( 12 , 4 ), # group 2  label inside group 3\n",
        "                37 : (21 , 7 ), # group 2  label inside group 4\n",
        "                38 : ( 2 , 3 ), # group 2  label inside group 5\n",
        "                39 : ( 13 , 5 ), # group 2  label inside group 6\n",
        "                40 : ( 13, 5 ), # group 2  label inside group 7\n",
        "                41 : ( 8 , 4 ), # group 4  label inside group 2\n",
        "                42 : ( 8 , 4 ), # group 4  label inside group 3\n",
        "              }\n",
        "\n",
        "NUMBER_AUG_BY_GROUP = [\n",
        "        (NUMBER_OF_TRAINING_AUG_G0, NUMBER_OF_VALIDATION_AUG_G0),\n",
        "        (NUMBER_OF_TRAINING_AUG_G1, NUMBER_OF_VALIDATION_AUG_G1),\n",
        "        (NUMBER_OF_TRAINING_AUG_G2, NUMBER_OF_VALIDATION_AUG_G2),\n",
        "        (NUMBER_OF_TRAINING_AUG_G3, NUMBER_OF_VALIDATION_AUG_G3),\n",
        "        (NUMBER_OF_TRAINING_AUG_G4, NUMBER_OF_VALIDATION_AUG_G4)\n",
        "        ]\n",
        "                  \n",
        "NUMBER_OF_TRAINING_AUG = [0 for i in range(43)]\n",
        "NUMBER_OF_VALIDATION_AUG = [0 for i in range(43)]\n",
        "\n",
        "if useDataAugmentation == True:\n",
        "  for key in labelsInfo.keys():\n",
        "    if usePerLabelDataAug == True:\n",
        "      NUMBER_OF_TRAINING_AUG[key] = NUMBER_AUG_BY_LABEL[key][0]\n",
        "      NUMBER_OF_VALIDATION_AUG[key] = NUMBER_AUG_BY_LABEL[key][1]\n",
        "    else:\n",
        "      NUMBER_OF_TRAINING_AUG[key] = NUMBER_AUG_BY_GROUP[labelsInfo[key]][0]\n",
        "      NUMBER_OF_VALIDATION_AUG[key] = NUMBER_AUG_BY_GROUP[labelsInfo[key]][1]\n",
        "\n",
        "print(\"Tr AUG : \", NUMBER_OF_TRAINING_AUG)\n",
        "print(\"Val AUG : \", NUMBER_OF_VALIDATION_AUG)\n",
        "\n",
        "# parametri generatore training per gruppo\n",
        "brightness_range_training = [\n",
        "    (0.25,0.6), (0.25,0.6), (0.25,0.6), (0.25,0.6), (0.2,0.7)\n",
        "]\n",
        "rotation_range_training = [25, 25, 25, 25,35]\n",
        "width_shift_range_training=[8,8,8,8,8]\n",
        "height_shift_range_training=[8,8,8,8,8]\n",
        "shear_range_training=[15,15,15,15,15]\n",
        "zoom_range_training=[(0.4,1.15),(0.4,1.15),(0.4,1.15),(0.4,1.15),(0.3,1.15)]\n",
        "channel_shift_range_training=[0.13,0.13,0.13,0.13,0.10]\n",
        "\n",
        "# parametri generatore validation per gruppo\n",
        "brightness_range_validation = [\n",
        "    (0.25,0.6), (0.25,0.6), (0.25,0.6), (0.25,0.6), (0.3,0.6)\n",
        "]\n",
        "rotation_range_validation = [25, 25, 25, 25, 25]\n",
        "width_shift_range_validation=[8,8,8,8,8]\n",
        "height_shift_range_validation=[8,8,8,8,8]\n",
        "shear_range_validation=[15,15,15,15,15]\n",
        "zoom_range_validation=[(0.4,1.15),(0.4,1.15),(0.4,1.15),(0.4,1.15),(0.4,1.15)]\n",
        "channel_shift_range_validation=[0.13,0.13,0.13,0.13,0.15]\n",
        "\n",
        "generatorTraining = []\n",
        "generatorValidation= []\n",
        "\n",
        "for group in range(len(groupInfo.keys())):\n",
        "  #generatore utilizzato per le immagni di training\n",
        "  generatorTraining.append(keras.preprocessing.image.ImageDataGenerator(\n",
        "      brightness_range = brightness_range_training[group],\n",
        "      rotation_range=rotation_range_training[group],\n",
        "      width_shift_range=width_shift_range_training[group],\n",
        "      height_shift_range=height_shift_range_training[group],\n",
        "      shear_range=shear_range_training[group],\n",
        "      zoom_range=zoom_range_training[group],\n",
        "      channel_shift_range=channel_shift_range_training[group]))\n",
        "\n",
        "  #generatore utilizzato per le immagini di validation\n",
        "  generatorValidation.append(keras.preprocessing.image.ImageDataGenerator(\n",
        "      brightness_range = brightness_range_validation[group],\n",
        "      rotation_range=rotation_range_validation[group],\n",
        "      width_shift_range=width_shift_range_validation[group],\n",
        "      height_shift_range=height_shift_range_validation[group],\n",
        "      shear_range=shear_range_validation[group],\n",
        "      zoom_range=zoom_range_validation[group],\n",
        "      channel_shift_range=channel_shift_range_validation[group]))\n",
        "\n",
        "# numero di immagini originali disponibili per ogni classe\n",
        "trainingClassCount = {}\n",
        "#numero di immagini di training totali suddivide per gruppo\n",
        "totalTrainingCount = [0 for group in groupInfo.keys()]\n",
        "loadLabel = [False for i in range(43)]\n",
        "# recupero il numero di immagini di training disponibili per ogni classe\n",
        "files = list(filter(lambda fn : fn.startswith('resized'), os.listdir(trainingDir)))\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  numFilePath = trainingDir + 'num' + str(classLabel)\n",
        "  with open(numFilePath, 'r') as file:\n",
        "    originalNum = int(file.readline())\n",
        "    trainingClassCount[classLabel] = originalNum\n",
        "    groupIndex = labelsInfo[classLabel][0]\n",
        "    if loadGroup[groupIndex] == True:\n",
        "      loadLabel[classLabel] = True\n",
        "      totalTrainingCount[groupIndex] += originalNum * (NUMBER_OF_TRAINING_AUG[classLabel] + 1)\n",
        "\n",
        "# se uso le TPU in tf 1.13 il numero di immagini deve essere divisibile per 8\n",
        "trainingPadEnd = [False for group in groupInfo.keys()]\n",
        "trainingToPad = [0 for group in groupInfo.keys()]\n",
        "if useTPU == True and tfVersion()['MAJOR'] == 1 and tfVersion()['MAJOR'] <= 13:\n",
        "  for groupIndex in range(len(groupInfo.keys())):\n",
        "    if loadGroup[groupIndex] and totalTrainingCount[groupIndex] % 8 != 0:\n",
        "      # se uso le TPU la lunghezza dei dati deve essere divisibile per 8\n",
        "      trainingToPad[groupIndex] = 8 - (totalTrainingCount[groupIndex]  % 8)\n",
        "      totalTrainingCount[groupIndex] = totalTrainingCount[groupIndex]  + (trainingToPad[groupIndex])\n",
        "      trainingPadEnd[groupIndex] = True\n",
        "  \n",
        "#preparo gli array che contengono le img di training\n",
        "trainingData = []\n",
        "trainingLabels = []\n",
        "originalTrainingLabels = []\n",
        "\n",
        "for groupIndex in range(len(groupInfo.keys())):\n",
        "  trainingData.append(np.empty((totalTrainingCount[groupIndex], width, height, 3), dtype=\"float32\"))\n",
        "  trainingLabels.append( np.empty((totalTrainingCount[groupIndex]), dtype='int32'))\n",
        "  originalTrainingLabels.append( np.empty((totalTrainingCount[groupIndex]), dtype='int32'))\n",
        "\n",
        "# numero di immagini originali disponibili per ogni classe\n",
        "validationClassCount = {}\n",
        "#leggo quante img ci sono per ogni class di validation\n",
        "totalValidationCount = [0 for group in groupInfo.keys()]\n",
        "\n",
        "\n",
        "# recupero il numero di immagini di training disponibili per ogni classe\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  numFilePath = validationDir + 'num' + str(classLabel)\n",
        "  with open(numFilePath, 'r') as file:\n",
        "    numFile = int(file.readline())\n",
        "    validationClassCount[classLabel] = numFile\n",
        "    groupIndex = labelsInfo[classLabel][0]\n",
        "    if loadGroup[groupIndex] == True:\n",
        "      totalValidationCount[groupIndex] += numFile * (NUMBER_OF_VALIDATION_AUG[classLabel]+ 1)\n",
        "\n",
        "# se uso le TPU in tf 1.13 il numero di immagini deve essere divisibile per 8\n",
        "validationPadEnd = [False for group in groupInfo.keys()]\n",
        "validationToPad = [0 for group in groupInfo.keys()]\n",
        "if tfVersion()['MAJOR'] == 1 and tfVersion()['MAJOR'] <= 13:\n",
        "  for groupIndex in range(len(groupInfo.keys())):\n",
        "    if totalValidationCount[groupIndex] % 8 != 0:\n",
        "      validationToPad[groupIndex] = 8 - (totalValidationCount[groupIndex]  % 8)\n",
        "      totalValidationCount[groupIndex] = totalValidationCount[groupIndex]  + (validationToPad[groupIndex])\n",
        "      validationPadEnd[groupIndex] = True\n",
        "  \n",
        "#preparo gli array che contengono le img di validation\n",
        "validationData = []\n",
        "validationLabels = []\n",
        "originalValidationLabels = []\n",
        "for groupIndex in range(len(groupInfo.keys())):\n",
        "  validationData.append(np.empty((totalValidationCount[groupIndex], width, height, 3), dtype=\"float32\"))\n",
        "  validationLabels.append( np.empty((totalValidationCount[groupIndex]), dtype='int32'))\n",
        "  originalValidationLabels.append( np.empty((totalValidationCount[groupIndex]), dtype='int32'))\n",
        "\n",
        "#numero di immagini elaborate per gruppo\n",
        "validationCount = [0 for group in groupInfo.keys()]\n",
        "trainingCount = [0 for group in groupInfo.keys()]\n",
        "loadedClass = 0\n",
        "\n",
        "#caricamento dati\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  if loadLabel[classLabel] == True:\n",
        "    #carico le img di training originali\n",
        "    trainingImages = np.memmap(trainingDir + fileName, dtype=np.uint8,\n",
        "                mode='r', shape=(trainingClassCount[classLabel],width,height,3))\n",
        "\n",
        "    imagesToLoad =trainingClassCount[classLabel]\n",
        "    group = labelsInfo[classLabel][0]\n",
        "    indices = generateIndices(imagesToLoad, trainingClassCount[classLabel])\n",
        "    for index in indices:\n",
        "      trainingData[group][trainingCount[group]]  = trainingImages[index]/255.0\n",
        "      trainingLabels[group][trainingCount[group]] = labelsInfo[classLabel][1]\n",
        "      originalTrainingLabels[group][trainingCount[group]] = classLabel\n",
        "      trainingCount[group] += 1\n",
        "    #carico le immagini di validation\n",
        "    validationImages = np.memmap(validationDir + fileName, dtype=np.uint8,\n",
        "                mode='r', shape=(validationClassCount[classLabel],width,height,3))\n",
        "\n",
        "    for img in validationImages:\n",
        "      validationData[group][validationCount[group]] = img/255.0\n",
        "      validationLabels[group][validationCount[group]] = labelsInfo[classLabel][1]\n",
        "      originalValidationLabels[group][validationCount[group]] = classLabel\n",
        "      validationCount[group] += 1\n",
        "\n",
        "  loadedClass += 1\n",
        "  if (loadedClass) % 5 == 0 or loadedClass == len(files):\n",
        "    print('Caricamento file ', loadedClass, 'su', len(files))\n",
        "\n",
        "# fine for caricamento classi\n",
        "\n",
        "# per ogni immagine genero delle nuove immagini con trasformazioni casuali\n",
        "print(\"\\nGenero le immagini aggiuntive necessarie:\\n\")\n",
        "resetSeed(48560  + randomSeed)\n",
        "for group in range(len(groupInfo.keys())):\n",
        "  for imageIndex in range(0, trainingCount[group]):\n",
        "    #print(group, imageIndex, originalTrainingLabels[group][imageIndex], NUMBER_OF_TRAINING_AUG[originalTrainingLabels[group][imageIndex]])    \n",
        "    for augIndex in range(0, NUMBER_OF_TRAINING_AUG[originalTrainingLabels[group][imageIndex]]):\n",
        "      trainingData[group][trainingCount[group]] = generateRandomImage(generatorTraining[group], trainingData[group][imageIndex])/255.0\n",
        "      trainingLabels[group][trainingCount[group]] = trainingLabels[group][imageIndex]\n",
        "      trainingCount[group] += 1\n",
        "  print(\"Gruppo\", group, \"training terminato\")\n",
        "\n",
        "resetSeed(-420360  + randomSeed)\n",
        "for group in range(len(groupInfo.keys())):\n",
        "  for imageIndex in range(0, validationCount[group]):\n",
        "    for augIndex in range(0, NUMBER_OF_VALIDATION_AUG[originalValidationLabels[group][imageIndex]]):\n",
        "      validationData[group][validationCount[group]] = generateRandomImage(generatorValidation[group], validationData[group][imageIndex])/255.0\n",
        "      validationLabels[group][validationCount[group]] = validationLabels[group][imageIndex]\n",
        "      validationCount[group] += 1\n",
        "  print(\"Gruppo\", group, \"validation terminato\")\n",
        "\n",
        "# Se necessario copio l'ultima immagine per rendere la lunghezza divisibile per 8\n",
        "for group in range(len(groupInfo.keys())):       \n",
        "  if trainingPadEnd[group] == True:\n",
        "    for index in range(1, trainingToPad[group] + 1):\n",
        "      trainingData[group][-index] = trainingData[group][len(trainingData[group]) - (trainingToPad[group] + 1)]\n",
        "      trainingLabels[group][-index] = trainingLabels[group][len(trainingLabels[group]) - (trainingToPad[group] + 1)]\n",
        "    \n",
        "  if validationPadEnd[group] == True:\n",
        "    for index in range(1, validationToPad[group] + 1):\n",
        "      validationData[group][-index] = validationData[group][len(validationData[group]) - (validationToPad[group] + 1)]\n",
        "      validationLabels[group][-index] = validationLabels[group][len(validationLabels[group]) - (validationToPad[group] + 1)]\n",
        "    \n",
        "print(\"Fine padding\")      \n",
        "\n",
        "# statistiche sulla distribuzione delle labels      \n",
        "\n",
        "for index in range(5):\n",
        "  if loadGroup[index] == True:\n",
        "    plt.figure(figsize=(10,5))\n",
        "    maxLabel = max(trainingLabels[index])+1\n",
        "    if maxLabel > 42:\n",
        "      raise RuntimeError(\"C'è un errore grave nel codice, ricontrolla.\")\n",
        "    plt.hist(trainingLabels[index], alpha = 0.5, bins=maxLabel, label = \"training\")\n",
        "    plt.hist(validationLabels[index], alpha = 0.5, bins=maxLabel, label = \"validation\")\n",
        "    plt.xticks(np.arange(0, maxLabel, 1))\n",
        "    plt.xlim(left=0, right=maxLabel)\n",
        "    plt.title('Group' + str(index))\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tr AUG :  [20, 1, 1, 2, 1, 1, 8, 2, 2, 2, 1, 2, 2, 2, 8, 6, 8, 5, 2, 13, 9, 10, 8, 6, 9, 1, 5, 10, 6, 10, 7, 3, 8, 7, 12, 4, 12, 21, 2, 13, 13, 8, 8]\n",
            "Val AUG :  [2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 3, 4, 3, 4, 7, 3, 5, 5, 4, 4]\n",
            "Caricamento file  5 su 43\n",
            "Caricamento file  10 su 43\n",
            "Caricamento file  15 su 43\n",
            "Caricamento file  20 su 43\n",
            "Caricamento file  25 su 43\n",
            "Caricamento file  30 su 43\n",
            "Caricamento file  35 su 43\n",
            "Caricamento file  40 su 43\n",
            "Caricamento file  43 su 43\n",
            "\n",
            "Genero le immagini aggiuntive necessarie:\n",
            "\n",
            "Gruppo 0 training terminato\n",
            "Gruppo 1 training terminato\n",
            "Gruppo 2 training terminato\n",
            "Gruppo 3 training terminato\n",
            "Gruppo 4 training terminato\n",
            "Gruppo 0 validation terminato\n",
            "Gruppo 1 validation terminato\n",
            "Gruppo 2 validation terminato\n",
            "Gruppo 3 validation terminato\n",
            "Gruppo 4 validation terminato\n",
            "Fine padding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAE/CAYAAADhW39vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwQsaZCgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fii6NWrR446X",
        "colab_type": "code",
        "outputId": "835e0d15-2d07-4809-ae04-442b0a537a55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "#@title Esempio immagini { vertical-output: true, display-mode: \"form\" }\n",
        "numImages = 10 #@param {type:\"integer\"}\n",
        "offset = 562 #@param {type:\"integer\"}\n",
        "group = 4 #@param {type:\"integer\"}\n",
        "\n",
        "figure = plt.figure(figsize = (30,30),constrained_layout=False)\n",
        "gs = figure.add_gridspec(nrows=2, ncols=numImages, right = 0.4, left = 0.1,top = 0.2, bottom = 0.1)\n",
        "count = 0\n",
        "for i in range(numImages):\n",
        "  ax = figure.add_subplot(gs[0,i])\n",
        "  ax.imshow(validationData[group][offset + count])\n",
        "  ax.axis('off')\n",
        "  ax.grid(False)\n",
        "  count += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqoAAABZCAYAAAD2HAb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+X/1a7hhNoPqrgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 2160x2160 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmzn1-GBY09f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model1(numberOfLabels): \n",
        "  def closure():\n",
        "    inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "    layer = buildConvBlock(inputs, layers = 3, size = 128, kernelSize = 3, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "    layer = buildResNetBlock(layer, 64, 64, 256)\n",
        "    layer = buildResNetBlock(layer, 64, 64, 256)\n",
        "    layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "    layer = buildResNetBlock(layer, 96, 96, 384)\n",
        "    layer = buildResNetBlock(layer, 96, 96, 384)\n",
        "    layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "    layer = buildResNetBlock(layer, 128, 128, 512)\n",
        "    layer = buildResNetBlock(layer, 192, 192, 768)\n",
        "    layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "    layer = buildResNetBlock(layer, 256, 256, 1024)\n",
        "    outputs = buildGlobalSoftmax(layer, numberOfLabels = numberOfLabels, kernelSize=3, denseDepth = 2, denseSize=128, dropout = 0.35)\n",
        "    return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return closure\n",
        "\n",
        "#non funciona in v1.14\n",
        "def model2(numberOfLabels): \n",
        "  def closure():\n",
        "    inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "    layer = buildConvBlock(inputs, layers = 3, size = 128, kernelSize = 3, poolSize = 2, poolStrides = 2, flatten = False, useBatch = True)\n",
        "\n",
        "    layer = buildResidualInceptionBlockV4(layer, residualLayer = layer, size1x1 = 16, size3x3 = 64, size5x5 = 8, sizeMaxPool = 16, dimensionalityReduction = 0)\n",
        "    layer = buildResidualInceptionBlockV4(layer, residualLayer = layer, size1x1 = 16, size3x3 = 64, size5x5 = 8, sizeMaxPool = 16, dimensionalityReduction = 0)\n",
        "    layer = buildResidualInceptionBlockV4(layer, residualLayer = layer, size1x1 = 16, size3x3 = 64, size5x5 = 8, sizeMaxPool = 16, dimensionalityReduction = 0) \n",
        "    layer = buildMaxPoolLayer(layer, poolSize = 2, poolStrides = 2, flattenOutput = False)\n",
        "    layer = buildResidualInceptionBlockV4(layer, residualLayer = layer, size1x1 = 32, size3x3 = 128, size5x5 = 16, sizeMaxPool = 32, dimensionalityReduction = 0)\n",
        "    layer = buildResidualInceptionBlockV4(layer, residualLayer = layer, size1x1 = 32, size3x3 = 128, size5x5 = 16, sizeMaxPool = 32, dimensionalityReduction = 0)\n",
        "    layer = buildResidualInceptionBlockV4(layer, residualLayer = layer, size1x1 = 32, size3x3 = 128, size5x5 = 16, sizeMaxPool = 32, dimensionalityReduction = 0)\n",
        "    layer = buildMaxPoolLayer(layer, poolSize = 2, poolStrides = 2, flattenOutput = False)\n",
        "    layer = buildResidualInceptionBlockV4(layer, residualLayer = layer, size1x1 = 64, size3x3 = 256, size5x5 = 32, sizeMaxPool = 64, dimensionalityReduction = 0)\n",
        "    layer = buildResidualInceptionBlockV4(layer, residualLayer = layer, size1x1 = 64, size3x3 = 256, size5x5 = 32, sizeMaxPool = 64, dimensionalityReduction = 0) \n",
        "    layer = buildResidualInceptionBlockV4(layer, residualLayer = layer, size1x1 = 64, size3x3 = 256, size5x5 = 32, sizeMaxPool = 64, dimensionalityReduction = 0) \n",
        "\n",
        "    outputs = buildGlobalSoftmax(layer, kernelSize=3, reductionLayerSize = numberOfLabels, numberOfLabels =  numberOfLabels, denseDepth = 2,  denseSize=128, dropout = 0.35)\n",
        "    return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return closure\n",
        "\n",
        "def model5(numberOfLabels): \n",
        "  def closure():\n",
        "    inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "    layer = buildConvBlock(inputs, layers = 3, size = 128, kernelSize = 3, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "    layer = buildResNetBlock(layer, 64, 64, 256)\n",
        "    layer = buildResNetBlock(layer, 64, 64, 256)\n",
        "    layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "    layer = buildResNetBlock(layer, 96, 96, 384)\n",
        "    layer = buildResNetBlock(layer, 96, 96, 384)\n",
        "    layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "    layer = buildResNetBlock(layer, 128, 128, 512)\n",
        "    layer = buildResNetBlock(layer, 192, 192, 768)\n",
        "    layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "    layer = buildResNetBlock(layer, 256, 256, 1024)\n",
        "    layer = buildResNetBlock(layer, 256, 256, 1024)\n",
        "    outputs = buildGlobalSoftmax(layer, reductionLayerSize=256, numberOfLabels = numberOfLabels, kernelSize=3, denseDepth = 2, denseSize=128, dropout = 0.35)\n",
        "    return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return closure\n",
        "\n",
        "def model6(numberOfLabels): \n",
        "  def closure():\n",
        "    inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "    layer = buildConvBlock(inputs, layers = 3, size = 128, kernelSize = 3, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "    layer = buildResNetBlock(layer, 64, 64, 256)\n",
        "    layer = buildResNetBlock(layer, 64, 64, 256)\n",
        "    layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "    layer = buildResNetBlock(layer, 128, 128, 512)\n",
        "    layer = buildResNetBlock(layer, 128, 128, 512)\n",
        "    layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "    layer = buildResNetBlock(layer, 256, 256, 1024)\n",
        "    layer = buildResNetBlock(layer, 256, 256, 1024)\n",
        "    layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "    layer = buildResNetBlock(layer, 512, 512, 2048)\n",
        "    outputs = buildGlobalSoftmax(layer, reductionLayerSize=256, numberOfLabels = numberOfLabels, kernelSize=3, denseDepth = 2, denseSize=128, dropout = 0.35)\n",
        "    return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return closure\n",
        "\n",
        "def model7(numberOfLabels):\n",
        "  def closure():\n",
        "      inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "      layer = buildConvBlock(inputs, layers = 3, size = 64, kernelSize = 3, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "      layer = buildResNetBlock(layer, 128, 128, 512)\n",
        "      layer = buildResNetBlock(layer, 128, 128, 512)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResNetBlock(layer, 256, 256, 1024)\n",
        "      layer = buildResNetBlock(layer, 256, 256, 1024)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResNetBlock(layer, 512, 512, 2048)\n",
        "      outputs = buildGlobalSoftmax(layer, numberOfLabels = numberOfLabels, kernelSize=3, denseDepth = 2, denseSize=128, dropout = 0.35)\n",
        "      return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return closure\n",
        "\n",
        "def model8(numberOfLabels):\n",
        "  MULT = 2\n",
        "  L1_B = 64\n",
        "  L1_A = L1_B * MULT\n",
        "  L2_B = 128\n",
        "  L2_A = L1_B * MULT\n",
        "  L3_B = 256\n",
        "  L3_A = L1_B * MULT\n",
        "  \n",
        "  def closure():\n",
        "      inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "      layer = buildConvBlock(inputs, layers = 3, size = 16, kernelSize = 3, poolSize = 3, poolStrides = 2, flatten = False)\n",
        "      layer = buildResNetBlock(layer, L1_B, L1_B, L1_A)\n",
        "      layer = buildResNetBlock(layer, L1_B, L1_B, L1_A)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResNetBlock(layer, L2_B, L2_B, L2_A)\n",
        "      layer = buildResNetBlock(layer, L2_B, L2_B, L2_A)\n",
        "      layer = buildMaxPoolLayer(layer, poolStrides = 2, poolSize = 2)\n",
        "      layer = buildResNetBlock(layer, L3_B, L3_B, L3_A)\n",
        "      layer = buildResNetBlock(layer, L3_B, L3_B, L3_A)\n",
        "      outputs = buildGlobalSoftmax(layer, numberOfLabels = numberOfLabels)\n",
        "      #outputs = buildGlobalSoftmax(layer, numberOfLabels = numberOfLabels, kernelSize=1, denseDepth = 2, denseSize=32, dropout = 0.3)\n",
        "      return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return (closure, \"MODEL8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6HM-f0IZKnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subGroupModels = Models()\n",
        "\n",
        "\n",
        "for group in [4]:#range(len(groupInfo.keys())):\n",
        "  if loadGroup[group] == False:\n",
        "    raise RuntimeError(\"Non hai caricato i dati per il gruppo\", group)\n",
        "  trInfo = TrainingInfo.getDefaultTPU(\n",
        "      trainingData[group],\n",
        "      trainingLabels[group],\n",
        "      validationData[group],\n",
        "      validationLabels[group]\n",
        "  )\n",
        "  \n",
        "  #uniqueLables, counts = np.unique(trainingLabels[group], return_counts=True)\n",
        "  #classWeights = dict(zip(uniqueLables, 1 / (counts / max(counts))))\n",
        "  \n",
        "  trInfo.setParameters(\n",
        "      learningRateList = [0.0005],\n",
        "      fineTuningIterations = 4,\n",
        "      mainEpochs = 400,\n",
        "      fineTuningEpochs = 70,\n",
        "      batchSize = 1024,\n",
        "      validationFrequency = 10,\n",
        "      validationFrequencyFT = 5,\n",
        "      metrics = ['sparse_categorical_accuracy'],\n",
        "      classWeights = None #non supportato attualmente\n",
        "  )\n",
        "  generatedModel = model8(max(trainingLabels[group]) + 1)\n",
        "  subGroupModels.addModel('Res_' + generatedModel[1] + '_group' + str(group), generatedModel[0], trInfo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20KS91pVrjiL",
        "colab_type": "code",
        "outputId": "db2ba03a-b2fd-40cd-8100-debd5cf4bb99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Training sub-group { vertical-output: true, display-mode: \"form\" }\n",
        "cleanLastSession = False #@param {type:\"boolean\"}\n",
        "if 'lastSession' in locals():\n",
        "  if cleanLastSession == True:\n",
        "    for trainedModel in lastSession:\n",
        "      print(\"Rimuovo il training del modello\", trainedModel)\n",
        "      shutil.rmtree(trainedModel)\n",
        "    lastSession = []\n",
        "else:\n",
        "  lastSession = []\n",
        "#@markdown ---\n",
        "verboseTraining = 1 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "mainTrainingEarlyStoppingDelta = 0.005 #@param {type:\"number\"}\n",
        "mainTrainingEarlyStoppinPatience = 15 #@param {type:\"integer\"}\n",
        "fineTuningEarlyStoppingDelta = 0.001 #@param {type:\"number\"}\n",
        "fineTuningEarlyStoppinPatience = 15 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "trainingPath = rootPath + 'trainingPhaseGroupModel/'\n",
        "\n",
        "\n",
        "dataToLog  = [\"AUG : \"+ str(useDataAugmentation)+\"\\n\",\n",
        "                     \"TR_AUG : \" + str(NUMBER_OF_TRAINING_AUG)+\"\\n\",\n",
        "                     \"VAL_AUG : \" + str(NUMBER_OF_VALIDATION_AUG)+\"\\n\",\n",
        "                     \"randomSeed : \" + str(randomSeed)]\n",
        "if \"useCustomLoad\" in locals() and useCustomLoad == True:\n",
        "  dataToLog.append(\"Custom_load : \" + str(useCustomLoad)+\"\\n\")\n",
        "  dataToLog.append(\"Custom_ratio : \" + str(customRatio) + \"\\n\")  \n",
        "        \n",
        "history = train(tpu_address,\n",
        "  trainingPath,\n",
        "  subGroupModels, \n",
        "  verboseTraining = 1,\n",
        "  mainTrainingEarlyStoppingDelta = mainTrainingEarlyStoppingDelta,\n",
        "  mainTrainingEarlyStoppinPatience = mainTrainingEarlyStoppinPatience,\n",
        "  fineTuningEarlyStoppingDelta = fineTuningEarlyStoppingDelta,\n",
        "  fineTuningEarlyStoppinPatience = fineTuningEarlyStoppinPatience,\n",
        "  stringToLog = ''.join(dataToLog),\n",
        "  lastSession = lastSession)\n",
        "  \n",
        "    \n",
        "print(\"Fine training\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m \n",
            "Res_MODEL8_group4] : main training con lr0.0005 \u001b[0m\n",
            "Epoch 1/400\n",
            "8/8 [==============================] - 11s 1s/step - loss: 4.3992 - sparse_categorical_accuracy: 0.2726\n",
            "Epoch 2/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 3.7525 - sparse_categorical_accuracy: 0.4922\n",
            "Epoch 3/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 3.3694 - sparse_categorical_accuracy: 0.6096\n",
            "Epoch 4/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 3.0319 - sparse_categorical_accuracy: 0.6980\n",
            "Epoch 5/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 2.7582 - sparse_categorical_accuracy: 0.7794\n",
            "Epoch 6/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 2.5550 - sparse_categorical_accuracy: 0.8140\n",
            "Epoch 7/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 2.3875 - sparse_categorical_accuracy: 0.8564\n",
            "Epoch 8/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 2.2365 - sparse_categorical_accuracy: 0.8982\n",
            "Epoch 9/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 2.1288 - sparse_categorical_accuracy: 0.9153\n",
            "Epoch 10/400\n",
            "2/2 [==============================] - 15s 7s/step\n",
            "2/2 [==============================] - 15s 7s/step\n",
            "8/8 [==============================] - 65s 8s/step - loss: 2.0351 - sparse_categorical_accuracy: 0.9331 - val_loss: 2.5043 - val_sparse_categorical_accuracy: 0.2098\n",
            "Epoch 11/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.9494 - sparse_categorical_accuracy: 0.9442\n",
            "Epoch 12/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.8922 - sparse_categorical_accuracy: 0.9543\n",
            "Epoch 13/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.8308 - sparse_categorical_accuracy: 0.9612\n",
            "Epoch 14/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.7891 - sparse_categorical_accuracy: 0.9628\n",
            "Epoch 15/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.7285 - sparse_categorical_accuracy: 0.9712\n",
            "Epoch 16/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.7096 - sparse_categorical_accuracy: 0.9683\n",
            "Epoch 17/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.6682 - sparse_categorical_accuracy: 0.9731\n",
            "Epoch 18/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.6206 - sparse_categorical_accuracy: 0.9801\n",
            "Epoch 19/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.5908 - sparse_categorical_accuracy: 0.9839\n",
            "Epoch 20/400\n",
            "2/2 [==============================] - 16s 8s/step\n",
            "2/2 [==============================] - 16s 8s/step\n",
            "8/8 [==============================] - 26s 3s/step - loss: 1.5514 - sparse_categorical_accuracy: 0.9855 - val_loss: 2.4705 - val_sparse_categorical_accuracy: 0.2098\n",
            "Epoch 21/400\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.5261 - sparse_categorical_accuracy: 0.9851\n",
            "Epoch 22/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4952 - sparse_categorical_accuracy: 0.9894\n",
            "Epoch 23/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4734 - sparse_categorical_accuracy: 0.9897\n",
            "Epoch 24/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4474 - sparse_categorical_accuracy: 0.9905\n",
            "Epoch 25/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4265 - sparse_categorical_accuracy: 0.9915\n",
            "Epoch 26/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.3911 - sparse_categorical_accuracy: 0.9948\n",
            "Epoch 27/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.3717 - sparse_categorical_accuracy: 0.9955\n",
            "Epoch 28/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.3505 - sparse_categorical_accuracy: 0.9939\n",
            "Epoch 29/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.3376 - sparse_categorical_accuracy: 0.9944\n",
            "Epoch 30/400\n",
            "2/2 [==============================] - 17s 9s/step\n",
            "2/2 [==============================] - 17s 9s/step\n",
            "8/8 [==============================] - 28s 3s/step - loss: 1.3143 - sparse_categorical_accuracy: 0.9945 - val_loss: 2.3208 - val_sparse_categorical_accuracy: 0.3514\n",
            "Epoch 31/400\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.2997 - sparse_categorical_accuracy: 0.9958\n",
            "Epoch 32/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.2712 - sparse_categorical_accuracy: 0.9965\n",
            "Epoch 33/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.2560 - sparse_categorical_accuracy: 0.9960\n",
            "Epoch 34/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.2449 - sparse_categorical_accuracy: 0.9962\n",
            "Epoch 35/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.2232 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 36/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.2088 - sparse_categorical_accuracy: 0.9974\n",
            "Epoch 37/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.1888 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 38/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.1762 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 39/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.1647 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 40/400\n",
            "2/2 [==============================] - 17s 9s/step\n",
            "2/2 [==============================] - 17s 9s/step\n",
            "8/8 [==============================] - 28s 4s/step - loss: 1.1444 - sparse_categorical_accuracy: 0.9983 - val_loss: 1.9628 - val_sparse_categorical_accuracy: 0.4589\n",
            "Epoch 41/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.1337 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 42/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.1091 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 43/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.1049 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 44/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.0826 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 45/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.0812 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 46/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 1.0624 - sparse_categorical_accuracy: 0.9985\n",
            "Epoch 47/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.0437 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 48/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.0364 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 49/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.0309 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 50/400\n",
            "2/2 [==============================] - 19s 9s/step\n",
            "2/2 [==============================] - 19s 9s/step\n",
            "8/8 [==============================] - 30s 4s/step - loss: 1.0138 - sparse_categorical_accuracy: 0.9994 - val_loss: 1.4093 - val_sparse_categorical_accuracy: 0.7107\n",
            "Epoch 51/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.9994 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 52/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.9833 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 53/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.9746 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 54/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.9611 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 55/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.9370 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 56/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.9318 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 57/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.9268 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 58/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.9091 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 59/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.9082 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 60/400\n",
            "2/2 [==============================] - 20s 10s/step\n",
            "2/2 [==============================] - 20s 10s/step\n",
            "8/8 [==============================] - 33s 4s/step - loss: 0.8973 - sparse_categorical_accuracy: 0.9998 - val_loss: 1.0416 - val_sparse_categorical_accuracy: 0.8191\n",
            "Epoch 61/400\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.8867 - sparse_categorical_accuracy: 0.9990\n",
            "Epoch 62/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.8727 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 63/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.8695 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 64/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.8507 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 65/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.8525 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 66/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.8320 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 67/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.8260 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 68/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.8115 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 69/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.8079 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 70/400\n",
            "2/2 [==============================] - 21s 11s/step\n",
            "2/2 [==============================] - 21s 11s/step\n",
            "8/8 [==============================] - 34s 4s/step - loss: 0.7949 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.7577 - val_sparse_categorical_accuracy: 0.9012\n",
            "Epoch 71/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.7835 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 72/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.7824 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 73/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.7596 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 74/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.7683 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 75/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.7456 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 76/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.7398 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 77/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.7480 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 78/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.7326 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 79/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.7174 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 80/400\n",
            "2/2 [==============================] - 20s 10s/step\n",
            "2/2 [==============================] - 20s 10s/step\n",
            "8/8 [==============================] - 33s 4s/step - loss: 0.7227 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.6044 - val_sparse_categorical_accuracy: 0.9353\n",
            "Epoch 81/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.6905 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 82/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6966 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 83/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.6955 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 84/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.6796 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 85/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6642 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 86/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.6589 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 87/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6665 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 88/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6527 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 89/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6517 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 90/400\n",
            "2/2 [==============================] - 23s 11s/step\n",
            "2/2 [==============================] - 23s 11s/step\n",
            "8/8 [==============================] - 37s 5s/step - loss: 0.6297 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.5183 - val_sparse_categorical_accuracy: 0.9406\n",
            "Epoch 91/400\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.6390 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 92/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.6355 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 93/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6131 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 94/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6180 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 95/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.6021 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 96/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.5926 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 97/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.5900 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 98/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.5814 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 99/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.5859 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 100/400\n",
            "2/2 [==============================] - 23s 12s/step\n",
            "2/2 [==============================] - 23s 12s/step\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.5625 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4422 - val_sparse_categorical_accuracy: 0.9642\n",
            "Epoch 101/400\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.5699 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 102/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.5625 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 103/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.5489 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 104/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.5541 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 105/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.5379 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 106/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.5451 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 107/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.5317 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 108/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.5162 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 109/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.5224 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 110/400\n",
            "2/2 [==============================] - 26s 13s/step\n",
            "2/2 [==============================] - 26s 13s/step\n",
            "8/8 [==============================] - 41s 5s/step - loss: 0.5208 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4166 - val_sparse_categorical_accuracy: 0.9589\n",
            "Epoch 111/400\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.5073 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 112/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.5001 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 113/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.4962 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 114/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.4949 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 115/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.4891 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 116/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.4741 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 117/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.4816 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 118/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.4786 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 119/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.4635 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 120/400\n",
            "2/2 [==============================] - 26s 13s/step\n",
            "2/2 [==============================] - 26s 13s/step\n",
            "8/8 [==============================] - 42s 5s/step - loss: 0.4668 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.3636 - val_sparse_categorical_accuracy: 0.9650\n",
            "Epoch 121/400\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.4673 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 122/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.4595 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 123/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.4526 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 124/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.4530 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 125/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.4617 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 126/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.5845 - sparse_categorical_accuracy: 0.9702\n",
            "Epoch 127/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.7251 - sparse_categorical_accuracy: 0.9506\n",
            "Epoch 128/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.5824 - sparse_categorical_accuracy: 0.9817\n",
            "Epoch 129/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.5316 - sparse_categorical_accuracy: 0.9868\n",
            "Epoch 130/400\n",
            "2/2 [==============================] - 27s 13s/step\n",
            "2/2 [==============================] - 27s 13s/step\n",
            "8/8 [==============================] - 43s 5s/step - loss: 0.5085 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.4257 - val_sparse_categorical_accuracy: 0.9458\n",
            "Epoch 131/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.4588 - sparse_categorical_accuracy: 0.9972\n",
            "Epoch 132/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.4507 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 133/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.4227 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 134/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.4249 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 135/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.4199 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 136/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.3945 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 137/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.4037 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 138/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.3984 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 139/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3850 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 140/400\n",
            "2/2 [==============================] - 28s 14s/step\n",
            "2/2 [==============================] - 28s 14s/step\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.3794 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2987 - val_sparse_categorical_accuracy: 0.9747\n",
            "Epoch 141/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.3816 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 142/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.3761 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 143/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3678 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 144/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3631 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 145/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.3711 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 146/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.3498 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 147/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.3616 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 148/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.3510 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 149/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.3413 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 150/400\n",
            "2/2 [==============================] - 30s 15s/step\n",
            "2/2 [==============================] - 30s 15s/step\n",
            "8/8 [==============================] - 48s 6s/step - loss: 0.3511 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2709 - val_sparse_categorical_accuracy: 0.9738\n",
            "Epoch 151/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.3376 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 152/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.3370 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 153/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.3401 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 154/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.3336 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 155/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.3284 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 156/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.3274 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 157/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.3242 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 158/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3121 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 159/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.3130 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 160/400\n",
            "2/2 [==============================] - 35s 17s/step\n",
            "2/2 [==============================] - 35s 17s/step\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.3116 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2541 - val_sparse_categorical_accuracy: 0.9703\n",
            "Epoch 161/400\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.3146 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 162/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2987 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 163/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.3076 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 164/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3095 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 165/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2929 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 166/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.2978 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 167/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.2922 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 168/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2904 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 169/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.2892 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 170/400\n",
            "2/2 [==============================] - 35s 18s/step\n",
            "2/2 [==============================] - 35s 18s/step\n",
            "8/8 [==============================] - 56s 7s/step - loss: 0.2942 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2296 - val_sparse_categorical_accuracy: 0.9764\n",
            "Epoch 171/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.2823 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 172/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2858 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 173/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2700 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 174/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2844 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 175/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2697 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 176/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2685 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 177/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.2652 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 178/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2714 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 179/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2558 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 180/400\n",
            "2/2 [==============================] - 33s 16s/step\n",
            "2/2 [==============================] - 33s 16s/step\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.2610 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2302 - val_sparse_categorical_accuracy: 0.9677\n",
            "Epoch 181/400\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.2590 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 182/400\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.2579 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 183/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2584 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 184/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2430 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 185/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.2570 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 186/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.2449 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 187/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2551 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 188/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2435 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 189/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 190/400\n",
            "2/2 [==============================] - 38s 19s/step\n",
            "2/2 [==============================] - 38s 19s/step\n",
            "8/8 [==============================] - 60s 8s/step - loss: 0.2508 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2597 - val_sparse_categorical_accuracy: 0.9545\n",
            "Epoch 191/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.2399 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 192/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2318 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 193/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2368 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 194/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.2297 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 195/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2351 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 196/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2282 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 197/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2271 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 198/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.2177 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 199/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2236 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 200/400\n",
            "2/2 [==============================] - 37s 19s/step\n",
            "2/2 [==============================] - 37s 19s/step\n",
            "8/8 [==============================] - 60s 7s/step - loss: 0.2160 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2121 - val_sparse_categorical_accuracy: 0.9703\n",
            "Epoch 201/400\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.2175 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 202/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2232 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 203/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2102 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 204/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2170 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 205/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2138 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 206/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2137 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 207/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2005 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 208/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.1998 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 209/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2134 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 210/400\n",
            "2/2 [==============================] - 39s 20s/step\n",
            "2/2 [==============================] - 39s 20s/step\n",
            "8/8 [==============================] - 63s 8s/step - loss: 0.2017 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1956 - val_sparse_categorical_accuracy: 0.9694\n",
            "Epoch 211/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.2011 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 212/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.2023 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 213/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1945 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 214/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1944 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 215/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1994 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 216/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.2037 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 217/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2084 - sparse_categorical_accuracy: 0.9982\n",
            "Epoch 218/400\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.2044 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 219/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2197 - sparse_categorical_accuracy: 0.9966\n",
            "Epoch 220/400\n",
            "2/2 [==============================] - 39s 20s/step\n",
            "2/2 [==============================] - 39s 20s/step\n",
            "8/8 [==============================] - 64s 8s/step - loss: 0.2243 - sparse_categorical_accuracy: 0.9951 - val_loss: 0.3269 - val_sparse_categorical_accuracy: 0.9318\n",
            "Epoch 221/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.2289 - sparse_categorical_accuracy: 0.9934\n",
            "Epoch 222/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.2493 - sparse_categorical_accuracy: 0.9905\n",
            "Epoch 223/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.2361 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 224/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2222 - sparse_categorical_accuracy: 0.9941\n",
            "Epoch 225/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2236 - sparse_categorical_accuracy: 0.9952\n",
            "Epoch 226/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2184 - sparse_categorical_accuracy: 0.9937\n",
            "Epoch 227/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.2059 - sparse_categorical_accuracy: 0.9961\n",
            "Epoch 228/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.2021 - sparse_categorical_accuracy: 0.9983\n",
            "Epoch 229/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1856 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 230/400\n",
            "2/2 [==============================] - 42s 21s/step\n",
            "2/2 [==============================] - 42s 21s/step\n",
            "8/8 [==============================] - 69s 9s/step - loss: 0.1771 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.2083 - val_sparse_categorical_accuracy: 0.9624\n",
            "Epoch 231/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.1791 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 232/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1789 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 233/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.1655 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 234/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.1738 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 235/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1687 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 236/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1733 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 237/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1684 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 238/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.1568 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 239/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.1616 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 240/400\n",
            "2/2 [==============================] - 44s 22s/step\n",
            "2/2 [==============================] - 44s 22s/step\n",
            "8/8 [==============================] - 72s 9s/step - loss: 0.1610 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1959 - val_sparse_categorical_accuracy: 0.9633\n",
            "Epoch 241/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1589 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 242/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.1574 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 243/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1626 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 244/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1547 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 245/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.1545 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 246/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1552 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 247/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1518 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 248/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1523 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 249/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.1488 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 250/400\n",
            "2/2 [==============================] - 47s 23s/step\n",
            "2/2 [==============================] - 47s 23s/step\n",
            "8/8 [==============================] - 74s 9s/step - loss: 0.1499 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1727 - val_sparse_categorical_accuracy: 0.9650\n",
            "Epoch 251/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.1393 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 252/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1421 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 253/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.1450 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 254/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1409 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 255/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1430 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 256/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.1429 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 257/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1407 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 258/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.1382 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 259/400\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.1357 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 260/400\n",
            "2/2 [==============================] - 48s 24s/step\n",
            "2/2 [==============================] - 48s 24s/step\n",
            "8/8 [==============================] - 80s 10s/step - loss: 0.1398 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1619 - val_sparse_categorical_accuracy: 0.9694\n",
            "Epoch 261/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.1393 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 262/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1326 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 263/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1374 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 264/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1355 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 265/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.1358 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 266/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1349 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 267/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.1343 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 268/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1327 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 269/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1267 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 270/400\n",
            "2/2 [==============================] - 51s 25s/step\n",
            "2/2 [==============================] - 51s 25s/step\n",
            "8/8 [==============================] - 83s 10s/step - loss: 0.1267 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1552 - val_sparse_categorical_accuracy: 0.9685\n",
            "Epoch 271/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.1241 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 272/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.1215 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 273/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1288 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 274/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1252 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 275/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1231 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 276/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1200 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 277/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1287 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 278/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1222 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 279/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1237 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 280/400\n",
            "2/2 [==============================] - 54s 27s/step\n",
            "2/2 [==============================] - 54s 27s/step\n",
            "8/8 [==============================] - 87s 11s/step - loss: 0.1162 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1560 - val_sparse_categorical_accuracy: 0.9694\n",
            "Epoch 281/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.1192 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 282/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.1161 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 283/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1175 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 284/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1160 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 285/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1114 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 286/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1123 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 287/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.1126 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 288/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1109 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 289/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.1112 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 290/400\n",
            "2/2 [==============================] - 55s 27s/step\n",
            "2/2 [==============================] - 55s 27s/step\n",
            "8/8 [==============================] - 89s 11s/step - loss: 0.1088 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.1491 - val_sparse_categorical_accuracy: 0.9694\n",
            "Epoch 291/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.1106 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 292/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.1109 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 293/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1088 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 294/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1067 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 295/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1092 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 296/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1063 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 297/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1082 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 298/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1044 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 299/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1094 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 300/400\n",
            "2/2 [==============================] - 56s 28s/step\n",
            "2/2 [==============================] - 56s 28s/step\n",
            "8/8 [==============================] - 90s 11s/step - loss: 0.1072 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1498 - val_sparse_categorical_accuracy: 0.9694\n",
            "Epoch 301/400\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.1135 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 302/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 303/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1127 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 304/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1051 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 305/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1075 - sparse_categorical_accuracy: 0.9991\n",
            "Epoch 306/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 307/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1090 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 308/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1168 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 309/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1335 - sparse_categorical_accuracy: 0.9930\n",
            "Epoch 310/400\n",
            "2/2 [==============================] - 58s 29s/step\n",
            "2/2 [==============================] - 58s 29s/step\n",
            "8/8 [==============================] - 95s 12s/step - loss: 0.1452 - sparse_categorical_accuracy: 0.9923 - val_loss: 0.4146 - val_sparse_categorical_accuracy: 0.8907\n",
            "Epoch 311/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.1616 - sparse_categorical_accuracy: 0.9889\n",
            "Epoch 312/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1508 - sparse_categorical_accuracy: 0.9926\n",
            "Epoch 313/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1547 - sparse_categorical_accuracy: 0.9890\n",
            "Epoch 314/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1446 - sparse_categorical_accuracy: 0.9919\n",
            "Epoch 315/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1286 - sparse_categorical_accuracy: 0.9952\n",
            "Epoch 316/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9973\n",
            "Epoch 317/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1109 - sparse_categorical_accuracy: 0.9980\n",
            "Epoch 318/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1057 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 319/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.1010 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 320/400\n",
            "2/2 [==============================] - 61s 31s/step\n",
            "2/2 [==============================] - 61s 31s/step\n",
            "8/8 [==============================] - 97s 12s/step - loss: 0.1021 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1702 - val_sparse_categorical_accuracy: 0.9563\n",
            "Epoch 321/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0945 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 322/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0932 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 323/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0929 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 324/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0914 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 325/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0856 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 326/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0920 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 327/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0908 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 328/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0860 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 329/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0901 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 330/400\n",
            "2/2 [==============================] - 63s 31s/step\n",
            "2/2 [==============================] - 63s 31s/step\n",
            "8/8 [==============================] - 102s 13s/step - loss: 0.0867 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1231 - val_sparse_categorical_accuracy: 0.9712\n",
            "Epoch 331/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0855 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 332/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0829 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 333/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0862 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 334/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0861 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 335/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0872 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 336/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0782 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 337/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0832 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 338/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0795 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 339/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0812 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 340/400\n",
            "2/2 [==============================] - 65s 32s/step\n",
            "2/2 [==============================] - 65s 32s/step\n",
            "8/8 [==============================] - 105s 13s/step - loss: 0.0827 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1160 - val_sparse_categorical_accuracy: 0.9764\n",
            "Epoch 341/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 342/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 343/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 344/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0807 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 345/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0816 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 346/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0787 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 347/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0764 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 348/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0765 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 349/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0774 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 350/400\n",
            "2/2 [==============================] - 65s 32s/step\n",
            "2/2 [==============================] - 65s 32s/step\n",
            "8/8 [==============================] - 105s 13s/step - loss: 0.0751 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1245 - val_sparse_categorical_accuracy: 0.9738\n",
            "Epoch 351/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0747 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 352/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0735 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 353/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0801 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 354/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0744 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 355/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0761 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 356/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0741 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 357/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0714 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 358/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0702 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 359/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0727 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 360/400\n",
            "2/2 [==============================] - 68s 34s/step\n",
            "2/2 [==============================] - 68s 34s/step\n",
            "8/8 [==============================] - 111s 14s/step - loss: 0.0703 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1208 - val_sparse_categorical_accuracy: 0.9729\n",
            "Epoch 361/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0739 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 362/400\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0688 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 363/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0712 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 364/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0687 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 365/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0691 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 366/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0682 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 367/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0658 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 368/400\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0670 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 369/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0680 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 370/400\n",
            "2/2 [==============================] - 70s 35s/step\n",
            "2/2 [==============================] - 70s 35s/step\n",
            "8/8 [==============================] - 113s 14s/step - loss: 0.0652 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1234 - val_sparse_categorical_accuracy: 0.9720\n",
            "Epoch 371/400\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0654 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 372/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0644 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 373/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0682 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 374/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0641 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 375/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0660 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 376/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0652 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 377/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0625 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 378/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0615 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 379/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0621 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 380/400\n",
            "2/2 [==============================] - 74s 37s/step\n",
            "2/2 [==============================] - 74s 37s/step\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.0628 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1263 - val_sparse_categorical_accuracy: 0.9712\n",
            "Epoch 381/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0667 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 382/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0645 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 383/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0625 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 384/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0602 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 385/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0604 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 386/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0594 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 387/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0594 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 388/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0597 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 389/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0593 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 390/400\n",
            "2/2 [==============================] - 74s 37s/step\n",
            "2/2 [==============================] - 74s 37s/step\n",
            "8/8 [==============================] - 117s 15s/step - loss: 0.0583 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1185 - val_sparse_categorical_accuracy: 0.9720\n",
            "Epoch 391/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0620 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 392/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0590 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 393/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0574 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 394/400\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0557 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 395/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0583 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 396/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0557 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 397/400\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0575 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 398/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0559 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 399/400\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0565 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 400/400\n",
            "2/2 [==============================] - 75s 38s/step\n",
            "2/2 [==============================] - 75s 38s/step\n",
            "8/8 [==============================] - 120s 15s/step - loss: 0.0577 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1186 - val_sparse_categorical_accuracy: 0.9712\n",
            "\u001b[1m \n",
            "Res_MODEL8_group4] : fine tuning con lr0.00025partendo da0.0005 \u001b[0m\n",
            "Epoch 1/70\n",
            "8/8 [==============================] - 11s 1s/step - loss: 0.0570 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0549 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0551 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/70\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0539 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/70\n",
            "2/2 [==============================] - 16s 8s/step\n",
            "2/2 [==============================] - 16s 8s/step\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.0564 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1387 - val_sparse_categorical_accuracy: 0.9685\n",
            "Epoch 6/70\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0531 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0564 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 8/70\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0589 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 9/70\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0633 - sparse_categorical_accuracy: 0.9979\n",
            "Epoch 10/70\n",
            "2/2 [==============================] - 18s 9s/step\n",
            "2/2 [==============================] - 18s 9s/step\n",
            "8/8 [==============================] - 29s 4s/step - loss: 0.0603 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.1155 - val_sparse_categorical_accuracy: 0.9633\n",
            "Epoch 11/70\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.0582 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 12/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0615 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 13/70\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0550 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 14/70\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0537 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 15/70\n",
            "2/2 [==============================] - 19s 10s/step\n",
            "2/2 [==============================] - 19s 10s/step\n",
            "8/8 [==============================] - 31s 4s/step - loss: 0.0547 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.1111 - val_sparse_categorical_accuracy: 0.9642\n",
            "Epoch 16/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0511 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 17/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 18/70\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 19/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0496 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/70\n",
            "2/2 [==============================] - 20s 10s/step\n",
            "2/2 [==============================] - 20s 10s/step\n",
            "8/8 [==============================] - 32s 4s/step - loss: 0.0492 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1244 - val_sparse_categorical_accuracy: 0.9694\n",
            "Epoch 21/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0482 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0471 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0481 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0457 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/70\n",
            "2/2 [==============================] - 21s 11s/step\n",
            "2/2 [==============================] - 21s 11s/step\n",
            "8/8 [==============================] - 33s 4s/step - loss: 0.0453 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1225 - val_sparse_categorical_accuracy: 0.9712\n",
            "Epoch 26/70\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.0483 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0437 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0434 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0436 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/70\n",
            "2/2 [==============================] - 22s 11s/step\n",
            "2/2 [==============================] - 22s 11s/step\n",
            "8/8 [==============================] - 35s 4s/step - loss: 0.0424 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1134 - val_sparse_categorical_accuracy: 0.9720\n",
            "Epoch 31/70\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0423 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 32/70\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0428 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 33/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0420 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 34/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0425 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 35/70\n",
            "2/2 [==============================] - 22s 11s/step\n",
            "2/2 [==============================] - 22s 11s/step\n",
            "8/8 [==============================] - 36s 4s/step - loss: 0.0411 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1082 - val_sparse_categorical_accuracy: 0.9720\n",
            "Epoch 36/70\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0413 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 37/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0414 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 38/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0412 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 39/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0398 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/70\n",
            "2/2 [==============================] - 24s 12s/step\n",
            "2/2 [==============================] - 24s 12s/step\n",
            "8/8 [==============================] - 38s 5s/step - loss: 0.0397 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1105 - val_sparse_categorical_accuracy: 0.9738\n",
            "Epoch 41/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0407 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 42/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0386 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 43/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0389 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 44/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0385 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 45/70\n",
            "2/2 [==============================] - 25s 12s/step\n",
            "2/2 [==============================] - 25s 12s/step\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0363 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1124 - val_sparse_categorical_accuracy: 0.9720\n",
            "Epoch 46/70\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0371 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 47/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0370 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0379 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/70\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.0369 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/70\n",
            "2/2 [==============================] - 26s 13s/step\n",
            "2/2 [==============================] - 26s 13s/step\n",
            "8/8 [==============================] - 43s 5s/step - loss: 0.0374 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1156 - val_sparse_categorical_accuracy: 0.9729\n",
            "Epoch 51/70\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0364 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 52/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0369 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 53/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0344 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 54/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0352 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 55/70\n",
            "2/2 [==============================] - 28s 14s/step\n",
            "2/2 [==============================] - 28s 14s/step\n",
            "8/8 [==============================] - 45s 6s/step - loss: 0.0374 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1108 - val_sparse_categorical_accuracy: 0.9659\n",
            "Epoch 56/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0381 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 57/70\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0382 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 58/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0392 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 59/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0413 - sparse_categorical_accuracy: 0.9990\n",
            "Epoch 60/70\n",
            "2/2 [==============================] - 29s 15s/step\n",
            "2/2 [==============================] - 29s 15s/step\n",
            "8/8 [==============================] - 47s 6s/step - loss: 0.0595 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.1989 - val_sparse_categorical_accuracy: 0.9205\n",
            "Epoch 61/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0569 - sparse_categorical_accuracy: 0.9950\n",
            "Epoch 62/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0569 - sparse_categorical_accuracy: 0.9952\n",
            "Epoch 63/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0570 - sparse_categorical_accuracy: 0.9956\n",
            "Epoch 64/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9956\n",
            "Epoch 65/70\n",
            "2/2 [==============================] - 31s 15s/step\n",
            "2/2 [==============================] - 31s 15s/step\n",
            "8/8 [==============================] - 49s 6s/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.8644 - val_sparse_categorical_accuracy: 0.7229\n",
            "Epoch 66/70\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.0472 - sparse_categorical_accuracy: 0.9978\n",
            "Epoch 67/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0425 - sparse_categorical_accuracy: 0.9989\n",
            "Epoch 68/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0375 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 69/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0377 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 70/70\n",
            "2/2 [==============================] - 31s 15s/step\n",
            "2/2 [==============================] - 31s 15s/step\n",
            "8/8 [==============================] - 50s 6s/step - loss: 0.0351 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.1711 - val_sparse_categorical_accuracy: 0.9344\n",
            "\u001b[1m \n",
            "Res_MODEL8_group4] : fine tuning con lr0.000125partendo da0.0005 \u001b[0m\n",
            "Epoch 1/70\n",
            "8/8 [==============================] - 12s 2s/step - loss: 0.0337 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 2/70\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0330 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 3/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0342 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 4/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0313 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 5/70\n",
            "2/2 [==============================] - 17s 9s/step\n",
            "2/2 [==============================] - 17s 9s/step\n",
            "8/8 [==============================] - 73s 9s/step - loss: 0.0323 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0984 - val_sparse_categorical_accuracy: 0.9712\n",
            "Epoch 6/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0308 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 7/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0315 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 8/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0307 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 9/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0325 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 10/70\n",
            "2/2 [==============================] - 18s 9s/step\n",
            "2/2 [==============================] - 18s 9s/step\n",
            "8/8 [==============================] - 29s 4s/step - loss: 0.0308 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1102 - val_sparse_categorical_accuracy: 0.9589\n",
            "Epoch 11/70\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0301 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 12/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0307 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 13/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0319 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 14/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0309 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/70\n",
            "2/2 [==============================] - 18s 9s/step\n",
            "2/2 [==============================] - 18s 9s/step\n",
            "8/8 [==============================] - 29s 4s/step - loss: 0.0286 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1358 - val_sparse_categorical_accuracy: 0.9650\n",
            "Epoch 16/70\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.0305 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/70\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0299 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0299 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0297 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/70\n",
            "2/2 [==============================] - 19s 10s/step\n",
            "2/2 [==============================] - 19s 10s/step\n",
            "8/8 [==============================] - 31s 4s/step - loss: 0.0292 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1169 - val_sparse_categorical_accuracy: 0.9685\n",
            "Epoch 21/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0291 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 22/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0278 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 23/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0282 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 24/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0282 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 25/70\n",
            "2/2 [==============================] - 19s 10s/step\n",
            "2/2 [==============================] - 19s 10s/step\n",
            "8/8 [==============================] - 31s 4s/step - loss: 0.0282 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1058 - val_sparse_categorical_accuracy: 0.9720\n",
            "Epoch 26/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0285 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 27/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0281 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 28/70\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0277 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 29/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0270 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 30/70\n",
            "2/2 [==============================] - 21s 10s/step\n",
            "2/2 [==============================] - 21s 10s/step\n",
            "8/8 [==============================] - 33s 4s/step - loss: 0.0270 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.0891 - val_sparse_categorical_accuracy: 0.9738\n",
            "Epoch 31/70\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0272 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 32/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0286 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 33/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0305 - sparse_categorical_accuracy: 0.9998\n",
            "Epoch 34/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0359 - sparse_categorical_accuracy: 0.9984\n",
            "Epoch 35/70\n",
            "2/2 [==============================] - 22s 11s/step\n",
            "2/2 [==============================] - 22s 11s/step\n",
            "8/8 [==============================] - 35s 4s/step - loss: 0.0360 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.1234 - val_sparse_categorical_accuracy: 0.9554\n",
            "Epoch 36/70\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9994\n",
            "Epoch 37/70\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0293 - sparse_categorical_accuracy: 0.9996\n",
            "Epoch 38/70\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0306 - sparse_categorical_accuracy: 0.9995\n",
            "Epoch 39/70\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0295 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 40/70\n",
            "2/2 [==============================] - 24s 12s/step\n",
            "2/2 [==============================] - 24s 12s/step\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0270 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.1851 - val_sparse_categorical_accuracy: 0.9397\n",
            "Epoch 41/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0302 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 42/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0333 - sparse_categorical_accuracy: 0.9988\n",
            "Epoch 43/70\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0327 - sparse_categorical_accuracy: 0.9987\n",
            "Epoch 44/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0312 - sparse_categorical_accuracy: 0.9993\n",
            "Epoch 45/70\n",
            "2/2 [==============================] - 25s 13s/step\n",
            "2/2 [==============================] - 25s 13s/step\n",
            "8/8 [==============================] - 39s 5s/step - loss: 0.0276 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.1154 - val_sparse_categorical_accuracy: 0.9659\n",
            "Epoch 46/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0290 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 47/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0267 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 48/70\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0274 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 49/70\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0258 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 50/70\n",
            "2/2 [==============================] - 26s 13s/step\n",
            "2/2 [==============================] - 26s 13s/step\n",
            "8/8 [==============================] - 41s 5s/step - loss: 0.0275 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.1125 - val_sparse_categorical_accuracy: 0.9712\n",
            "Epoch 51/70\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0258 - sparse_categorical_accuracy: 0.9999\n",
            "Epoch 52/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0253 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 53/70\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0263 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 54/70\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0247 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 55/70\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0258 - sparse_categorical_accuracy: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doyoDzepG_wV",
        "colab_type": "code",
        "outputId": "9a7c27d2-c692-4731-a1f2-28737c2a5f12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "if 'predictions' not in locals():\n",
        "  raise RuntimeError(\"Devi esereguire prima la cella group test\")\n",
        "    \n",
        "predictedGroupLabels = np.zeros((len(predictions[0])),dtype=\"int32\")\n",
        "\n",
        "trueLabels = np.load(testDir + \"labels.npy\")\n",
        "\n",
        "# dalle predictions estraggo il groupLabel\n",
        "for predictionIndex in range(len(trueLabels)):\n",
        "  prediction = np.zeros((5), dtype=\"float\")\n",
        "  # preparo il vettore inferenza\n",
        "  for modelIndex in range(len(predictions)):\n",
        "    prediction = np.add(prediction, predictions[modelIndex][predictionIndex])\n",
        "  predictedGroupLabels[predictionIndex] = np.argmax(prediction)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "# label original suddivide per gruppo in base alle inferenza e non al reale gruppo\n",
        "trueLabelsByGroup = [[],[],[],[],[]]\n",
        "testDataGroup = [[],[],[],[],[]]\n",
        "for lIndex in range(len(predictedGroupLabels)):\n",
        "  testDataGroup[predictedGroupLabels[lIndex]].append(testData[lIndex])\n",
        "  trueLabelsByGroup[predictedGroupLabels[lIndex]].append(trueLabels[lIndex]) \n",
        "\n",
        "result = []  \n",
        "maxLabels = [12,15,8,4,4]\n",
        "\n",
        "count = 0\n",
        "\n",
        "weights = [\n",
        "    '/gdrive/My Drive/DatasetSegnaliStradali/GTSRB/trainingPhaseGroupModel/ResBalancedx2_group0_2019_6_28_18_3_36/0.001/FineTuning/0.000125/weights/epoch_10_valLoss_0.0472.hdf5',\n",
        "          '/gdrive/My Drive/DatasetSegnaliStradali/GTSRB/trainingPhaseGroupModel/ResBalancedx2_group1_2019_6_29_8_29_12/0.001/FineTuning/0.000125/weights/epoch_15_valLoss_0.0280.hdf5',\n",
        "          '/gdrive/My Drive/DatasetSegnaliStradali/GTSRB/trainingPhaseGroupModel/ResBalancedx2_group2_2019_6_28_13_53_56/0.001/FineTuning/0.000125/weights/epoch_25_valLoss_0.0067.hdf5',\n",
        "          '/gdrive/My Drive/DatasetSegnaliStradali/GTSRB/trainingPhaseGroupModel/Res_group3_2019_6_24_8_48_1/0.0001/FineTuning/6.25e-06/weights/epoch_50_valLoss_0.1405.hdf5',\n",
        "          '/gdrive/My Drive/DatasetSegnaliStradali/GTSRB/trainingPhaseGroupModel/Res_MODEL8_group4_2019_7_2_10_5_3/0.0005/FineTuning/6.25e-05/weights/epoch_15_valLoss_0.1101.hdf5']#'/gdrive/My Drive/DatasetSegnaliStradali/GTSRB/trainingPhaseGroupModel/Res_group4_2019_6_23_20_32_28/0.0001/FineTuning/6.25e-06/weights/epoch_40_valLoss_0.1579.hdf5']\n",
        "\n",
        "for tdGroup in testDataGroup:\n",
        "  if tfVersion()['MAJOR'] <= 1 and tfVersion()['MINOR'] <= 13:\n",
        "    if len(tdGroup) % 8 != 0:\n",
        "      for index in range(len(tdGroup),len(tdGroup) + (8-len(tdGroup) % 8)):\n",
        "        tdGroup.append(tdGroup[-1])\n",
        "\n",
        "  data = np.asarray(tdGroup, dtype=np.float32)\n",
        "  if count <= 2:\n",
        "    model = model7(maxLabels[count])\n",
        "  if count == 3:\n",
        "    model = model1(maxLabels[count])\n",
        "  if count == 4:\n",
        "    model = model8(maxLabels[count])[0]\n",
        "  \n",
        "  res = testModel(tpu_address,\n",
        "                         [model],\n",
        "                         [\n",
        "                             [weights[count]]\n",
        "                         ],\n",
        "                         data)\n",
        "  \n",
        "  count += 1\n",
        "  for r in res:\n",
        "    result.append(r)\n",
        "  print(\"fine\" , count)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test model 0 weights 0\n",
            "12/12 [==============================] - 27s 2s/step\n",
            "12/12 [==============================] - 27s 2s/step\n",
            "fine 1\n",
            "Test model 0 weights 0\n",
            "6/6 [==============================] - 15s 2s/step\n",
            "6/6 [==============================] - 15s 2s/step\n",
            "fine 2\n",
            "Test model 0 weights 0\n",
            "4/4 [==============================] - 11s 3s/step\n",
            "4/4 [==============================] - 11s 3s/step\n",
            "fine 3\n",
            "Test model 0 weights 0\n",
            "4/4 [==============================] - 16s 4s/step\n",
            "4/4 [==============================] - 16s 4s/step\n",
            "fine 4\n",
            "Test model 0 weights 0\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "fine 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28jPJjSDOGCL",
        "colab_type": "code",
        "outputId": "084124e5-4eb1-4b37-b541-b8277e7bffb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "lookUpTable=[\n",
        "     {\n",
        "         0 :0, 1:1,2:2,3:3,4:4,5:5,6:7,7:8,8:9,9:10,10:15,11:16\n",
        "     }   ,\n",
        "    {\n",
        "        0:11,1:18,2:19,3:20,4:21,5:22,6:23,7:24,8:25,9:26,10:27,11:28,12:29,13:30,14:31\n",
        "    },\n",
        "    {\n",
        "        0:33,1:34,2:35,3:26,4:37,5:38,6:39,7:40\n",
        "    },\n",
        "    {\n",
        "        0:12,1:13,2:14,3:17\n",
        "    },\n",
        "    {\n",
        "      0:6,1:32,2:41,3:42  \n",
        "    }\n",
        "]\n",
        "\n",
        "index = 0\n",
        "total = 0\n",
        "correct = 0\n",
        "for index in [0,1,2,3,4]:\n",
        "  corBackup = correct\n",
        "  totBackup = total\n",
        "  wrongGroup = 0\n",
        "  for lIndex in range(len(trueLabelsByGroup[index])):\n",
        "    pred = np.argmax(result[index][lIndex])\n",
        "    ## correggo con una lookup table\n",
        "    pred = lookUpTable[index][pred]\n",
        "    if pred == trueLabelsByGroup[index][lIndex]:\n",
        "      correct += 1\n",
        "    else:\n",
        "      #sbagliata\n",
        "      if labelsInfo[trueLabelsByGroup[index][lIndex]][0] != index:\n",
        "        wrongGroup += 1\n",
        "    total += 1\n",
        "  print(total-totBackup, correct - corBackup, wrongGroup)\n",
        "  index += 1\n",
        "\n",
        "print(total, correct)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5675 5653 6\n",
            "2790 2748 0\n",
            "1769 1640 4\n",
            "2036 2003 1\n",
            "360 264 0\n",
            "12630 12308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1S2AstpA0b5",
        "colab_type": "text"
      },
      "source": [
        "5675 5653 6\n",
        "\n",
        "2790 2748 0\n",
        "\n",
        "1769 1640 4\n",
        "\n",
        "2036 2003\n",
        "\n",
        "360 343\n",
        "\n",
        "12630 12387"
      ]
    }
  ]
}
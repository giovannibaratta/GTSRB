{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelBuildInception.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giovannibaratta/GTSRB/blob/master/ModelBuildInception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Emgme5Yh5gG_",
        "colab": {}
      },
      "source": [
        "#@title Import e definizioni (Versione 5) { vertical-output: true, display-mode: \"form\" }\n",
        "#@markdown Selezionare se si vuole caricare una versione specifica di tensorflow\n",
        "forceVersion = False #@param {type:\"boolean\"} \n",
        "tfVersion = \"1.13.1\" #@param [\"1.12.2\", \"1.13.1\", \"1.14.0rc1\", \"1.14.0\", \"2.0.0b1\", \"PRINT_AV_VERSION\"] {allow-input: true}\n",
        "#@markdown Selezionare se si è collegati ad un runtime locale (non quello di colab)\n",
        "localRuntime = False #@param{type:\"boolean\"}\n",
        "#@markdown Selezionare se si intende utilizzare le TPU come acceleratore (solo se il runtime è quello di colab)\n",
        "useTPU = False #@param {type:\"boolean\"}\n",
        "\n",
        "useTPU = False if localRuntime else useTPU\n",
        "\n",
        "if forceVersion == True:\n",
        "  if useTPU == True:\n",
        "    !pip install -q tensorflow=={tfVersion}\n",
        "  else:\n",
        "    !pip install -q tensorflow-gpu=={tfVersion}\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import pprint\n",
        "import math\n",
        "import random as rn\n",
        "#data aug\n",
        "from tensorflow import keras \n",
        "# gestione directory\n",
        "import shutil\n",
        "import sys\n",
        "# colorare output\n",
        "!pip install -q colorama\n",
        "from colorama import Style as ColoramaStyle\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "currentPath = !pwd\n",
        "#@markdown Path da utilizzare nel caso di runtime remoto\n",
        "colabPath = '/gdrive/My Drive/DatasetSegnaliStradali/GTSRB/' #@param{type:'string'} \n",
        "#@markdown Path da utilizzare nel caso di runtime locale\n",
        "localPath =  \"/Desktop/DL/\" #@param{type:'string'} \n",
        "completeLocalPath = currentPath[0] + localPath\n",
        "#@markdown Cartella da utilizzare all'interno del path per l'output dei risultati (la cartella deve essere già presente)\n",
        "phase = \"trainingPhaseInception\" #@param [\"trainingPhase1\", \"trainingPhaseCNN\", \"trainingPhaseResNet\", \"trainingPhaseInception\", \"trainingPhaseGroupModel\"] {allow-input: true}\n",
        "rootPath = completeLocalPath if localRuntime else colabPath\n",
        "\n",
        "#@markdown Dimensioni delle immagini di training, validation e test\n",
        "width = 48#@param{type:'integer'}\n",
        "height = 48#@param{type:'integer'}\n",
        "tmpPath = rootPath + 'tmp/'\n",
        "testDir = rootPath + 'data/test' + str(width) + 'x' + str(height) + '/'\n",
        "\n",
        "print('Versione TF : ', ColoramaStyle.BRIGHT, tf.__version__, ColoramaStyle.RESET_ALL,sep=\"\")\n",
        "\n",
        "if useTPU == False:\n",
        "  if 'COLAB_TPU_ADDR' in os.environ:\n",
        "    raise RuntimeError(\"Hai selezionato il runtime TPU. Cambia l'impostazioni del notebook\")\n",
        "  print(\"Acceleratore : GPU\")\n",
        "  print(\"Verifica device :\",tf.test.gpu_device_name())\n",
        "  tpu_address = ''\n",
        "else:\n",
        "  if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "    print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "  else:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    print(\"Acceleratore : TPU\")\n",
        "    print ('Verifica device : ', tpu_address)\n",
        "\n",
        "if not localRuntime:\n",
        "  from google.colab import drive\n",
        "  from google.colab import files\n",
        "  drive.mount('/gdrive')\n",
        "    \n",
        "#import script da gdrive\n",
        "scriptPath = rootPath + \"scripts/colab/\"\n",
        "sys.path.append(scriptPath)\n",
        "\n",
        "from CommonUtils import *\n",
        "from ModelBuilderUtils import *\n",
        "from TrainingUtils import *\n",
        "from TestUtils import *\n",
        "\n",
        "if tfVersion()['MAJOR'] < 2:\n",
        "  tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "resetSeed()\n",
        "\n",
        "groupInfo = {\n",
        "    0 : 'prohibitory',\n",
        "    1 : 'danger',\n",
        "    2 : 'mandatory',\n",
        "    3 : 'others',\n",
        "    4 : 'limitsEnd'\n",
        "}\n",
        "\n",
        "labelsInfo = {\n",
        "    # labelNumber : (group,labelInsideGroup, description)\n",
        "    0 : (0,0, '20 km/h'),\n",
        "    1 : (0,1, '30 km/h'),\n",
        "    2 : (0,2, '50 km/h'),\n",
        "    3 : (0,3, '60 km/h'),\n",
        "    4 : (0,4, '70 km/h'),\n",
        "    5 : (0,5, '80 km/h'),\n",
        "    6 : (4,0, '80 km/h end'),\n",
        "    7 : (0,6, '100 km/h'),\n",
        "    8 : (0,7, '120 km/h'),\n",
        "    9 : (0,8, 'No overtaking'),\n",
        "    10 : (0,9, 'No overtaking for tracks'),\n",
        "    11 : (1,0, 'Crossroad with secondary way'),\n",
        "    12 : (3,0, 'Main road'),\n",
        "    13 : (3,1,  'Give way'),\n",
        "    14 : (3,2, 'Stop'),\n",
        "    15 : (0,10,  'Road up'),\n",
        "    16 : (0,11, 'Road up for track'),\n",
        "    17 : (3,3,  'Brock'),\n",
        "    18 : (1,1, 'Other dangerous'),\n",
        "    19 : (1,2, 'Turn left'),\n",
        "    20 : (1,3, 'Turn right'),\n",
        "    21 : (1,4, 'Winding road'),\n",
        "    22 : (1,5, 'Hollow road'),\n",
        "    23 : (1,6, 'Slippery road'),\n",
        "    24 : (1,7, 'Narrowing road'),\n",
        "    25 : (1,8, 'Roadwork'),\n",
        "    26 : (1,9, 'Traffic light'),\n",
        "    27 : (1,10, 'Pedestrian'),\n",
        "    28 : (1,11, 'Children'),\n",
        "    29 : (1,12, 'Bike'),\n",
        "    30 : (1,13, 'Snow'),\n",
        "    31 : (1,14, 'Deer'),\n",
        "    32 : (4,1, 'End of the limits'),\n",
        "    33 : (2,0, 'Only right'),\n",
        "    34 : (2,1, 'Only left'),\n",
        "    35 : (2,2, 'Only straight'),\n",
        "    36 : (2,3, 'Only straight and right'),\n",
        "    37 : (2,4, 'Only straight and left'),\n",
        "    38 : (2,5, 'Take right'),\n",
        "    39 : (2,6, 'Take left'),\n",
        "    40 : (2,7, 'Circle crossroad'),\n",
        "    41 : (4,2, 'End of overtaking limit'),\n",
        "    42 : (4,3, 'End of overtaking limit for track')\n",
        "}\n",
        "\n",
        "lookUpTable=[\n",
        "    # gruppo 0\n",
        "    {\n",
        "        0:0,\n",
        "        1:1,\n",
        "        2:2,\n",
        "        3:3,\n",
        "        4:4,\n",
        "        5:5,\n",
        "        6:7,\n",
        "        7:8,\n",
        "        8:9,\n",
        "        9:10,\n",
        "        10:15,\n",
        "        11:16\n",
        "    },\n",
        "    # gruppo 1\n",
        "    {\n",
        "        0:11,\n",
        "        1:18,\n",
        "        2:19,\n",
        "        3:20,\n",
        "        4:21,\n",
        "        5:22,\n",
        "        6:23,\n",
        "        7:24,\n",
        "        8:25,\n",
        "        9:26,\n",
        "        10:27,\n",
        "        11:28,\n",
        "        12:29,\n",
        "        13:30,\n",
        "        14:31\n",
        "    },\n",
        "    # gruppo 2\n",
        "    {\n",
        "        0:33,\n",
        "        1:34,\n",
        "        2:35,\n",
        "        3:36,\n",
        "        4:37,\n",
        "        5:38,\n",
        "        6:39,\n",
        "        7:40\n",
        "    },\n",
        "    # gruppo 3\n",
        "    {\n",
        "        0:12,\n",
        "        1:13,\n",
        "        2:14,\n",
        "        3:17\n",
        "    },\n",
        "    #gruppo 4\n",
        "    {\n",
        "        0:6,\n",
        "        1:32,\n",
        "        2:41,\n",
        "        3:42  \n",
        "    }\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1CDs1W0GIft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Caricamento dei dati (versione 5) { vertical-output: true, display-mode: \"form\" }\n",
        "if 'trainingData' in locals():\n",
        "  del trainingData\n",
        "if 'trainingLabels' in locals():\n",
        "  del trainingLabels\n",
        "if 'validationData' in locals():  \n",
        "  del validationData\n",
        "if 'validationLabels' in locals():\n",
        "  del validationLabels\n",
        "\n",
        "trainingDir = rootPath + 'data/training/'\n",
        "validationDir = rootPath + 'data/validation/'\n",
        "\n",
        "#@markdown Deselezionare nel caso si sti allenando il modello a due step, in quel caso le label non sono le originale ma sono il gruppo della classe\n",
        "loadTrueLabels = True #@param{type:'boolean'}\n",
        "\n",
        "samplingToLoad = 1#@param{type:'integer'}\n",
        "#@markdown Seed per la genezione di nuove immagini\n",
        "randomSeed = 62806#@param{type:'integer'}\n",
        "#@markdown Sperimentale, non usare\n",
        "use16Bit = False#@param{type:'boolean'}\n",
        "#@markdown Sperimentale, non usare\n",
        "convertToTesnor = False#@param{type:'boolean'}\n",
        "trainingDir = rootPath + 'data/sampling' + str(samplingToLoad) + '_' + str(width) + 'x' + str(height) + '/training/'\n",
        "validationDir = rootPath + 'data/sampling' + str(samplingToLoad) + '_' + str(width) + 'x' + str(height) + '/validation/'\n",
        "\n",
        "#riproducibilità dei training\n",
        "resetSeed(15 + randomSeed)\n",
        "\n",
        "#@markdown Selezionare se si vogliono generare delle immagini aggiuntive\n",
        "useDataAugmentation = True #@param {type:\"boolean\"}\n",
        "#@markdown Se selezionato il valore degli slider vengono aggiunti ai valori presenti nel codice\n",
        "usePerLabelDataAug = True #@param {type:\"boolean\"}\n",
        "#@markdown Se selezionato non genera immagini aggiuntive per il validation set\n",
        "onlyTrainingAug = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Numero di immagini da generare per ogni immagine originale\n",
        "NUMBER_OF_TRAINING_AUG_GLOBAL = 1 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "NUMBER_OF_VALIDATION_AUG_GLOBAL = 1 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "\n",
        "# da modificare se si vuole alterare la distribuzione delle classi\n",
        "NUMBER_AUG_BY_LABEL = { \n",
        "                0 : ( 4 , 2 ), # group 0  label inside group 0\n",
        "                1 : ( 1 , 1 ), # group 0  label inside group 1\n",
        "                2 : ( 1 , 1 ), # group 0  label inside group 2\n",
        "                3 : ( 1 , 1 ), # group 0  label inside group 3\n",
        "                4 : ( 1 , 1 ), # group 0  label inside group 4\n",
        "                5 : ( 1 , 1 ), # group 0  label inside group 5\n",
        "                6 : ( 3 , 2 ), # group 4  label inside group 0\n",
        "                7 : ( 1 , 1 ), # group 0  label inside group 6\n",
        "                8 : ( 1 , 1 ), # group 0  label inside group 7\n",
        "                9 : ( 1 , 1 ), # group 0  label inside group 8\n",
        "                10 : ( 1 , 1 ), # group 0  label inside group 9\n",
        "                11 : ( 1 , 1 ), # group 1  label inside group 0\n",
        "                12 : ( 1 , 1 ), # group 3  label inside group 0\n",
        "                13 : ( 1 , 1 ), # group 3  label inside group 1\n",
        "                14 : ( 2 , 1 ), # group 3  label inside group 2\n",
        "                15 : ( 2 , 1 ), # group 0  label inside group 10\n",
        "                16 : ( 3 , 2 ), # group 0  label inside group 11\n",
        "                17 : ( 1 , 1 ), # group 3  label inside group 3\n",
        "                18 : ( 1 , 1 ), # group 1  label inside group 1\n",
        "                19 : ( 4 , 2 ), # group 1  label inside group 2\n",
        "                20 : ( 3 , 2 ), # group 1  label inside group 3\n",
        "                21 : ( 3 , 2 ), # group 1  label inside group 4\n",
        "                22 : ( 3 , 2 ), # group 1  label inside group 5\n",
        "                23 : ( 3 , 2 ), # group 1  label inside group 6\n",
        "                24 : ( 3 , 2 ), # group 1  label inside group 7\n",
        "                25 : ( 1 , 1 ), # group 1  label inside group 8\n",
        "                26 : ( 3 , 2 ), # group 1  label inside group 9\n",
        "                27 : ( 3 , 2 ), # group 1  label inside group 10\n",
        "                28 : ( 3 , 2 ), # group 1  label inside group 11\n",
        "                29 : ( 3 , 2 ), # group 1  label inside group 12\n",
        "                30 : ( 4 , 2 ), # group 1  label inside group 13\n",
        "                31 : ( 2 , 2 ), # group 1  label inside group 14\n",
        "                32 : ( 3 , 2 ), # group 4  label inside group 1\n",
        "                33 : ( 3 , 2 ), # group 2  label inside group 0\n",
        "                34 : ( 5 , 2 ), # group 2  label inside group 1\n",
        "                35 : ( 1 , 2 ), # group 2  label inside group 2\n",
        "                36 : ( 2 , 2 ), # group 2  label inside group 3\n",
        "                37 : ( 2 , 2 ), # group 2  label inside group 4\n",
        "                38 : ( 1 , 1 ), # group 2  label inside group 5\n",
        "                39 : ( 3 , 2 ), # group 2  label inside group 6\n",
        "                40 : ( 3, 2 ), # group 2  label inside group 7\n",
        "                41 : ( 3 , 2 ), # group 4  label inside group 2\n",
        "                42 : ( 3 , 2 ), # group 4  label inside group 3\n",
        "              }\n",
        "\n",
        "NUMBER_OF_TRAINING_AUG = [0 for i in range(43)]\n",
        "NUMBER_OF_VALIDATION_AUG = [0 for i in range(43)]\n",
        "\n",
        "if useDataAugmentation == True:\n",
        "  for key in labelsInfo.keys():\n",
        "    NUMBER_OF_TRAINING_AUG[key] = NUMBER_AUG_BY_LABEL[key][0] if usePerLabelDataAug else NUMBER_OF_TRAINING_AUG_GLOBAL\n",
        "    NUMBER_OF_VALIDATION_AUG[key] = NUMBER_AUG_BY_LABEL[key][1] if usePerLabelDataAug else NUMBER_OF_VALIDATION_AUG_GLOBAL\n",
        "    if usePerLabelDataAug and onlyTrainingAug:\n",
        "        NUMBER_OF_VALIDATION_AUG[key] = 0\n",
        "\n",
        "\n",
        "brightness_range_training = (0.25,0.6)\n",
        "rotation_range_training = 25\n",
        "width_shift_range_training = 8\n",
        "height_shift_range_training = 8\n",
        "shear_range_training = 15\n",
        "zoom_range_training =(0.4,1.15)\n",
        "channel_shift_range_training = 0.13\n",
        "\n",
        "brightness_range_validation =(0.25,0.7)\n",
        "rotation_range_validation = 25\n",
        "width_shift_range_validation = 8 \n",
        "height_shift_range_validation = 8\n",
        "shear_range_validation = 0.4\n",
        "zoom_range_validation = (0.4,1.15)\n",
        "channel_shift_range_validation = 0.12\n",
        "\n",
        "#generatore utilizzato per le immagni di training\n",
        "generatorTraining = keras.preprocessing.image.ImageDataGenerator(\n",
        "    brightness_range = brightness_range_training,\n",
        "    rotation_range= rotation_range_training,\n",
        "    width_shift_range= width_shift_range_training,\n",
        "    height_shift_range= height_shift_range_training,\n",
        "    shear_range=shear_range_training,\n",
        "    zoom_range= zoom_range_training,\n",
        "    channel_shift_range=channel_shift_range_training)\n",
        "\n",
        "#generatore utilizzato per le immagini di validation\n",
        "generatorValidation = keras.preprocessing.image.ImageDataGenerator(\n",
        "    brightness_range = brightness_range_validation,\n",
        "    rotation_range=rotation_range_validation,\n",
        "    width_shift_range=width_shift_range_validation,\n",
        "    height_shift_range=height_shift_range_validation,\n",
        "    shear_range=shear_range_validation,\n",
        "    zoom_range=zoom_range_validation,\n",
        "    channel_shift_range=channel_shift_range_validation)\n",
        "\n",
        "# numero di immagini originali disponibili per ogni classe\n",
        "trainingClassCount = {}\n",
        "# numero di immagini di training totali\n",
        "totalTrainingCount = 0\n",
        "\n",
        "files = list(filter(lambda fn : fn.startswith('resized'), os.listdir(trainingDir)))\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  numFilePath = trainingDir + 'num' + str(classLabel)\n",
        "  with open(numFilePath, 'r') as file:\n",
        "    originalNum = int(file.readline())\n",
        "    trainingClassCount[classLabel] = originalNum \n",
        "    totalTrainingCount += originalNum * (NUMBER_OF_TRAINING_AUG[classLabel] + 1)\n",
        "\n",
        "print(\"Training images (no pad):\", totalTrainingCount)\n",
        "\n",
        "# se uso le TPU in tf 1.13 il numero di immagini deve essere divisibile per 8\n",
        "trainingPadEnd = False\n",
        "\n",
        "if useTPU == True and tfVersion()['MAJOR'] == 1 and tfVersion()['MAJOR'] <= 13:\n",
        "  if totalTrainingCount % 8 != 0:\n",
        "    trainingToPad = 8 - (totalTrainingCount % 8)\n",
        "    totalTrainingCount = totalTrainingCount + (8 - (totalTrainingCount % 8))\n",
        "    trainingPadEnd = True\n",
        "  \n",
        "#preparo gli array che contengono le img di training\n",
        "trainingData = np.empty((totalTrainingCount, width, height, 3), dtype='float32')\n",
        "trainingLabels = np.empty((totalTrainingCount), dtype='int32')\n",
        "trueTrainingLabels = np.empty((totalTrainingCount), dtype='int32')\n",
        "\n",
        "# numero di immagini originali disponibili per ogni classe\n",
        "validationClassCount = {}\n",
        "# numero di immagini di validation totali\n",
        "totalValidationCount = 0\n",
        "\n",
        "# recupero il numero di immagini di validation disponibili per ogni classe\n",
        "files = list(filter(lambda fn : fn.startswith('resized'), os.listdir(trainingDir)))\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  numFilePath = validationDir + 'num' + str(classLabel)\n",
        "  with open(numFilePath, 'r') as file:\n",
        "    originalNum = int(file.readline())\n",
        "    validationClassCount[classLabel] = originalNum\n",
        "    totalValidationCount += originalNum * (NUMBER_OF_VALIDATION_AUG[classLabel] + 1)\n",
        "\n",
        "print(\"Validation images (no pad):\", totalValidationCount)\n",
        "\n",
        "# se uso le TPU in tf 1.13 il numero di immagini deve essere divisibile per 8\n",
        "validationPadEnd = False \n",
        "\n",
        "if useTPU == True and tfVersion()['MAJOR'] == 1 and tfVersion()['MAJOR'] <= 13:\n",
        "    if totalValidationCount % 8 != 0:\n",
        "      # se uso le TPU la lunghezza dei dati deve essere divisibile per 8\n",
        "      validationToPad = 8 - (totalValidationCount % 8)\n",
        "      totalValidationCount = totalValidationCount + (8 - (totalValidationCount % 8))\n",
        "      validationPadEnd = True\n",
        "  \n",
        "#preparo gli array che contengono le img di validation\n",
        "validationData = np.empty((totalValidationCount, width, height, 3), dtype='float32')\n",
        "# contengono il gruppo da 0 a 4\n",
        "validationLabels = np.empty((totalValidationCount), dtype='int32')\n",
        "#contengono la label vera da 0 a 42\n",
        "trueValidationLabels = np.empty((totalValidationCount), dtype='int32')\n",
        "\n",
        "print('Total', totalValidationCount + totalTrainingCount)\n",
        "if useDataAugmentation == True:\n",
        "  print(\"Data augmentation training\", NUMBER_OF_TRAINING_AUG, \"\\nvalidation\", NUMBER_OF_VALIDATION_AUG)\n",
        "else:\n",
        "  print(\"Data augmentation : OFF\")\n",
        "\n",
        "#numero di immagini elaborate  \n",
        "validationCount = 0\n",
        "trainingCount = 0\n",
        "loadedClass = 0\n",
        "\n",
        "#caricamento dati\n",
        "for fileName in files:\n",
        "  classLabel = int(fileName.replace(\"resized\",\"\"))\n",
        "  #carico le img di training originali\n",
        "  trainingImages = np.memmap(trainingDir + fileName, dtype=np.uint8,\n",
        "              mode='r', shape=(trainingClassCount[classLabel],width,height,3))\n",
        "\n",
        "  for img in trainingImages:\n",
        "    trainingData[trainingCount]  = img/255.0\n",
        "    trainingLabels[trainingCount] = labelsInfo[classLabel][0] if not loadTrueLabels else classLabel\n",
        "    trueTrainingLabels[trainingCount] = classLabel\n",
        "    trainingCount += 1\n",
        "\n",
        "  #carico le immagini di validation\n",
        "  validationImages = np.memmap(validationDir + fileName, dtype=np.uint8,\n",
        "              mode='r', shape=(validationClassCount[classLabel],width,height,3))\n",
        "\n",
        "  for img in validationImages:\n",
        "    validationData[validationCount] = img/255.0\n",
        "    validationLabels[validationCount] = labelsInfo[classLabel][0] if not loadTrueLabels else classLabel\n",
        "    trueValidationLabels[validationCount] = classLabel\n",
        "    validationCount += 1\n",
        "  \n",
        "# per ogni immagine genero delle nuove immagini con trasformazioni casuali\n",
        "if useDataAugmentation == True:\n",
        "  print(\"Genero le immagini aggiuntive\")\n",
        "  resetSeed(48560  + randomSeed)\n",
        "  for imageIndex in range(0, trainingCount):\n",
        "    for augIndex in range(0, NUMBER_OF_TRAINING_AUG[trueTrainingLabels[imageIndex]]):\n",
        "      trainingData[trainingCount] = generateRandomImage(generatorTraining, trainingData[imageIndex])/255.0\n",
        "      trainingLabels[trainingCount] = trainingLabels[imageIndex]\n",
        "      trueTrainingLabels[trainingCount] = trueTrainingLabels[imageIndex]\n",
        "      trainingCount += 1\n",
        "\n",
        "  resetSeed(-420360  + randomSeed)\n",
        "  for imageIndex in range(0, validationCount):\n",
        "    for augIndex in range(0, NUMBER_OF_VALIDATION_AUG[trueValidationLabels[imageIndex]]):\n",
        "      validationData[validationCount] = generateRandomImage(generatorValidation, validationData[imageIndex])/255.0\n",
        "      validationLabels[validationCount] = validationLabels[imageIndex]\n",
        "      trueValidationLabels[validationCount] = trueValidationLabels[imageIndex]\n",
        "      validationCount += 1\n",
        "\n",
        "# Se necessario copio l'ultima immagine per rendere la lunghezza divisibile per 8\n",
        "if trainingPadEnd == True:\n",
        "  for index in range(1, trainingToPad + 1):\n",
        "    trainingData[-index] = trainingData[len(trainingData) - (trainingToPad + 1)]\n",
        "    trainingLabels[-index] = trainingLabels[len(trainingLabels) - (trainingToPad + 1)]\n",
        "if validationPadEnd == True:\n",
        "  for index in range(1, validationToPad + 1):\n",
        "    validationData[-index] = validationData[len(validationData) - (validationToPad + 1)]\n",
        "    validationLabels[-index] = validationLabels[len(validationLabels) - (validationToPad + 1)]\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "if use16Bit:\n",
        "    trainingData = tf.convert_to_tensor(trainingData, dtype=tf.bfloat16)\n",
        "    validationData = tf.convert_to_tensor(validationData, dtype=tf.bfloat16)\n",
        "else:\n",
        "    if convertToTesnor:\n",
        "        tempTrainingData = tf.convert_to_tensor(trainingData[:1000], dtype=tf.float32)\n",
        "        tempValidationData = tf.convert_to_tensor(validationData[:1000], dtype=tf.float32)\n",
        "\n",
        "        for index in range((len(trainingData)//1000)-1):\n",
        "            tempTrainingData = tf.concat([tempTrainingData, tf.convert_to_tensor(trainingData[1000+1000*index:1000+1000*(index+1)], dtype=tf.float32)],0)\n",
        "        for index in range((len(validationData)//1000)-1):\n",
        "            tempValidationData = tf.concat([tempValidationData, tf.convert_to_tensor(validationData[1000+1000*index:1000+1000*(index+1)], dtype=tf.float32)],0)\n",
        "        trainingData = tf.concat([tempTrainingData, tf.convert_to_tensor(trainingData[1000*(len(trainingData)//1000):len(trainingData)], dtype=tf.float32)],0)\n",
        "        validationData = tf.concat([tempValidationData, tf.convert_to_tensor(validationData[1000*(len(validationData)//1000):len(validationData)], dtype=tf.float32)],0)\n",
        "print('Training', trainingData.shape) \n",
        "print('Validation', validationData.shape)\n",
        "\n",
        "# statistiche sulla distribuzione delle labels\n",
        "plt.figure(figsize=(20,5))\n",
        "maxLabel = max(trainingLabels)+1\n",
        "print(maxLabel)\n",
        "if maxLabel > 43:\n",
        "  raise RuntimeError(\"C'è un errore grave nel codice, ricontrolla.\")\n",
        "plt.hist(trainingLabels, alpha = 0.5, bins=maxLabel, label = \"training\")\n",
        "plt.hist(validationLabels, alpha = 0.5, bins=maxLabel, label = \"validation\")\n",
        "plt.xticks(np.arange(0, maxLabel, 1))\n",
        "plt.xlim(left=0, right=maxLabel)\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OjI1iBuVXX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# modello inc dello step 1\n",
        "def incBaseline():\n",
        "  def closure():\n",
        "    inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "    layer = buildConvBlock(inputs, layers = 3, size = 64, kernelSize = 3, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "    layer = buildInceptionBlock(layer)\n",
        "    outputs = buildGlobalSoftmax(layer)\n",
        "    return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return (closure, \"incBaseline\")  \n",
        "\n",
        "# più profondo\n",
        "def inc_1():\n",
        "  def closure():\n",
        "    inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "    layer = buildConvBlock(inputs, layers = 3, size = 64, kernelSize = 3, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "    layer = buildInceptionBlock(layer)\n",
        "    layer = buildInceptionBlock(layer)\n",
        "    layer = buildMaxPoolLayer(layer, poolSize=2, poolStrides=2)\n",
        "    layer = buildInceptionBlock(layer)\n",
        "    layer = buildInceptionBlock(layer)\n",
        "    outputs = buildGlobalSoftmax(layer)\n",
        "    return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return (closure, \"inc_1\")\n",
        "\n",
        "# più profondo\n",
        "def inc_2():\n",
        "  def closure():\n",
        "    inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "    layer = buildConvBlock(inputs, layers = 3, size = 64, kernelSize = 3, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "    layer = buildInceptionBlock(layer)\n",
        "    layer = buildInceptionBlock(layer)\n",
        "    layer = buildMaxPoolLayer(layer, poolSize=2, poolStrides=2)\n",
        "    layer = buildInceptionBlock(layer)\n",
        "    layer = buildInceptionBlock(layer)\n",
        "    layer = buildMaxPoolLayer(layer, poolSize=2, poolStrides=2)\n",
        "    layer = buildInceptionBlock(layer)\n",
        "    layer = buildInceptionBlock(layer)\n",
        "    outputs = buildGlobalSoftmax(layer)\n",
        "    return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return (closure, \"inc_2\")  \n",
        "\n",
        "def inc_3():\n",
        "  def closure():\n",
        "    inputs = tf.keras.layers.Input(shape=(width, height, 3), name = \"L0_INPUT\")\n",
        "    layer = buildConvBlock(inputs, layers = 3, size = 64, kernelSize = 5, poolSize = 2, poolStrides = 2, flatten = False)\n",
        "    layer = buildInceptionBlock(layer)\n",
        "    layer = buildInceptionBlock(layer)\n",
        "    layer = buildMaxPoolLayer(layer, poolSize=2, poolStrides=2)\n",
        "    layer = buildInceptionBlock(layer,64,128,64,64)\n",
        "    layer = buildInceptionBlock(layer,64,128,64,64)\n",
        "    layer = buildMaxPoolLayer(layer, poolSize=2, poolStrides=2)\n",
        "    layer = buildInceptionBlock(layer,64,256,64,64)\n",
        "    outputs = buildGlobalSoftmax(layer, denseDepth = 1, denseSize=64, dropout = 0.15)\n",
        "    return tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return (closure, \"inc_3\")   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSWQ8QctU9YR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = Models()\n",
        "\n",
        "trInfo = TrainingInfo.getDefaultTPU(\n",
        "    trainingData,\n",
        "    trainingLabels,\n",
        "    validationData,\n",
        "    validationLabels\n",
        ")\n",
        "\n",
        "uniqueLables, counts = np.unique(trainingLabels, return_counts=True)\n",
        "classWeights = dict(zip(uniqueLables, [math.pow(e,1/3) for e in max(counts) / counts]))\n",
        "print(classWeights)\n",
        "\n",
        "trInfo.setParameters(\n",
        "    learningRateList = [0.0001],\n",
        "    fineTuningIterations = 0,\n",
        "    mainEpochs = 100,\n",
        "    fineTuningEpochs = 200,\n",
        "    batchSize = 128,\n",
        "    validationFrequency = 2,\n",
        "    validationFrequencyFT = 10,\n",
        "    metrics = ['sparse_categorical_accuracy'],\n",
        "    classWeights = classWeights#None\n",
        ")\n",
        "\n",
        "generatedModel = inc_3()\n",
        "models.addModel(generatedModel[1], generatedModel[0], trInfo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y_-ugGJM7U0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Training ( versione 4) { vertical-output: true, display-mode: \"form\" }\n",
        "cleanLastSession = False #@param {type:\"boolean\"}\n",
        "if 'lastSession' in locals():\n",
        "  if cleanLastSession == True:\n",
        "    for trainedModel in lastSession:\n",
        "      print(\"Rimuovo il training del modello\", trainedModel)\n",
        "      shutil.rmtree(trainedModel)\n",
        "    lastSession = []\n",
        "else:\n",
        "  lastSession = []\n",
        "#@markdown ---\n",
        "verboseTraining = 0 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "mainTrainingEarlyStoppingDelta = 0.01 #@param {type:\"number\"}\n",
        "mainTrainingEarlyStoppinPatience = 15 #@param {type:\"integer\"}\n",
        "fineTuningEarlyStoppingDelta = 0.003 #@param {type:\"number\"}\n",
        "fineTuningEarlyStoppinPatience = 10 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "trainingPath = rootPath + phase + \"/\"\n",
        "\n",
        "dataToLog  = [\"AUG : \"+ str(useDataAugmentation)+\"\\n\",\n",
        "                    \"TR_AUG : \" + str(NUMBER_OF_TRAINING_AUG)+\"\\n\",\n",
        "                    \"VAL_AUG : \" + str(NUMBER_OF_VALIDATION_AUG)+\"\\n\",\n",
        "                    \"brightness_range_training : \" + str(brightness_range_training) + \"\\n\",\n",
        "                    \"rotation_range_training : \" + str(rotation_range_training) + \"\\n\",\n",
        "                    \"width_shift_range_training : \" + str(width_shift_range_training) + \"\\n\",\n",
        "                    \"height_shift_range_training : \" + str(height_shift_range_training) + \"\\n\",\n",
        "                    \"shear_range_training : \" + str(shear_range_training) + \"\\n\",     \n",
        "                    \"zoom_range_training : \" + str(zoom_range_training) + \"\\n\",\n",
        "                    \"channel_shift_range_training : \" + str(channel_shift_range_training) + \"\\n\",\n",
        "                    \"brightness_range_validation : \" + str(brightness_range_validation) + \"\\n\",\n",
        "                    \"rotation_range_validation : \" + str(rotation_range_validation) + \"\\n\",\n",
        "                    \"width_shift_range_validation : \" + str(width_shift_range_validation) + \"\\n\",\n",
        "                    \"height_shift_range_validation : \" + str(height_shift_range_validation) + \"\\n\",\n",
        "                    \"shear_range_validation : \" + str(shear_range_validation) + \"\\n\",     \n",
        "                    \"zoom_range_validation : \" + str(zoom_range_validation) + \"\\n\",\n",
        "                    \"channel_shift_range_validation : \" + str(channel_shift_range_validation) + \"\\n\",\n",
        "                    \"sampling : \" + str(samplingToLoad) + \"\\n\",\n",
        "                    \"randomSeed : \" + str(randomSeed)+\"\\n\"]\n",
        "\n",
        "if \"useCustomLoad\" in locals() and useCustomLoad == True:\n",
        "  dataToLog.append(\"Custom_load : \" + str(useCustomLoad)+\"\\n\")\n",
        "  dataToLog.append(\"Custom_ratio : \" + str(customRatio) + \"\\n\")  \n",
        "        \n",
        "train(tpu_address,\n",
        "  trainingPath,\n",
        "  models, \n",
        "  verboseTraining = 1,\n",
        "  mainTrainingEarlyStoppingDelta = mainTrainingEarlyStoppingDelta,\n",
        "  mainTrainingEarlyStoppinPatience = mainTrainingEarlyStoppinPatience,\n",
        "  fineTuningEarlyStoppingDelta = fineTuningEarlyStoppingDelta,\n",
        "  fineTuningEarlyStoppinPatience = fineTuningEarlyStoppinPatience,\n",
        "  stringToLog = ''.join(dataToLog),\n",
        "  lastSession = lastSession)\n",
        "  \n",
        "    \n",
        "print(\"Fine training\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}